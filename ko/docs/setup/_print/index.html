<!doctype html><html lang=ko class=no-js><head><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-36037335-10"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','UA-36037335-10')</script><link rel=alternate hreflang=en href=https://kubernetes.io/docs/setup/><link rel=alternate hreflang=zh href=https://kubernetes.io/zh/docs/setup/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/setup/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/setup/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/setup/><link rel=alternate hreflang=pt href=https://kubernetes.io/pt/docs/setup/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/setup/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/setup/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/setup/><link rel=alternate hreflang=pl href=https://kubernetes.io/pl/docs/setup/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/setup/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.82.0"><link rel=canonical type=text/html href=https://kubernetes.io/ko/docs/setup/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>시작하기 | Kubernetes</title><meta property="og:title" content="시작하기"><meta property="og:description" content="운영 수준의 컨테이너 오케스트레이션"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/ko/docs/setup/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="시작하기"><meta itemprop=description content="운영 수준의 컨테이너 오케스트레이션"><meta name=twitter:card content="summary"><meta name=twitter:title content="시작하기"><meta name=twitter:description content="운영 수준의 컨테이너 오케스트레이션"><link rel=preload href=/scss/main.min.aeea2a074ae7ac3d467a0d6f52e45894b49452cbb3f0f410c268ec7280c5a653.css as=style><link href=/scss/main.min.aeea2a074ae7ac3d467a0d6f52e45894b49452cbb3f0f410c268ec7280c5a653.css rel=stylesheet integrity><script src=/js/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png"}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다. 쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고 클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.
쿠버네티스 클러스터를 로컬 머신에, 클라우드에, 온-프레미스 데이터센터에 배포할 수 있고, 아니면 매니지드 쿠버네티스 클러스터를 선택할 수도 있다. 광범위한 클라우드 제공 업체 또는 베어 메탈 환경에 걸쳐 사용할 수 있는 맞춤형 솔루션도 있다.
학습 환경 쿠버네티스를 배우고 있다면, 쿠버네티스 커뮤니티에서 지원하는 도구나, 로컬 머신에서 쿠버네티스를 설치하기 위한 생태계 내의 도구를 사용하자."><meta property="og:description" content="본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다. 쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고 클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.
쿠버네티스 클러스터를 로컬 머신에, 클라우드에, 온-프레미스 데이터센터에 배포할 수 있고, 아니면 매니지드 쿠버네티스 클러스터를 선택할 수도 있다. 광범위한 클라우드 제공 업체 또는 베어 메탈 환경에 걸쳐 사용할 수 있는 맞춤형 솔루션도 있다.
학습 환경 쿠버네티스를 배우고 있다면, 쿠버네티스 커뮤니티에서 지원하는 도구나, 로컬 머신에서 쿠버네티스를 설치하기 위한 생태계 내의 도구를 사용하자."><meta name=twitter:description content="본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다. 쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고 클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.
쿠버네티스 클러스터를 로컬 머신에, 클라우드에, 온-프레미스 데이터센터에 배포할 수 있고, 아니면 매니지드 쿠버네티스 클러스터를 선택할 수도 있다. 광범위한 클라우드 제공 업체 또는 베어 메탈 환경에 걸쳐 사용할 수 있는 맞춤형 솔루션도 있다.
학습 환경 쿠버네티스를 배우고 있다면, 쿠버네티스 커뮤니티에서 지원하는 도구나, 로컬 머신에서 쿠버네티스를 설치하기 위한 생태계 내의 도구를 사용하자."><meta property="og:url" content="https://kubernetes.io/ko/docs/setup/"><meta property="og:title" content="시작하기"><meta name=twitter:title content="시작하기"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/script.js></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/ko/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/ko/docs/>문서</span></a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/blog/>쿠버네티스 블로그</span></a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/training/>교육</span></a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/partners/>파트너</span></a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/community/>커뮤니티</span></a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/case-studies/>사례 연구</span></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>버전</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=https://kubernetes.io/ko/docs/setup/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/ko/docs/setup/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/ko/docs/setup/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/ko/docs/setup/>v1.21</a>
<a class=dropdown-item href=https://v1-20.docs.kubernetes.io/ko/docs/setup/>v1.20</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>한국어 Korean</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/setup/>English</a>
<a class=dropdown-item href=/zh/docs/setup/>中文 Chinese</a>
<a class=dropdown-item href=/ja/docs/setup/>日本語 Japanese</a>
<a class=dropdown-item href=/fr/docs/setup/>Français</a>
<a class=dropdown-item href=/de/docs/setup/>Deutsch</a>
<a class=dropdown-item href=/pt/docs/setup/>Português</a>
<a class=dropdown-item href=/es/docs/setup/>Español</a>
<a class=dropdown-item href=/id/docs/setup/>Bahasa Indonesia</a>
<a class=dropdown-item href=/ru/docs/setup/>Русский</a>
<a class=dropdown-item href=/pl/docs/setup/>Polski</a>
<a class=dropdown-item href=/uk/docs/setup/>Українська</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/ko/docs/setup/>Return to the regular view of this page</a>.</p></div><h1 class=title>시작하기</h1><ul><li>1: <a href=#pg-d33663ac044e1981b406949f9124cc04>릴리스 노트와 버전 차이 지원(skew)</a></li><ul><li>1.1: <a href=#pg-a49e4163901749c7ce817c73e249f1bc>v1.20 릴리스 노트</a></li><li>1.2: <a href=#pg-85b7e96ac42e5e28ec570ad43f0ef5cd>쿠버네티스 버전 및 버전 차이(skew) 지원 정책</a></li></ul><li>2: <a href=#pg-0b597086a9d1382f86abadcfeab657d6>학습 환경</a></li><ul></ul><li>3: <a href=#pg-4e14853fdaa3bd273f31a60112b9b5ac>운영 환경</a></li><ul><li>3.1: <a href=#pg-a77d3feb6e6d9978f32fa14622642e9a>컨테이너 런타임</a></li><li>3.2: <a href=#pg-00e1646f68aeb89f9722cf6f6cfcad94>배포 도구로 쿠버네티스 설치하기</a></li><ul><li>3.2.1: <a href=#pg-a16f59f325a17cdeed324d5c889f7f73>kubeadm으로 클러스터 구성하기</a></li><ul><li>3.2.1.1: <a href=#pg-29e59491dd6118b23072dfe9ebb93323>kubeadm 설치하기</a></li><li>3.2.1.2: <a href=#pg-4c656c5eda3e1c06ad1aedebdc04a211>kubeadm으로 컨트롤 플레인 사용자 정의하기</a></li><li>3.2.1.3: <a href=#pg-015edbc7cc688d31b1d1edce7c186135>고가용성 토폴로지 선택</a></li><li>3.2.1.4: <a href=#pg-ed857e09999827b013ee9062dc9c59bb>컨트롤 플레인을 자체 호스팅하기 위해 쿠버네티스 클러스터 구성하기</a></li></ul><li>3.2.2: <a href=#pg-478acca1934b6d89a0bc00fb25bfe5b6>Kops로 쿠버네티스 설치하기</a></li><li>3.2.3: <a href=#pg-f8b4964187fe973644e06ee629eff1de>Kubespray로 쿠버네티스 설치하기</a></li></ul><li>3.3: <a href=#pg-acce7e24090fea04715a7a516ba3e69b>쿠버네티스에서 윈도우</a></li><ul><li>3.3.1: <a href=#pg-a307d413f1f7430fced233023087e2a1>쿠버네티스의 윈도우 지원 소개</a></li><li>3.3.2: <a href=#pg-3a51e66c5de55f9093a8dc55742006d3>쿠버네티스에서 윈도우 컨테이너 스케줄링을 위한 가이드</a></li></ul></ul><li>4: <a href=#pg-84b6491601d6a2b3da4cd5a105c866ba>모범 사례</a></li><ul><li>4.1: <a href=#pg-c797ee17120176c685455db89ae091a9>대형 클러스터에 대한 고려 사항</a></li><li>4.2: <a href=#pg-970615c97499e3651fd3a98e0387cefc>여러 영역에서 실행</a></li><li>4.3: <a href=#pg-f89867de1d34943f1524f67a241f5cc9>노드 구성 검증하기</a></li><li>4.4: <a href=#pg-0394f813094b7a35058dffe5b8bacd20>PKI 인증서 및 요구 조건</a></li></ul></ul><div class=content><p>본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다.
쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고
클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.</p><p>쿠버네티스 클러스터를 로컬 머신에, 클라우드에, 온-프레미스 데이터센터에 배포할 수 있고, 아니면 매니지드 쿠버네티스 클러스터를 선택할 수도 있다. 광범위한 클라우드 제공 업체 또는 베어 메탈 환경에 걸쳐 사용할 수 있는 맞춤형 솔루션도 있다.</p><h2 id=학습-환경>학습 환경</h2><p>쿠버네티스를 배우고 있다면, 쿠버네티스 커뮤니티에서 지원하는 도구나, 로컬 머신에서 쿠버네티스를 설치하기 위한 생태계 내의 도구를 사용하자.</p><h2 id=운영-환경>운영 환경</h2><p>운영 환경을 위한 솔루션을 평가할 때에는, 쿠버네티스 클러스터 운영에 대한 어떤 측면(또는 <em>추상적인 개념</em>)을 스스로 관리하기를 원하는지, 제공자에게 넘기기를 원하는지 고려하자.</p><p><a href=https://kubernetes.io/partners/#conformance>쿠버네티스 파트너</a>에는 <a href=https://github.com/cncf/k8s-conformance/#certified-kubernetes>공인 쿠버네티스</a> 공급자 목록이 포함되어 있다.</p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d33663ac044e1981b406949f9124cc04>1 - 릴리스 노트와 버전 차이 지원(skew)</h1></div><div class=td-content><h1 id=pg-a49e4163901749c7ce817c73e249f1bc>1.1 - v1.20 릴리스 노트</h1><h1 id=v1-20-0>v1.20.0</h1><p><a href=https://docs.k8s.io>문서</a></p><h2 id=v1-20-0-다운로드>v1.20.0 다운로드</h2><table><thead><tr><th>파일명</th><th>sha512 해시</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td><code>ebfe49552bbda02807034488967b3b62bf9e3e507d56245e298c4c19090387136572c1fca789e772a5e8a19535531d01dcedb61980e42ca7b0461d3864df2c14</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td><code>bcbd67ed0bb77840828c08c6118ad0c9bf2bcda16763afaafd8731fd6ce735be654feef61e554bcc34c77c65b02a25dae565adc5e1dc49a2daaa0d115bf1efe6</code></td></tr></tbody></table><h3 id=클라이언트-바이너리>클라이언트 바이너리</h3><table><thead><tr><th>파일명</th><th>sha512 해시</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td><code>3609f6483f4244676162232b3294d7a2dc40ae5bdd86a842a05aa768f5223b8f50e1d6420fd8afb2d0ce19de06e1d38e5e5b10154ba0cb71a74233e6dc94d5a0</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td><code>e06c08016a08137d39804383fdc33a40bb2567aa77d88a5c3fd5b9d93f5b581c635b2c4faaa718ed3bb2d120cb14fe91649ed4469ba72c3a3dda1e343db545ed</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td><code>081472833601aa4fa78e79239f67833aa4efcb4efe714426cd01d4ddf6f36fbf304ef7e1f5373bff0fdff44a845f7560165c093c108bd359b5ab4189f36b1f2f</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td><code>037f84a2f29fe62d266cab38ac5600d058cce12cbc4851bcf062fafba796c1fbe23a0c2939cd15784854ca7cd92383e5b96a11474fc71fb614b47dbf98a477d9</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td><code>275727e1796791ca3cbe52aaa713a2660404eab6209466fdc1cfa8559c9b361fe55c64c6bcecbdeba536b6d56213ddf726e58adc60f959b6f77e4017834c5622</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td><code>7a9965293029e9fcdb2b7387467f022d2026953b8461e6c84182abf35c28b7822d2389a6d8e4d8e532d2ea5d5d67c6fee5fb6c351363cb44c599dc8800649b04</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td><code>85fc449ce1980f5f030cc32e8c8e2198c1cc91a448e04b15d27debc3ca56aa85d283f44b4f4e5fed26ac96904cc12808fa3e9af3d8bf823fc928befb9950d6f5</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td><code>4c0a27dba1077aaee943e0eb7a787239dd697e1d968e78d1933c1e60b02d5d233d58541d5beec59807a4ffe3351d5152359e11da120bf64cacb3ee29fbc242e6</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td><code>29336faf7c596539b8329afbbdceeddc843162501de4afee44a40616278fa1f284d8fc48c241fc7d52c65dab70f76280cc33cec419c8c5dbc2625d9175534af8</code></td></tr></tbody></table><h3 id=서버-바이너리>서버 바이너리</h3><table><thead><tr><th>파일명</th><th>sha512 해시</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td><code>fb56486a55dbf7dbacb53b1aaa690bae18d33d244c72a1e2dc95fb0fcce45108c44ba79f8fa04f12383801c46813dc33d2d0eb2203035cdce1078871595e446e</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td><code>735ed9993071fe35b292bf06930ee3c0f889e3c7edb983195b1c8e4d7113047c12c0f8281fe71879fc2fcd871e1ee587f03b695a03c8512c873abad444997a19</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td><code>ffab155531d5a9b82487ee1abf4f6ef49626ea58b2de340656a762e46cf3e0f470bdbe7821210901fe1114224957c44c1d9cc1e32efb5ee24e51fe63990785b2</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td><code>9d5730d35c4ddfb4c5483173629fe55df35d1e535d96f02459468220ac2c97dc01b995f577432a6e4d1548b6edbfdc90828dc9c1f7cf7464481af6ae10aaf118</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td><code>6e4c165306940e8b99dd6e590f8542e31aed23d2c7a6808af0357fa425cec1a57016dd66169cf2a95f8eb8ef70e1f29e2d500533aae889e2e3d9290d04ab8721</code></td></tr></tbody></table><h3 id=노드-바이너리>노드 바이너리</h3><table><thead><tr><th>파일명</th><th>sha512 해시</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td><code>3e6c90561dd1c27fa1dff6953c503251c36001f7e0f8eff3ec918c74ae2d9aa25917d8ac87d5b4224b8229f620b1830442e6dce3b2a497043f8497eee3705696</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td><code>26db385d9ae9a97a1051a638e7e3de22c4bbff389d5a419fe40d5893f9e4fa85c8b60a2bd1d370fd381b60c3ca33c5d72d4767c90898caa9dbd4df6bd116a247</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td><code>5b8b63f617e248432b7eb913285a8ef8ba028255216332c05db949666c3f9e9cb9f4c393bbd68d00369bda77abf9bfa2da254a5c9fe0d79ffdad855a77a9d8ed</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td><code>60da7715996b4865e390640525d6e98593ba3cd45c6caeea763aa5355a7f989926da54f58cc5f657f614c8134f97cd3894b899f8b467d100dca48bc22dd4ff63</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td><code>9407dc55412bd04633f84fcefe3a1074f3eaa772a7cb9302242b8768d6189b75d37677a959f91130e8ad9dc590f9ba8408ba6700a0ceff6827315226dd5ee1e6</code></td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td><code>9d4261af343cc330e6359582f80dbd6efb57d41f882747a94bbf47b4f93292d43dd19a86214d4944d268941622dfbc96847585e6fec15fddc4dbd93d17015fa8</code></td></tr></tbody></table><h2 id=v1-19-0-이후-변경로그-changelog>v1.19.0 이후 변경로그(Changelog)</h2><h2 id=새로운-소식-주요-테마>새로운 소식(주요 테마)</h2><h3 id=dockershim-사용-중단-deprecation>Dockershim 사용 중단(deprecation)</h3><p>Docker as an underlying runtime is being deprecated. Docker-produced images will continue to work in your cluster with all runtimes, as they always have.
The Kubernetes community <a href=https://blog.k8s.io/2020/12/02/dont-panic-kubernetes-and-docker/>has written a blog post about this in detail</a> with <a href=https://blog.k8s.io/2020/12/02/dockershim-faq/>a dedicated FAQ page for it</a>.</p><h3 id=client-go를-위한-외부-자격증명-credential-제공자>client-go를 위한 외부 자격증명(credential) 제공자</h3><p>The client-go credential plugins can now be passed in the current cluster information via the <code>KUBERNETES_EXEC_INFO</code> environment variable. Learn more about this on <a href=https://docs.k8s.io/reference/access-authn-authz/authentication/#client-go-credential-plugins/>client-go credential plugins documentation</a>.</p><h3 id=기능-게이트-feature-gate-를-통해-크론잡-cronjob-컨트롤러-v2-활성화-가능>기능 게이트(feature gate)를 통해 크론잡(CronJob) 컨트롤러 v2 활성화 가능</h3><p>An alternative implementation of <code>CronJob</code> controller is now available as an alpha feature in this release, which has experimental performance improvement by using informers instead of polling. While this will be the default behavior in the future, you can <a href=https://docs.k8s.io/concepts/workloads/controllers/cron-jobs/>try them in this release through a feature gate</a>.</p><h3 id=pid-제한-pid-limits-이-안정-기능-general-availability-으로-전환>PID 제한(PID Limits)이 안정 기능(General Availability)으로 전환</h3><p>PID Limits features are now generally available on both <code>SupportNodePidsLimit</code> (node-to-pod PID isolation) and <code>SupportPodPidsLimit</code> (ability to limit PIDs per pod), after being enabled-by-default in beta stage for a year.</p><h3 id=api-우선순위-및-공정성-api-priority-and-fairness-이-베타-단계로-전환>API 우선순위 및 공정성(API Priority and Fairness)이 베타 단계로 전환</h3><p>Initially introduced in 1.18, Kubernetes 1.20 now enables API Priority and Fairness (APF) by default. This allows <code>kube-apiserver</code> to <a href=https://docs.k8s.io/concepts/cluster-administration/flow-control/>categorize incoming requests by priority levels</a>.</p><h3 id=ipv4-ipv6이-작동>IPv4/IPv6이 작동</h3><p>IPv4/IPv6 dual-stack has been reimplemented for 1.20 to support dual-stack Services, based on user and community feedback. If your cluster has dual-stack enabled, you can create Services which can use IPv4, IPv6, or both, and you can change this setting for existing Services. Details are available in updated <a href=https://docs.k8s.io/concepts/services-networking/dual-stack/>IPv4/IPv6 dual-stack docs</a>, which cover the nuanced array of options.</p><p>We expect this implementation to progress from alpha to beta and GA in coming releases, so we’re eager to have you comment about your dual-stack experiences in <a href=https://kubernetes.slack.com/messages/k8s-dual-stack>#k8s-dual-stack</a> or in <a href=https://features.k8s.io/563>enhancements #563</a>.</p><h3 id=go1-15-5>go1.15.5</h3><p>go1.15.5 has been integrated to Kubernetes project as of this release, <a href=https://github.com/kubernetes/kubernetes/pull/95776>including other infrastructure related updates on this effort</a>.</p><h3 id=csi-볼륨-스냅샷-csi-volume-snapshot-이-안정-기능으로-전환>CSI 볼륨 스냅샷(CSI Volume Snapshot)이 안정 기능으로 전환</h3><p>CSI Volume Snapshot moves to GA in the 1.20 release. This feature provides a standard way to trigger volume snapshot operations in Kubernetes and allows Kubernetes users to incorporate snapshot operations in a portable manner on any Kubernetes environment regardless of supporting underlying storage providers.
Additionally, these Kubernetes snapshot primitives act as basic building blocks that unlock the ability to develop advanced, enterprise grade, storage administration features for Kubernetes: including application or cluster level backup solutions.
Note that snapshot support will require Kubernetes distributors to bundle the Snapshot controller, Snapshot CRDs, and validation webhook. In addition, a CSI driver supporting the snapshot functionality must also be deployed on the cluster.</p><h3 id=비재귀적-볼륨-소유-non-recursive-volume-ownership-fsgroup-가-베타-단계로-전환>비재귀적 볼륨 소유(Non-recursive Volume Ownership (FSGroup))가 베타 단계로 전환</h3><p>By default, the <code>fsgroup</code> setting, if specified, recursively updates permissions for every file in a volume on every mount. This can make mount, and pod startup, very slow if the volume has many files.
This setting enables a pod to specify a <code>PodFSGroupChangePolicy</code> that indicates that volume ownership and permissions will be changed only when permission and ownership of the root directory does not match with expected permissions on the volume.</p><h3 id=fsgroup를-위한-csidriver-정책이-베타-단계로-전환>FSGroup를 위한 CSIDriver 정책이 베타 단계로 전환</h3><p>The FSGroup's CSIDriver Policy is now beta in 1.20. This allows CSIDrivers to explicitly indicate if they want Kubernetes to manage permissions and ownership for their volumes via <code>fsgroup</code>.</p><h3 id=csi-드라이버의-보안성-향상-알파>CSI 드라이버의 보안성 향상(알파)</h3><p>In 1.20, we introduce a new alpha feature <code>CSIServiceAccountToken</code>. This feature allows CSI drivers to impersonate the pods that they mount the volumes for. This improves the security posture in the mounting process where the volumes are ACL’ed on the pods’ service account without handing out unnecessary permissions to the CSI drivers’ service account. This feature is especially important for secret-handling CSI drivers, such as the secrets-store-csi-driver. Since these tokens can be rotated and short-lived, this feature also provides a knob for CSI drivers to receive <code>NodePublishVolume</code> RPC calls periodically with the new token. This knob is also useful when volumes are short-lived, e.g. certificates.</p><h3 id=그레이스풀-노드-종료-graceful-node-shutdown-기능-소개-알파>그레이스풀 노드 종료(Graceful Node Shutdown) 기능 소개(알파)</h3><p>The <code>GracefulNodeShutdown</code> feature is now in Alpha. This allows kubelet to be aware of node system shutdowns, enabling graceful termination of pods during a system shutdown. This feature can be <a href=https://docs.k8s.io/concepts/architecture/nodes/#graceful-node-shutdown>enabled through feature gate</a>.</p><h3 id=런타임-로그-관리-sanitation>런타임 로그 관리(sanitation)</h3><p>Logs can now be configured to use runtime protection from leaking sensitive data. <a href=https://docs.k8s.io/concepts/cluster-administration/system-logs/#log-sanitization>Details for this experimental feature is available in documentation</a>.</p><h3 id=파드-리소스-메트릭>파드 리소스 메트릭</h3><p>On-demand metrics calculation is now available through <code>/metrics/resources</code>. <a href=https://docs.k8s.io/concepts/cluster-administration/system-metrics#kube-scheduler-metrics>When enabled</a>, the endpoint will report the requested resources and the desired limits of all running pods.</p><h3 id=rootcaconfigmap-소개><code>RootCAConfigMap</code> 소개</h3><p><code>RootCAConfigMap</code> graduates to Beta, seperating from <code>BoundServiceAccountTokenVolume</code>. The <code>kube-root-ca.crt</code> ConfigMap is now available to every namespace, by default. It contains the Certificate Authority bundle for verify kube-apiserver connections.</p><h3 id=kubectl-debug-이-베타-단계로-전환><code>kubectl debug</code> 이 베타 단계로 전환</h3><p><code>kubectl alpha debug</code> graduates from alpha to beta in 1.20, becoming <code>kubectl debug</code>.
<code>kubectl debug</code> provides support for common debugging workflows directly from kubectl. Troubleshooting scenarios supported in this release of <code>kubectl</code> include:
Troubleshoot workloads that crash on startup by creating a copy of the pod that uses a different container image or command.
Troubleshoot distroless containers by adding a new container with debugging tools, either in a new copy of the pod or using an ephemeral container. (Ephemeral containers are an alpha feature that are not enabled by default.)
Troubleshoot on a node by creating a container running in the host namespaces and with access to the host’s filesystem.
Note that as a new builtin command, <code>kubectl debug</code> takes priority over any <code>kubectl</code> plugin named “debug”. You will need to rename the affected plugin.
Invocations using <code>kubectl alpha debug</code> are now deprecated and will be removed in a subsequent release. Update your scripts to use <code>kubectl debug</code> instead of <code>kubectl alpha debug</code>!
For more information about kubectl debug, see Debugging Running Pods on the Kubernetes website, kubectl help debug, or reach out to SIG CLI by visiting #sig-cli or commenting on <a href=https://features.k8s.io/1441>enhancement #1441</a>.</p><h3 id=kubeadm에서-사용-중단된-플래그-삭제>kubeadm에서 사용 중단된 플래그 삭제</h3><p><code>kubeadm</code> applies a number of deprecations and removals of deprecated features in this release. More details are available in the Urgent Upgrade Notes and Kind / Deprecation sections.</p><h3 id=파드의-호스트네임을-fqdn으로-사용하는-것이-베타-단계로-전환>파드의 호스트네임을 FQDN으로 사용하는 것이 베타 단계로 전환</h3><p>Previously introduced in 1.19 behind a feature gate, <code>SetHostnameAsFQDN</code> is now enabled by default. More details on this behavior is available in <a href=https://docs.k8s.io/concepts/services-networking/dns-pod-service/#pod-sethostnameasfqdn-field>documentation for DNS for Services and Pods</a></p><h3 id=tokenrequest-tokenrequestprojection-이-안정-기능으로-전환><code>TokenRequest</code> / <code>TokenRequestProjection</code> 이 안정 기능으로 전환</h3><p>Service account tokens bound to pod is now a stable feature. The feature gates will be removed in 1.21 release. For more information, refer to notes below on the changelogs.</p><h3 id=런타임클래스-runtimeclass-가-안정-기능으로-전환>런타임클래스(RuntimeClass)가 안정 기능으로 전환</h3><p>The <code>node.k8s.io</code> API groups are promoted from <code>v1beta1</code> to <code>v1</code>. <code>v1beta1</code> is now deprecated and will be removed in a future release, please start using <code>v1</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/95718>#95718</a>, <a href=https://github.com/SergeyKanzhelev>@SergeyKanzhelev</a>) [SIG Apps, Auth, Node, Scheduling and Testing]</p><h3 id=클라우드-컨트롤러-관리자-cloud-controller-manager-가-이제-각-클라우드-공급자를-통해서만-제공>클라우드 컨트롤러 관리자(Cloud Controller Manager)가 이제 각 클라우드 공급자를 통해서만 제공</h3><p>Kubernetes will no longer ship an instance of the Cloud Controller Manager binary. Each Cloud Provider is expected to ship their own instance of this binary. Details for a Cloud Provider to create an instance of such a binary can be found under <a href=https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/cloud-provider/sample>here</a>. Anyone with questions on building a Cloud Controller Manager should reach out to SIG Cloud Provider. Questions about the Cloud Controller Manager on a Managed Kubernetes solution should go to the relevant Cloud Provider. Questions about the Cloud Controller Manager on a non managed solution can be brought up with SIG Cloud Provider.</p><h2 id=알려진-이슈>알려진 이슈</h2><h3 id=kubelet의-요약-summary-api는-가속기-accelerator-메트릭을-가지고-있지-않음>kubelet의 요약(Summary) API는 가속기(accelerator) 메트릭을 가지고 있지 않음</h3><p>Currently, cadvisor_stats_provider provides AcceleratorStats but cri_stats_provider does not. As a result, when using cri_stats_provider, kubelet's Summary API does not have accelerator metrics. <a href=https://github.com/kubernetes/kubernetes/pull/96873>There is an open work in progress to fix this</a>.</p><h2 id=긴급-업그레이드-노트>긴급 업그레이드 노트</h2><h3 id=주의-업그레이드-전에-반드시-읽어야-함>(주의. 업그레이드 전에 반드시 읽어야 함)</h3><ul><li><p>A bug was fixed in kubelet where exec probe timeouts were not respected. This may result in unexpected behavior since the default timeout (if not specified) is <code>1s</code> which may be too small for some exec probes. Ensure that pods relying on this behavior are updated to correctly handle probe timeouts. See <a href=https://docs.k8s.io/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes>configure probe</a> section of the documentation for more details.</p><ul><li>This change in behavior may be unexpected for some clusters and can be disabled by turning off the <code>ExecProbeTimeout</code> feature gate. This gate will be locked and removed in future releases so that exec probe timeouts are always respected. (<a href=https://github.com/kubernetes/kubernetes/pull/94115>#94115</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Node and Testing]</li></ul></li><li><p>RuntimeClass feature graduates to General Availability. Promote <code>node.k8s.io</code> API groups from <code>v1beta1</code> to <code>v1</code>. <code>v1beta1</code> is now deprecated and will be removed in a future release, please start using <code>v1</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/95718>#95718</a>, <a href=https://github.com/SergeyKanzhelev>@SergeyKanzhelev</a>) [SIG Apps, Auth, Node, Scheduling and Testing]</p></li><li><p>API priority and fairness graduated to beta. 1.19 servers with APF turned on should not be run in a multi-server cluster with 1.20+ servers. (<a href=https://github.com/kubernetes/kubernetes/pull/96527>#96527</a>, <a href=https://github.com/adtac>@adtac</a>) [SIG API Machinery and Testing]</p></li><li><p>For CSI drivers, kubelet no longer creates the target_path for NodePublishVolume in accordance with the CSI spec. Kubelet also no longer checks if staging and target paths are mounts or corrupted. CSI drivers need to be idempotent and do any necessary mount verification. (<a href=https://github.com/kubernetes/kubernetes/pull/88759>#88759</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Storage]</p></li><li><p>Kubeadm: <a href=http://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/kubeadm/2067-rename-master-label-taint/README.md>http://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/kubeadm/2067-rename-master-label-taint/README.md</a> (<a href=https://github.com/kubernetes/kubernetes/pull/95382>#95382</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p><ul><li>The label applied to control-plane nodes "node-role.kubernetes.io/master" is now deprecated and will be removed in a future release after a GA deprecation period.</li><li>Introduce a new label "node-role.kubernetes.io/control-plane" that will be applied in parallel to "node-role.kubernetes.io/master" until the removal of the "node-role.kubernetes.io/master" label.</li><li>Make "kubeadm upgrade apply" add the "node-role.kubernetes.io/control-plane" label on existing nodes that only have the "node-role.kubernetes.io/master" label during upgrade.</li><li>Please adapt your tooling built on top of kubeadm to use the "node-role.kubernetes.io/control-plane" label.</li><li>The taint applied to control-plane nodes "node-role.kubernetes.io/master:NoSchedule" is now deprecated and will be removed in a future release after a GA deprecation period.</li><li>Apply toleration for a new, future taint "node-role.kubernetes.io/control-plane:NoSchedule" to the kubeadm CoreDNS / kube-dns managed manifests. Note that this taint is not yet applied to kubeadm control-plane nodes.</li><li>Please adapt your workloads to tolerate the same future taint preemptively.</li></ul></li><li><p>Kubeadm: improve the validation of serviceSubnet and podSubnet.
ServiceSubnet has to be limited in size, due to implementation details, and the mask can not allocate more than 20 bits.
PodSubnet validates against the corresponding cluster "--node-cidr-mask-size" of the kube-controller-manager, it fail if the values are not compatible.
kubeadm no longer sets the node-mask automatically on IPv6 deployments, you must check that your IPv6 service subnet mask is compatible with the default node mask /64 or set it accordenly.
Previously, for IPv6, if the podSubnet had a mask lower than /112, kubeadm calculated a node-mask to be multiple of eight and splitting the available bits to maximise the number used for nodes. (<a href=https://github.com/kubernetes/kubernetes/pull/95723>#95723</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Cluster Lifecycle]</p></li><li><p>The deprecated flag --experimental-kustomize is now removed from kubeadm commands. Use --experimental-patches instead, which was introduced in 1.19. Migration information available in --help description for --experimental-patches. (<a href=https://github.com/kubernetes/kubernetes/pull/94871>#94871</a>, <a href=https://github.com/neolit123>@neolit123</a>)</p></li><li><p>Windows hyper-v container featuregate is deprecated in 1.20 and will be removed in 1.21 (<a href=https://github.com/kubernetes/kubernetes/pull/95505>#95505</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node and Windows]</p></li><li><p>The kube-apiserver ability to serve on an insecure port, deprecated since v1.10, has been removed. The insecure address flags <code>--address</code> and <code>--insecure-bind-address</code> have no effect in kube-apiserver and will be removed in v1.24. The insecure port flags <code>--port</code> and <code>--insecure-port</code> may only be set to 0 and will be removed in v1.24. (<a href=https://github.com/kubernetes/kubernetes/pull/95856>#95856</a>, <a href=https://github.com/knight42>@knight42</a>, [SIG API Machinery, Node, Testing])</p></li><li><p>Add dual-stack Services (alpha). This is a BREAKING CHANGE to an alpha API.
It changes the dual-stack API wrt Service from a single ipFamily field to 3
fields: ipFamilyPolicy (SingleStack, PreferDualStack, RequireDualStack),
ipFamilies (a list of families assigned), and clusterIPs (inclusive of
clusterIP). Most users do not need to set anything at all, defaulting will
handle it for them. Services are single-stack unless the user asks for
dual-stack. This is all gated by the "IPv6DualStack" feature gate. (<a href=https://github.com/kubernetes/kubernetes/pull/91824>#91824</a>, <a href=https://github.com/khenidak>@khenidak</a>) [SIG API Machinery, Apps, CLI, Network, Node, Scheduling and Testing]</p></li><li><p><code>TokenRequest</code> and <code>TokenRequestProjection</code> are now GA features. The following flags are required by the API server:</p><ul><li><code>--service-account-issuer</code>, should be set to a URL identifying the API server that will be stable over the cluster lifetime.</li><li><code>--service-account-key-file</code>, set to one or more files containing one or more public keys used to verify tokens.</li><li><code>--service-account-signing-key-file</code>, set to a file containing a private key to use to sign service account tokens. Can be the same file given to <code>kube-controller-manager</code> with <code>--service-account-private-key-file</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/95896>#95896</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Auth, Cluster Lifecycle]</li></ul></li><li><p>kubeadm: make the command "kubeadm alpha kubeconfig user" accept a "--config" flag and remove the following flags:</p><ul><li>apiserver-advertise-address / apiserver-bind-port: use either localAPIEndpoint from InitConfiguration or controlPlaneEndpoint from ClusterConfiguration.</li><li>cluster-name: use clusterName from ClusterConfiguration</li><li>cert-dir: use certificatesDir from ClusterConfiguration (<a href=https://github.com/kubernetes/kubernetes/pull/94879>#94879</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cluster Lifecycle]</li></ul></li><li><p>Resolves non-deterministic behavior of the garbage collection controller when ownerReferences with incorrect data are encountered. Events with a reason of <code>OwnerRefInvalidNamespace</code> are recorded when namespace mismatches between child and owner objects are detected. The <a href=https://github.com/kubernetes-sigs/kubectl-check-ownerreferences>kubectl-check-ownerreferences</a> tool can be run prior to upgrading to locate existing objects with invalid ownerReferences.</p><ul><li>A namespaced object with an ownerReference referencing a uid of a namespaced kind which does not exist in the same namespace is now consistently treated as though that owner does not exist, and the child object is deleted.</li><li>A cluster-scoped object with an ownerReference referencing a uid of a namespaced kind is now consistently treated as though that owner is not resolvable, and the child object is ignored by the garbage collector. (<a href=https://github.com/kubernetes/kubernetes/pull/92743>#92743</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery, Apps and Testing]</li></ul></li></ul><h2 id=종류-kind-별-변경-사항>종류(Kind)별 변경 사항</h2><h3 id=사용-중단>사용 중단</h3><ul><li>Docker support in the kubelet is now deprecated and will be removed in a future release. The kubelet uses a module called "dockershim" which implements CRI support for Docker and it has seen maintenance issues in the Kubernetes community. We encourage you to evaluate moving to a container runtime that is a full-fledged implementation of CRI (v1alpha1 or v1 compliant) as they become available. (<a href=https://github.com/kubernetes/kubernetes/pull/94624>#94624</a>, <a href=https://github.com/dims>@dims</a>) [SIG Node]</li><li>Kubeadm: deprecate self-hosting support. The experimental command "kubeadm alpha self-hosting" is now deprecated and will be removed in a future release. (<a href=https://github.com/kubernetes/kubernetes/pull/95125>#95125</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: graduate the "kubeadm alpha certs" command to a parent command "kubeadm certs". The command "kubeadm alpha certs" is deprecated and will be removed in a future release. Please migrate. (<a href=https://github.com/kubernetes/kubernetes/pull/94938>#94938</a>, <a href=https://github.com/yagonobre>@yagonobre</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: remove the deprecated "kubeadm alpha kubelet config enable-dynamic" command. To continue using the feature please defer to the guide for "Dynamic Kubelet Configuration" at k8s.io. This change also removes the parent command "kubeadm alpha kubelet" as there are no more sub-commands under it for the time being. (<a href=https://github.com/kubernetes/kubernetes/pull/94668>#94668</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: remove the deprecated --kubelet-config flag for the command "kubeadm upgrade node" (<a href=https://github.com/kubernetes/kubernetes/pull/94869>#94869</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubectl: deprecate --delete-local-data (<a href=https://github.com/kubernetes/kubernetes/pull/95076>#95076</a>, <a href=https://github.com/dougsland>@dougsland</a>) [SIG CLI, Cloud Provider and Scalability]</li><li>Kubelet's deprecated endpoint <code>metrics/resource/v1alpha1</code> has been removed, please adopt <code>metrics/resource</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/94272>#94272</a>, <a href=https://github.com/RainbowMango>@RainbowMango</a>) [SIG Instrumentation and Node]</li><li>Removes deprecated scheduler metrics DeprecatedSchedulingDuration, DeprecatedSchedulingAlgorithmPredicateEvaluationSecondsDuration, DeprecatedSchedulingAlgorithmPriorityEvaluationSecondsDuration (<a href=https://github.com/kubernetes/kubernetes/pull/94884>#94884</a>, <a href=https://github.com/arghya88>@arghya88</a>) [SIG Instrumentation and Scheduling]</li><li>Scheduler alpha metrics binding_duration_seconds and scheduling_algorithm_preemption_evaluation_seconds are deprecated, Both of those metrics are now covered as part of framework_extension_point_duration_seconds, the former as a PostFilter the latter and a Bind plugin. The plan is to remove both in 1.21 (<a href=https://github.com/kubernetes/kubernetes/pull/95001>#95001</a>, <a href=https://github.com/arghya88>@arghya88</a>) [SIG Instrumentation and Scheduling]</li><li>Support 'controlplane' as a valid EgressSelection type in the EgressSelectorConfiguration API. 'Master' is deprecated and will be removed in v1.22. (<a href=https://github.com/kubernetes/kubernetes/pull/95235>#95235</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG API Machinery]</li><li>The v1alpha1 PodPreset API and admission plugin has been removed with no built-in replacement. Admission webhooks can be used to modify pods on creation. (<a href=https://github.com/kubernetes/kubernetes/pull/94090>#94090</a>, <a href=https://github.com/deads2k>@deads2k</a>) [SIG API Machinery, Apps, CLI, Cloud Provider, Scalability and Testing]</li></ul><h3 id=api-변경>API 변경</h3><ul><li><code>TokenRequest</code> and <code>TokenRequestProjection</code> features have been promoted to GA. This feature allows generating service account tokens that are not visible in Secret objects and are tied to the lifetime of a Pod object. See <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection>https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection</a> for details on configuring and using this feature. The <code>TokenRequest</code> and <code>TokenRequestProjection</code> feature gates will be removed in v1.21.<ul><li>kubeadm's kube-apiserver Pod manifest now includes the following flags by default "--service-account-key-file", "--service-account-signing-key-file", "--service-account-issuer". (<a href=https://github.com/kubernetes/kubernetes/pull/93258>#93258</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Auth, Cluster Lifecycle, Storage and Testing]</li></ul></li><li>A new <code>nofuzz</code> go build tag now disables gofuzz support. Release binaries enable this. (<a href=https://github.com/kubernetes/kubernetes/pull/92491>#92491</a>, <a href=https://github.com/BenTheElder>@BenTheElder</a>) [SIG API Machinery]</li><li>Add WindowsContainerResources and Annotations to CRI-API UpdateContainerResourcesRequest (<a href=https://github.com/kubernetes/kubernetes/pull/95741>#95741</a>, <a href=https://github.com/katiewasnothere>@katiewasnothere</a>) [SIG Node]</li><li>Add a <code>serving</code> and <code>terminating</code> condition to the EndpointSlice API.
<code>serving</code> tracks the readiness of endpoints regardless of their terminating state. This is distinct from <code>ready</code> since <code>ready</code> is only true when pods are not terminating.
<code>terminating</code> is true when an endpoint is terminating. For pods this is any endpoint with a deletion timestamp. (<a href=https://github.com/kubernetes/kubernetes/pull/92968>#92968</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Apps and Network]</li><li>Add dual-stack Services (alpha). This is a BREAKING CHANGE to an alpha API.
It changes the dual-stack API wrt Service from a single ipFamily field to 3
fields: ipFamilyPolicy (SingleStack, PreferDualStack, RequireDualStack),
ipFamilies (a list of families assigned), and clusterIPs (inclusive of
clusterIP). Most users do not need to set anything at all, defaulting will
handle it for them. Services are single-stack unless the user asks for
dual-stack. This is all gated by the "IPv6DualStack" feature gate. (<a href=https://github.com/kubernetes/kubernetes/pull/91824>#91824</a>, <a href=https://github.com/khenidak>@khenidak</a>) [SIG API Machinery, Apps, CLI, Network, Node, Scheduling and Testing]</li><li>Add support for hugepages to downward API (<a href=https://github.com/kubernetes/kubernetes/pull/86102>#86102</a>, <a href=https://github.com/derekwaynecarr>@derekwaynecarr</a>) [SIG API Machinery, Apps, CLI, Network, Node, Scheduling and Testing]</li><li>Adds kubelet alpha feature, <code>GracefulNodeShutdown</code> which makes kubelet aware of node system shutdowns and result in graceful termination of pods during a system shutdown. (<a href=https://github.com/kubernetes/kubernetes/pull/96129>#96129</a>, <a href=https://github.com/bobbypage>@bobbypage</a>) [SIG Node]</li><li>AppProtocol is now GA for Endpoints and Services. The ServiceAppProtocol feature gate will be deprecated in 1.21. (<a href=https://github.com/kubernetes/kubernetes/pull/96327>#96327</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps and Network]</li><li>Automatic allocation of NodePorts for services with type LoadBalancer can now be disabled by setting the (new) parameter
Service.spec.allocateLoadBalancerNodePorts=false. The default is to allocate NodePorts for services with type LoadBalancer which is the existing behavior. (<a href=https://github.com/kubernetes/kubernetes/pull/92744>#92744</a>, <a href=https://github.com/uablrek>@uablrek</a>) [SIG Apps and Network]</li><li>Certain fields on Service objects will be automatically cleared when changing the service's <code>type</code> to a mode that does not need those fields. For example, changing from type=LoadBalancer to type=ClusterIP will clear the NodePort assignments, rather than forcing the user to clear them. (<a href=https://github.com/kubernetes/kubernetes/pull/95196>#95196</a>, <a href=https://github.com/thockin>@thockin</a>) [SIG API Machinery, Apps, Network and Testing]</li><li>Document that ServiceTopology feature is required to use <code>service.spec.topologyKeys</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/96528>#96528</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Apps]</li><li>EndpointSlice has a new NodeName field guarded by the EndpointSliceNodeName feature gate.<ul><li>EndpointSlice topology field will be deprecated in an upcoming release.</li><li>EndpointSlice "IP" address type is formally removed after being deprecated in Kubernetes 1.17.</li><li>The discovery.k8s.io/v1alpha1 API is deprecated and will be removed in Kubernetes 1.21. (<a href=https://github.com/kubernetes/kubernetes/pull/96440>#96440</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG API Machinery, Apps and Network]</li></ul></li><li>External facing API podresources is now available under k8s.io/kubelet/pkg/apis/ (<a href=https://github.com/kubernetes/kubernetes/pull/92632>#92632</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>) [SIG Node and Testing]</li><li>Fewer candidates are enumerated for preemption to improve performance in large clusters. (<a href=https://github.com/kubernetes/kubernetes/pull/94814>#94814</a>, <a href=https://github.com/adtac>@adtac</a>)</li><li>Fix conversions for custom metrics. (<a href=https://github.com/kubernetes/kubernetes/pull/94481>#94481</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Instrumentation]</li><li>GPU metrics provided by kubelet are now disabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/95184>#95184</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>)</li><li>If BoundServiceAccountTokenVolume is enabled, cluster admins can use metric <code>serviceaccount_stale_tokens_total</code> to monitor workloads that are depending on the extended tokens. If there are no such workloads, turn off extended tokens by starting <code>kube-apiserver</code> with flag <code>--service-account-extend-token-expiration=false</code> (<a href=https://github.com/kubernetes/kubernetes/pull/96273>#96273</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery and Auth]</li><li>Introduce alpha support for exec-based container registry credential provider plugins in the kubelet. (<a href=https://github.com/kubernetes/kubernetes/pull/94196>#94196</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Node and Release]</li><li>Introduces a metric source for HPAs which allows scaling based on container resource usage. (<a href=https://github.com/kubernetes/kubernetes/pull/90691>#90691</a>, <a href=https://github.com/arjunrn>@arjunrn</a>) [SIG API Machinery, Apps, Autoscaling and CLI]</li><li>Kube-apiserver now deletes expired kube-apiserver Lease objects:<ul><li>The feature is under feature gate <code>APIServerIdentity</code>.</li><li>A flag is added to kube-apiserver: <code>identity-lease-garbage-collection-check-period-seconds</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95895>#95895</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery, Apps, Auth and Testing]</li></ul></li><li>Kube-controller-manager: volume plugins can be restricted from contacting local and loopback addresses by setting <code>--volume-host-allow-local-loopback=false</code>, or from contacting specific CIDR ranges by setting <code>--volume-host-cidr-denylist</code> (for example, <code>--volume-host-cidr-denylist=127.0.0.1/28,feed::/16</code>) (<a href=https://github.com/kubernetes/kubernetes/pull/91785>#91785</a>, <a href=https://github.com/mattcary>@mattcary</a>) [SIG API Machinery, Apps, Auth, CLI, Network, Node, Storage and Testing]</li><li>Migrate scheduler, controller-manager and cloud-controller-manager to use LeaseLock (<a href=https://github.com/kubernetes/kubernetes/pull/94603>#94603</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery, Apps, Cloud Provider and Scheduling]</li><li>Modify DNS-1123 error messages to indicate that RFC 1123 is not followed exactly (<a href=https://github.com/kubernetes/kubernetes/pull/94182>#94182</a>, <a href=https://github.com/mattfenwick>@mattfenwick</a>) [SIG API Machinery, Apps, Auth, Network and Node]</li><li>Move configurable fsgroup change policy for pods to beta (<a href=https://github.com/kubernetes/kubernetes/pull/96376>#96376</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Apps and Storage]</li><li>New flag is introduced, i.e. --topology-manager-scope=container|pod.
The default value is the "container" scope. (<a href=https://github.com/kubernetes/kubernetes/pull/92967>#92967</a>, <a href=https://github.com/cezaryzukowski>@cezaryzukowski</a>) [SIG Instrumentation, Node and Testing]</li><li>New parameter <code>defaultingType</code> for <code>PodTopologySpread</code> plugin allows to use k8s defined or user provided default constraints (<a href=https://github.com/kubernetes/kubernetes/pull/95048>#95048</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</li><li>NodeAffinity plugin can be configured with AddedAffinity. (<a href=https://github.com/kubernetes/kubernetes/pull/96202>#96202</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Node, Scheduling and Testing]</li><li>Promote RuntimeClass feature to GA.
Promote node.k8s.io API groups from v1beta1 to v1. (<a href=https://github.com/kubernetes/kubernetes/pull/95718>#95718</a>, <a href=https://github.com/SergeyKanzhelev>@SergeyKanzhelev</a>) [SIG Apps, Auth, Node, Scheduling and Testing]</li><li>Reminder: The labels "failure-domain.beta.kubernetes.io/zone" and "failure-domain.beta.kubernetes.io/region" are deprecated in favor of "topology.kubernetes.io/zone" and "topology.kubernetes.io/region" respectively. All users of the "failure-domain.beta..." labels should switch to the "topology..." equivalents. (<a href=https://github.com/kubernetes/kubernetes/pull/96033>#96033</a>, <a href=https://github.com/thockin>@thockin</a>) [SIG API Machinery, Apps, CLI, Cloud Provider, Network, Node, Scheduling, Storage and Testing]</li><li>Server Side Apply now treats LabelSelector fields as atomic (meaning the entire selector is managed by a single writer and updated together), since they contain interrelated and inseparable fields that do not merge in intuitive ways. (<a href=https://github.com/kubernetes/kubernetes/pull/93901>#93901</a>, <a href=https://github.com/jpbetz>@jpbetz</a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Storage and Testing]</li><li>Services will now have a <code>clusterIPs</code> field to go with <code>clusterIP</code>. <code>clusterIPs[0]</code> is a synonym for <code>clusterIP</code> and will be syncronized on create and update operations. (<a href=https://github.com/kubernetes/kubernetes/pull/95894>#95894</a>, <a href=https://github.com/thockin>@thockin</a>) [SIG Network]</li><li>The ServiceAccountIssuerDiscovery feature gate is now Beta and enabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/91921>#91921</a>, <a href=https://github.com/mtaufen>@mtaufen</a>) [SIG Auth]</li><li>The status of v1beta1 CRDs without "preserveUnknownFields:false" now shows a violation, "spec.preserveUnknownFields: Invalid value: true: must be false". (<a href=https://github.com/kubernetes/kubernetes/pull/93078>#93078</a>, <a href=https://github.com/vareti>@vareti</a>)</li><li>The usage of mixed protocol values in the same LoadBalancer Service is possible if the new feature gate MixedProtocolLBService is enabled. The feature gate is disabled by default. The user has to enable it for the API Server. (<a href=https://github.com/kubernetes/kubernetes/pull/94028>#94028</a>, <a href=https://github.com/janosi>@janosi</a>) [SIG API Machinery and Apps]</li><li>This PR will introduce a feature gate CSIServiceAccountToken with two additional fields in <code>CSIDriverSpec</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/93130>#93130</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Apps, Auth, CLI, Network, Node, Storage and Testing]</li><li>Users can try the cronjob controller v2 using the feature gate. This will be the default controller in future releases. (<a href=https://github.com/kubernetes/kubernetes/pull/93370>#93370</a>, <a href=https://github.com/alaypatel07>@alaypatel07</a>) [SIG API Machinery, Apps, Auth and Testing]</li><li>VolumeSnapshotDataSource moves to GA in 1.20 release (<a href=https://github.com/kubernetes/kubernetes/pull/95282>#95282</a>, <a href=https://github.com/xing-yang>@xing-yang</a>) [SIG Apps]</li><li>WinOverlay feature graduated to beta (<a href=https://github.com/kubernetes/kubernetes/pull/94807>#94807</a>, <a href=https://github.com/ksubrmnn>@ksubrmnn</a>) [SIG Windows]</li></ul><h3 id=기능-feature>기능(feature)</h3><ul><li><p><strong>Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.</strong>:</p></li><li><p>A new metric <code>apiserver_request_filter_duration_seconds</code> has been introduced that
measures request filter latency in seconds. (<a href=https://github.com/kubernetes/kubernetes/pull/95207>#95207</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery and Instrumentation]</p></li><li><p>A new set of alpha metrics are reported by the Kubernetes scheduler under the <code>/metrics/resources</code> endpoint that allow administrators to easily see the resource consumption (requests and limits for all resources on the pods) and compare it to actual pod usage or node capacity. (<a href=https://github.com/kubernetes/kubernetes/pull/94866>#94866</a>, <a href=https://github.com/smarterclayton>@smarterclayton</a>) [SIG API Machinery, Instrumentation, Node and Scheduling]</p></li><li><p>Add --experimental-logging-sanitization flag enabling runtime protection from leaking sensitive data in logs (<a href=https://github.com/kubernetes/kubernetes/pull/96370>#96370</a>, <a href=https://github.com/serathius>@serathius</a>) [SIG API Machinery, Cluster Lifecycle and Instrumentation]</p></li><li><p>Add a StorageVersionAPI feature gate that makes API server update storageversions before serving certain write requests.
This feature allows the storage migrator to manage storage migration for built-in resources.
Enabling internal.apiserver.k8s.io/v1alpha1 API and APIServerIdentity feature gate are required to use this feature. (<a href=https://github.com/kubernetes/kubernetes/pull/93873>#93873</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery, Auth and Testing]</p></li><li><p>Add a metric for time taken to perform recursive permission change (<a href=https://github.com/kubernetes/kubernetes/pull/95866>#95866</a>, <a href=https://github.com/JornShen>@JornShen</a>) [SIG Instrumentation and Storage]</p></li><li><p>Add a new <code>vSphere</code> metric: <code>cloudprovider_vsphere_vcenter_versions</code>. It's content show <code>vCenter</code> hostnames with the associated server version. (<a href=https://github.com/kubernetes/kubernetes/pull/94526>#94526</a>, <a href=https://github.com/Danil-Grigorev>@Danil-Grigorev</a>) [SIG Cloud Provider and Instrumentation]</p></li><li><p>Add a new flag to set priority for the kubelet on Windows nodes so that workloads cannot overwhelm the node there by disrupting kubelet process. (<a href=https://github.com/kubernetes/kubernetes/pull/96051>#96051</a>, <a href=https://github.com/ravisantoshgudimetla>@ravisantoshgudimetla</a>) [SIG Node and Windows]</p></li><li><p>Add feature to size memory backed volumes (<a href=https://github.com/kubernetes/kubernetes/pull/94444>#94444</a>, <a href=https://github.com/derekwaynecarr>@derekwaynecarr</a>) [SIG Storage and Testing]</p></li><li><p>Add foreground cascading deletion to kubectl with the new <code>kubectl delete foreground|background|orphan</code> option. (<a href=https://github.com/kubernetes/kubernetes/pull/93384>#93384</a>, <a href=https://github.com/zhouya0>@zhouya0</a>)</p></li><li><p>Add metrics for azure service operations (route and loadbalancer). (<a href=https://github.com/kubernetes/kubernetes/pull/94124>#94124</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider and Instrumentation]</p></li><li><p>Add network rule support in Azure account creation. (<a href=https://github.com/kubernetes/kubernetes/pull/94239>#94239</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>)</p></li><li><p>Add node_authorizer_actions_duration_seconds metric that can be used to estimate load to node authorizer. (<a href=https://github.com/kubernetes/kubernetes/pull/92466>#92466</a>, <a href=https://github.com/mborsz>@mborsz</a>) [SIG API Machinery, Auth and Instrumentation]</p></li><li><p>Add pod_ based CPU and memory metrics to Kubelet's /metrics/resource endpoint (<a href=https://github.com/kubernetes/kubernetes/pull/95839>#95839</a>, <a href=https://github.com/egernst>@egernst</a>) [SIG Instrumentation, Node and Testing]</p></li><li><p>Added <code>get-users</code> and <code>delete-user</code> to the <code>kubectl config</code> subcommand (<a href=https://github.com/kubernetes/kubernetes/pull/89840>#89840</a>, <a href=https://github.com/eddiezane>@eddiezane</a>) [SIG CLI]</p></li><li><p>Added counter metric "apiserver_request_self" to count API server self-requests with labels for verb, resource, and subresource. (<a href=https://github.com/kubernetes/kubernetes/pull/94288>#94288</a>, <a href=https://github.com/LogicalShark>@LogicalShark</a>) [SIG API Machinery, Auth, Instrumentation and Scheduling]</p></li><li><p>Added new k8s.io/component-helpers repository providing shared helper code for (core) components. (<a href=https://github.com/kubernetes/kubernetes/pull/92507>#92507</a>, <a href=https://github.com/ingvagabund>@ingvagabund</a>) [SIG Apps, Node, Release and Scheduling]</p></li><li><p>Adds <code>create ingress</code> command to <code>kubectl</code> (<a href=https://github.com/kubernetes/kubernetes/pull/78153>#78153</a>, <a href=https://github.com/amimof>@amimof</a>) [SIG CLI and Network]</p></li><li><p>Adds a headless service on node-local-cache addon. (<a href=https://github.com/kubernetes/kubernetes/pull/88412>#88412</a>, <a href=https://github.com/stafot>@stafot</a>) [SIG Cloud Provider and Network]</p></li><li><p>Allow cross compilation of kubernetes on different platforms. (<a href=https://github.com/kubernetes/kubernetes/pull/94403>#94403</a>, <a href=https://github.com/bnrjee>@bnrjee</a>) [SIG Release]</p></li><li><p>Azure: Support multiple services sharing one IP address (<a href=https://github.com/kubernetes/kubernetes/pull/94991>#94991</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>CRDs: For structural schemas, non-nullable null map fields will now be dropped and defaulted if a default is available. null items in list will continue being preserved, and fail validation if not nullable. (<a href=https://github.com/kubernetes/kubernetes/pull/95423>#95423</a>, <a href=https://github.com/apelisse>@apelisse</a>) [SIG API Machinery]</p></li><li><p>Changed: default "Accept: <em>/</em>" header added to HTTP probes. See <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes>https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes</a> (<a href=https://github.com/kubernetes/website/pull/24756>https://github.com/kubernetes/website/pull/24756</a>) (<a href=https://github.com/kubernetes/kubernetes/pull/95641>#95641</a>, <a href=https://github.com/fonsecas72>@fonsecas72</a>) [SIG Network and Node]</p></li><li><p>Client-go credential plugins can now be passed in the current cluster information via the KUBERNETES_EXEC_INFO environment variable. (<a href=https://github.com/kubernetes/kubernetes/pull/95489>#95489</a>, <a href=https://github.com/ankeesler>@ankeesler</a>) [SIG API Machinery and Auth]</p></li><li><p>Command to start network proxy changes from 'KUBE_ENABLE_EGRESS_VIA_KONNECTIVITY_SERVICE ./cluster/kube-up.sh' to 'KUBE_ENABLE_KONNECTIVITY_SERVICE=true ./hack/kube-up.sh' (<a href=https://github.com/kubernetes/kubernetes/pull/92669>#92669</a>, <a href=https://github.com/Jefftree>@Jefftree</a>) [SIG Cloud Provider]</p></li><li><p>Configure AWS LoadBalancer health check protocol via service annotations. (<a href=https://github.com/kubernetes/kubernetes/pull/94546>#94546</a>, <a href=https://github.com/kishorj>@kishorj</a>)</p></li><li><p>DefaultPodTopologySpread graduated to Beta. The feature gate is enabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/95631>#95631</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling and Testing]</p></li><li><p>E2e test for PodFsGroupChangePolicy (<a href=https://github.com/kubernetes/kubernetes/pull/96247>#96247</a>, <a href=https://github.com/saikat-royc>@saikat-royc</a>) [SIG Storage and Testing]</p></li><li><p>Ephemeral containers now apply the same API defaults as initContainers and containers (<a href=https://github.com/kubernetes/kubernetes/pull/94896>#94896</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Apps and CLI]</p></li><li><p>Gradudate the Pod Resources API to G.A
Introduces the pod_resources_endpoint_requests_total metric which tracks the total number of requests to the pod resources API (<a href=https://github.com/kubernetes/kubernetes/pull/92165>#92165</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>) [SIG Instrumentation, Node and Testing]</p></li><li><p>In dual-stack bare-metal clusters, you can now pass dual-stack IPs to <code>kubelet --node-ip</code>.
eg: <code>kubelet --node-ip 10.1.0.5,fd01::0005</code>. This is not yet supported for non-bare-metal
clusters.</p><p>In dual-stack clusters where nodes have dual-stack addresses, hostNetwork pods
will now get dual-stack PodIPs. (<a href=https://github.com/kubernetes/kubernetes/pull/95239>#95239</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Network and Node]</p></li><li><p>Introduce api-extensions category which will return: mutating admission configs, validating admission configs, CRDs and APIServices when used in kubectl get, for example. (<a href=https://github.com/kubernetes/kubernetes/pull/95603>#95603</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG API Machinery]</p></li><li><p>Introduces a new GCE specific cluster creation variable KUBE_PROXY_DISABLE. When set to true, this will skip over the creation of kube-proxy (whether the daemonset or static pod). This can be used to control the lifecycle of kube-proxy separately from the lifecycle of the nodes. (<a href=https://github.com/kubernetes/kubernetes/pull/91977>#91977</a>, <a href=https://github.com/varunmar>@varunmar</a>) [SIG Cloud Provider]</p></li><li><p>Kube-apiserver now maintains a Lease object to identify itself:</p><ul><li>The feature is under feature gate <code>APIServerIdentity</code>.</li><li>Two flags are added to kube-apiserver: <code>identity-lease-duration-seconds</code>, <code>identity-lease-renew-interval-seconds</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95533>#95533</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery]</li></ul></li><li><p>Kube-apiserver: The timeout used when making health check calls to etcd can now be configured with <code>--etcd-healthcheck-timeout</code>. The default timeout is 2 seconds, matching the previous behavior. (<a href=https://github.com/kubernetes/kubernetes/pull/93244>#93244</a>, <a href=https://github.com/Sh4d1>@Sh4d1</a>) [SIG API Machinery]</p></li><li><p>Kube-apiserver: added support for compressing rotated audit log files with <code>--audit-log-compress</code> (<a href=https://github.com/kubernetes/kubernetes/pull/94066>#94066</a>, <a href=https://github.com/lojies>@lojies</a>) [SIG API Machinery and Auth]</p></li><li><p>Kubeadm now prints warnings instead of throwing errors if the current system time is outside of the NotBefore and NotAfter bounds of a loaded certificate. (<a href=https://github.com/kubernetes/kubernetes/pull/94504>#94504</a>, <a href=https://github.com/neolit123>@neolit123</a>)</p></li><li><p>Kubeadm: Add a preflight check that the control-plane node has at least 1700MB of RAM (<a href=https://github.com/kubernetes/kubernetes/pull/93275>#93275</a>, <a href=https://github.com/xlgao-zju>@xlgao-zju</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: add the "--cluster-name" flag to the "kubeadm alpha kubeconfig user" to allow configuring the cluster name in the generated kubeconfig file (<a href=https://github.com/kubernetes/kubernetes/pull/93992>#93992</a>, <a href=https://github.com/prabhu43>@prabhu43</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: add the "--kubeconfig" flag to the "kubeadm init phase upload-certs" command to allow users to pass a custom location for a kubeconfig file. (<a href=https://github.com/kubernetes/kubernetes/pull/94765>#94765</a>, <a href=https://github.com/zhanw15>@zhanw15</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: make etcd pod request 100m CPU, 100Mi memory and 100Mi ephemeral_storage by default (<a href=https://github.com/kubernetes/kubernetes/pull/94479>#94479</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: make the command "kubeadm alpha kubeconfig user" accept a "--config" flag and remove the following flags:</p><ul><li>apiserver-advertise-address / apiserver-bind-port: use either localAPIEndpoint from InitConfiguration or controlPlaneEndpoint from ClusterConfiguration.</li><li>cluster-name: use clusterName from ClusterConfiguration</li><li>cert-dir: use certificatesDir from ClusterConfiguration (<a href=https://github.com/kubernetes/kubernetes/pull/94879>#94879</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cluster Lifecycle]</li></ul></li><li><p>Kubectl create now supports creating ingress objects. (<a href=https://github.com/kubernetes/kubernetes/pull/94327>#94327</a>, <a href=https://github.com/rikatz>@rikatz</a>) [SIG CLI and Network]</p></li><li><p>Kubectl rollout history sts/sts-name --revision=some-revision will start showing the detailed view of the sts on that specified revision (<a href=https://github.com/kubernetes/kubernetes/pull/86506>#86506</a>, <a href=https://github.com/dineshba>@dineshba</a>) [SIG CLI]</p></li><li><p>Kubectl: Previously users cannot provide arguments to a external diff tool via KUBECTL_EXTERNAL_DIFF env. This release now allow users to specify args to KUBECTL_EXTERNAL_DIFF env. (<a href=https://github.com/kubernetes/kubernetes/pull/95292>#95292</a>, <a href=https://github.com/dougsland>@dougsland</a>) [SIG CLI]</p></li><li><p>Kubemark now supports both real and hollow nodes in a single cluster. (<a href=https://github.com/kubernetes/kubernetes/pull/93201>#93201</a>, <a href=https://github.com/ellistarn>@ellistarn</a>) [SIG Scalability]</p></li><li><p>Kubernetes E2E test image manifest lists now contain Windows images. (<a href=https://github.com/kubernetes/kubernetes/pull/77398>#77398</a>, <a href=https://github.com/claudiubelu>@claudiubelu</a>) [SIG Testing and Windows]</p></li><li><p>Kubernetes is now built using go1.15.2</p><ul><li><p>build: Update to <a href=mailto:k/repo-infra@v0.1.1>k/repo-infra@v0.1.1</a> (supports go1.15.2)</p></li><li><p>build: Use go-runner:buster-v2.0.1 (built using go1.15.1)</p></li><li><p>bazel: Replace --features with Starlark build settings flag</p></li><li><p>hack/lib/util.sh: some bash cleanups</p><ul><li>switched one spot to use kube::logging</li><li>make kube::util::find-binary return an error when it doesn't find
anything so that hack scripts fail fast instead of with '' binary not
found errors.</li><li>this required deleting some genfeddoc stuff. the binary no longer
exists in k/k repo since we removed federation/, and I don't see it
in <a href=https://github.com/kubernetes-sigs/kubefed/>https://github.com/kubernetes-sigs/kubefed/</a> either. I'm assuming
that it's gone for good now.</li></ul></li><li><p>bazel: output go_binary rule directly from go_binary_conditional_pure</p><p>From: <a href=https://github.com/mikedanese>@mikedanese</a>:
Instead of aliasing. Aliases are annoying in a number of ways. This is
specifically bugging me now because they make the action graph harder to
analyze programmatically. By using aliases here, we would need to handle
potentially aliased go_binary targets and dereference to the effective
target.</p><p>The comment references an issue with <code>pure = select(...)</code> which appears
to be resolved considering this now builds.</p></li><li><p>make kube::util::find-binary not dependent on bazel-out/ structure</p><p>Implement an aspect that outputs go_build_mode metadata for go binaries,
and use that during binary selection. (<a href=https://github.com/kubernetes/kubernetes/pull/94449>#94449</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Architecture, CLI, Cluster Lifecycle, Node, Release and Testing]</p></li></ul></li><li><p>Kubernetes is now built using go1.15.5</p><ul><li>build: Update to <a href=mailto:k/repo-infra@v0.1.2>k/repo-infra@v0.1.2</a> (supports go1.15.5) (<a href=https://github.com/kubernetes/kubernetes/pull/95776>#95776</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Cloud Provider, Instrumentation, Release and Testing]</li></ul></li><li><p>New default scheduling plugins order reduces scheduling and preemption latency when taints and node affinity are used (<a href=https://github.com/kubernetes/kubernetes/pull/95539>#95539</a>, <a href=https://github.com/soulxu>@soulxu</a>) [SIG Scheduling]</p></li><li><p>Only update Azure data disks when attach/detach (<a href=https://github.com/kubernetes/kubernetes/pull/94265>#94265</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Promote SupportNodePidsLimit to GA to provide node-to-pod PID isolation.
Promote SupportPodPidsLimit to GA to provide ability to limit PIDs per pod. (<a href=https://github.com/kubernetes/kubernetes/pull/94140>#94140</a>, <a href=https://github.com/derekwaynecarr>@derekwaynecarr</a>)</p></li><li><p>SCTP support in API objects (Pod, Service, NetworkPolicy) is now GA.
Note that this has no effect on whether SCTP is enabled on nodes at the kernel level,
and note that some cloud platforms and network plugins do not support SCTP traffic. (<a href=https://github.com/kubernetes/kubernetes/pull/95566>#95566</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Apps and Network]</p></li><li><p>Scheduler now ignores Pod update events if the resourceVersion of old and new Pods are identical. (<a href=https://github.com/kubernetes/kubernetes/pull/96071>#96071</a>, <a href=https://github.com/Huang-Wei>@Huang-Wei</a>) [SIG Scheduling]</p></li><li><p>Scheduling Framework: expose Run[Pre]ScorePlugins functions to PreemptionHandle which can be used in PostFilter extention point. (<a href=https://github.com/kubernetes/kubernetes/pull/93534>#93534</a>, <a href=https://github.com/everpeace>@everpeace</a>) [SIG Scheduling and Testing]</p></li><li><p>SelectorSpreadPriority maps to PodTopologySpread plugin when DefaultPodTopologySpread feature is enabled (<a href=https://github.com/kubernetes/kubernetes/pull/95448>#95448</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</p></li><li><p>Send GCE node startup scripts logs to console and journal. (<a href=https://github.com/kubernetes/kubernetes/pull/95311>#95311</a>, <a href=https://github.com/karan>@karan</a>)</p></li><li><p>SetHostnameAsFQDN has been graduated to Beta and therefore it is enabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/95267>#95267</a>, <a href=https://github.com/javidiaz>@javidiaz</a>) [SIG Node]</p></li><li><p>Support [service.beta.kubernetes.io/azure-pip-ip-tags] annotations to allow customers to specify ip-tags to influence public-ip creation in Azure [Tag1=Value1, Tag2=Value2, etc.] (<a href=https://github.com/kubernetes/kubernetes/pull/94114>#94114</a>, <a href=https://github.com/MarcPow>@MarcPow</a>) [SIG Cloud Provider]</p></li><li><p>Support custom tags for cloud provider managed resources (<a href=https://github.com/kubernetes/kubernetes/pull/96450>#96450</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Support customize load balancer health probe protocol and request path (<a href=https://github.com/kubernetes/kubernetes/pull/96338>#96338</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Support for Windows container images (OS Versions: 1809, 1903, 1909, 2004) was added the pause:3.4 image. (<a href=https://github.com/kubernetes/kubernetes/pull/91452>#91452</a>, <a href=https://github.com/claudiubelu>@claudiubelu</a>) [SIG Node, Release and Windows]</p></li><li><p>Support multiple standard load balancers in one cluster (<a href=https://github.com/kubernetes/kubernetes/pull/96111>#96111</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>The beta <code>RootCAConfigMap</code> feature gate is enabled by default and causes kube-controller-manager to publish a "kube-root-ca.crt" ConfigMap to every namespace. This ConfigMap contains a CA bundle used for verifying connections to the kube-apiserver. (<a href=https://github.com/kubernetes/kubernetes/pull/96197>#96197</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Apps, Auth and Testing]</p></li><li><p>The kubelet_runtime_operations_duration_seconds metric buckets were set to 0.005 0.0125 0.03125 0.078125 0.1953125 0.48828125 1.220703125 3.0517578125 7.62939453125 19.073486328125 47.6837158203125 119.20928955078125 298.0232238769531 and 745.0580596923828 seconds (<a href=https://github.com/kubernetes/kubernetes/pull/96054>#96054</a>, <a href=https://github.com/alvaroaleman>@alvaroaleman</a>) [SIG Instrumentation and Node]</p></li><li><p>There is a new pv_collector_total_pv_count metric that counts persistent volumes by the volume plugin name and volume mode. (<a href=https://github.com/kubernetes/kubernetes/pull/95719>#95719</a>, <a href=https://github.com/tsmetana>@tsmetana</a>) [SIG Apps, Instrumentation, Storage and Testing]</p></li><li><p>Volume snapshot e2e test to validate PVC and VolumeSnapshotContent finalizer (<a href=https://github.com/kubernetes/kubernetes/pull/95863>#95863</a>, <a href=https://github.com/RaunakShah>@RaunakShah</a>) [SIG Cloud Provider, Storage and Testing]</p></li><li><p>Warns user when executing kubectl apply/diff to resource currently being deleted. (<a href=https://github.com/kubernetes/kubernetes/pull/95544>#95544</a>, <a href=https://github.com/SaiHarshaK>@SaiHarshaK</a>) [SIG CLI]</p></li><li><p><code>kubectl alpha debug</code> has graduated to beta and is now <code>kubectl debug</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/96138>#96138</a>, <a href=https://github.com/verb>@verb</a>) [SIG CLI and Testing]</p></li><li><p><code>kubectl debug</code> gains support for changing container images when copying a pod for debugging, similar to how <code>kubectl set image</code> works. See <code>kubectl help debug</code> for more information. (<a href=https://github.com/kubernetes/kubernetes/pull/96058>#96058</a>, <a href=https://github.com/verb>@verb</a>) [SIG CLI]</p></li></ul><h3 id=문서>문서</h3><ul><li>Fake dynamic client: document that List does not preserve TypeMeta in UnstructuredList (<a href=https://github.com/kubernetes/kubernetes/pull/95117>#95117</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG API Machinery]</li><li>Kubelet: remove alpha warnings for CNI flags. (<a href=https://github.com/kubernetes/kubernetes/pull/94508>#94508</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Network and Node]</li><li>Updates docs and guidance on cloud provider InstancesV2 and Zones interface for external cloud providers:<ul><li>removes experimental warning for InstancesV2</li><li>document that implementation of InstancesV2 will disable calls to Zones</li><li>deprecate Zones in favor of InstancesV2 (<a href=https://github.com/kubernetes/kubernetes/pull/96397>#96397</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Cloud Provider]</li></ul></li></ul><h3 id=실패-테스트>실패 테스트</h3><ul><li>Resolves an issue running Ingress conformance tests on clusters which use finalizers on Ingress objects to manage releasing load balancer resources (<a href=https://github.com/kubernetes/kubernetes/pull/96742>#96742</a>, <a href=https://github.com/spencerhance>@spencerhance</a>) [SIG Network and Testing]</li><li>The Conformance test "validates that there is no conflict between pods with same hostPort but different hostIP and protocol" now validates the connectivity to each hostPort, in addition to the functionality. (<a href=https://github.com/kubernetes/kubernetes/pull/96627>#96627</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Scheduling and Testing]</li></ul><h3 id=버그-또는-회귀-regression>버그 또는 회귀(regression)</h3><ul><li><p>Add kubectl wait --ignore-not-found flag (<a href=https://github.com/kubernetes/kubernetes/pull/90969>#90969</a>, <a href=https://github.com/zhouya0>@zhouya0</a>) [SIG CLI]</p></li><li><p>Added support to kube-proxy for externalTrafficPolicy=Local setting via Direct Server Return (DSR) load balancers on Windows. (<a href=https://github.com/kubernetes/kubernetes/pull/93166>#93166</a>, <a href=https://github.com/elweb9858>@elweb9858</a>) [SIG Network]</p></li><li><p>Alter wording to describe pods using a pvc (<a href=https://github.com/kubernetes/kubernetes/pull/95635>#95635</a>, <a href=https://github.com/RaunakShah>@RaunakShah</a>) [SIG CLI]</p></li><li><p>An issues preventing volume expand controller to annotate the PVC with <code>volume.kubernetes.io/storage-resizer</code> when the PVC StorageClass is already updated to the out-of-tree provisioner is now fixed. (<a href=https://github.com/kubernetes/kubernetes/pull/94489>#94489</a>, <a href=https://github.com/ialidzhikov>@ialidzhikov</a>) [SIG API Machinery, Apps and Storage]</p></li><li><p>Azure ARM client: don't segfault on empty response and http error (<a href=https://github.com/kubernetes/kubernetes/pull/94078>#94078</a>, <a href=https://github.com/bpineau>@bpineau</a>) [SIG Cloud Provider]</p></li><li><p>Azure armclient backoff step defaults to 1 (no retry). (<a href=https://github.com/kubernetes/kubernetes/pull/94180>#94180</a>, <a href=https://github.com/feiskyer>@feiskyer</a>)</p></li><li><p>Azure: fix a bug that kube-controller-manager would panic if wrong Azure VMSS name is configured (<a href=https://github.com/kubernetes/kubernetes/pull/94306>#94306</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cloud Provider]</p></li><li><p>Both apiserver_request_duration_seconds metrics and RequestReceivedTimestamp fields of an audit event now take into account the time a request spends in the apiserver request filters. (<a href=https://github.com/kubernetes/kubernetes/pull/94903>#94903</a>, <a href=https://github.com/tkashem>@tkashem</a>)</p></li><li><p>Build/lib/release: Explicitly use '--platform' in building server images</p><p>When we switched to go-runner for building the apiserver,
controller-manager, and scheduler server components, we no longer
reference the individual architectures in the image names, specifically
in the 'FROM' directive of the server image Dockerfiles.</p><p>As a result, server images for non-amd64 images copy in the go-runner
amd64 binary instead of the go-runner that matches that architecture.</p><p>This commit explicitly sets the '--platform=linux/${arch}' to ensure
we're pulling the correct go-runner arch from the manifest list.</p><p>Before:
<code>FROM ${base_image}</code></p><p>After:
<code>FROM --platform=linux/${arch} ${base_image}</code> (<a href=https://github.com/kubernetes/kubernetes/pull/94552>#94552</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Release]</p></li><li><p>Bump node-problem-detector version to v0.8.5 to fix OOM detection in with Linux kernels 5.1+ (<a href=https://github.com/kubernetes/kubernetes/pull/96716>#96716</a>, <a href=https://github.com/tosi3k>@tosi3k</a>) [SIG Cloud Provider, Scalability and Testing]</p></li><li><p>CSIDriver object can be deployed during volume attachment. (<a href=https://github.com/kubernetes/kubernetes/pull/93710>#93710</a>, <a href=https://github.com/Jiawei0227>@Jiawei0227</a>) [SIG Apps, Node, Storage and Testing]</p></li><li><p>Ceph RBD volume expansion now works even when ceph.conf was not provided. (<a href=https://github.com/kubernetes/kubernetes/pull/92027>#92027</a>, <a href=https://github.com/juliantaylor>@juliantaylor</a>)</p></li><li><p>Change plugin name in fsgroupapplymetrics of csi and flexvolume to distinguish different driver (<a href=https://github.com/kubernetes/kubernetes/pull/95892>#95892</a>, <a href=https://github.com/JornShen>@JornShen</a>) [SIG Instrumentation, Storage and Testing]</p></li><li><p>Change the calculation of pod UIDs so that static pods get a unique value - will cause all containers to be killed and recreated after in-place upgrade. (<a href=https://github.com/kubernetes/kubernetes/pull/87461>#87461</a>, <a href=https://github.com/bboreham>@bboreham</a>) [SIG Node]</p></li><li><p>Change the mount way from systemd to normal mount except ceph and glusterfs intree-volume. (<a href=https://github.com/kubernetes/kubernetes/pull/94916>#94916</a>, <a href=https://github.com/smileusd>@smileusd</a>) [SIG Apps, Cloud Provider, Network, Node, Storage and Testing]</p></li><li><p>Changes to timeout parameter handling in 1.20.0-beta.2 have been reverted to avoid breaking backwards compatibility with existing clients. (<a href=https://github.com/kubernetes/kubernetes/pull/96727>#96727</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and Testing]</p></li><li><p>Clear UDP conntrack entry on endpoint changes when using nodeport (<a href=https://github.com/kubernetes/kubernetes/pull/71573>#71573</a>, <a href=https://github.com/JacobTanenbaum>@JacobTanenbaum</a>) [SIG Network]</p></li><li><p>Cloud node controller: handle empty providerID from getProviderID (<a href=https://github.com/kubernetes/kubernetes/pull/95342>#95342</a>, <a href=https://github.com/nicolehanjing>@nicolehanjing</a>) [SIG Cloud Provider]</p></li><li><p>Disable watchcache for events (<a href=https://github.com/kubernetes/kubernetes/pull/96052>#96052</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery]</p></li><li><p>Disabled <code>LocalStorageCapacityIsolation</code> feature gate is honored during scheduling. (<a href=https://github.com/kubernetes/kubernetes/pull/96092>#96092</a>, <a href=https://github.com/Huang-Wei>@Huang-Wei</a>) [SIG Scheduling]</p></li><li><p>Do not fail sorting empty elements. (<a href=https://github.com/kubernetes/kubernetes/pull/94666>#94666</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG CLI]</p></li><li><p>Dual-stack: make nodeipam compatible with existing single-stack clusters when dual-stack feature gate become enabled by default (<a href=https://github.com/kubernetes/kubernetes/pull/90439>#90439</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG API Machinery]</p></li><li><p>Duplicate owner reference entries in create/update/patch requests now get deduplicated by the API server. The client sending the request now receives a warning header in the API response. Clients should stop sending requests with duplicate owner references. The API server may reject such requests as early as 1.24. (<a href=https://github.com/kubernetes/kubernetes/pull/96185>#96185</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery and Testing]</p></li><li><p>Endpoint slice controller now mirrors parent's service label to its corresponding endpoint slices. (<a href=https://github.com/kubernetes/kubernetes/pull/94443>#94443</a>, <a href=https://github.com/aojea>@aojea</a>)</p></li><li><p>Ensure getPrimaryInterfaceID not panic when network interfaces for Azure VMSS are null (<a href=https://github.com/kubernetes/kubernetes/pull/94355>#94355</a>, <a href=https://github.com/feiskyer>@feiskyer</a>) [SIG Cloud Provider]</p></li><li><p>Exposes and sets a default timeout for the SubjectAccessReview client for DelegatingAuthorizationOptions (<a href=https://github.com/kubernetes/kubernetes/pull/95725>#95725</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery and Cloud Provider]</p></li><li><p>Exposes and sets a default timeout for the TokenReview client for DelegatingAuthenticationOptions (<a href=https://github.com/kubernetes/kubernetes/pull/96217>#96217</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery and Cloud Provider]</p></li><li><p>Fix CVE-2020-8555 for Quobyte client connections. (<a href=https://github.com/kubernetes/kubernetes/pull/95206>#95206</a>, <a href=https://github.com/misterikkit>@misterikkit</a>) [SIG Storage]</p></li><li><p>Fix IP fragmentation of UDP and TCP packets not supported issues on LoadBalancer rules (<a href=https://github.com/kubernetes/kubernetes/pull/96464>#96464</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Fix a bug that DefaultPreemption plugin is disabled when using (legacy) scheduler policy. (<a href=https://github.com/kubernetes/kubernetes/pull/96439>#96439</a>, <a href=https://github.com/Huang-Wei>@Huang-Wei</a>) [SIG Scheduling and Testing]</p></li><li><p>Fix a bug where loadbalancer deletion gets stuck because of missing resource group. (<a href=https://github.com/kubernetes/kubernetes/pull/93962>#93962</a>, <a href=https://github.com/phiphi282>@phiphi282</a>)</p></li><li><p>Fix a concurrent map writes error in kubelet (<a href=https://github.com/kubernetes/kubernetes/pull/93773>#93773</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Node]</p></li><li><p>Fix a panic in <code>kubectl debug</code> when a pod has multiple init or ephemeral containers. (<a href=https://github.com/kubernetes/kubernetes/pull/94580>#94580</a>, <a href=https://github.com/kiyoshim55>@kiyoshim55</a>)</p></li><li><p>Fix a regression where kubeadm bails out with a fatal error when an optional version command line argument is supplied to the "kubeadm upgrade plan" command (<a href=https://github.com/kubernetes/kubernetes/pull/94421>#94421</a>, <a href=https://github.com/rosti>@rosti</a>) [SIG Cluster Lifecycle]</p></li><li><p>Fix azure disk attach failure for disk size bigger than 4TB (<a href=https://github.com/kubernetes/kubernetes/pull/95463>#95463</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix azure disk data loss issue on Windows when unmount disk (<a href=https://github.com/kubernetes/kubernetes/pull/95456>#95456</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Fix azure file migration panic (<a href=https://github.com/kubernetes/kubernetes/pull/94853>#94853</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix bug in JSON path parser where an error occurs when a range is empty (<a href=https://github.com/kubernetes/kubernetes/pull/95933>#95933</a>, <a href=https://github.com/brianpursley>@brianpursley</a>) [SIG API Machinery]</p></li><li><p>Fix client-go prometheus metrics to correctly present the API path accessed in some environments. (<a href=https://github.com/kubernetes/kubernetes/pull/74363>#74363</a>, <a href=https://github.com/aanm>@aanm</a>) [SIG API Machinery]</p></li><li><p>Fix detach azure disk issue when vm not exist (<a href=https://github.com/kubernetes/kubernetes/pull/95177>#95177</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix etcd_object_counts metric reported by kube-apiserver (<a href=https://github.com/kubernetes/kubernetes/pull/94773>#94773</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery]</p></li><li><p>Fix incorrectly reported verbs for kube-apiserver metrics for CRD objects (<a href=https://github.com/kubernetes/kubernetes/pull/93523>#93523</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Instrumentation]</p></li><li><p>Fix k8s.io/apimachinery/pkg/api/meta.SetStatusCondition to update ObservedGeneration (<a href=https://github.com/kubernetes/kubernetes/pull/95961>#95961</a>, <a href=https://github.com/KnicKnic>@KnicKnic</a>) [SIG API Machinery]</p></li><li><p>Fix kubectl SchemaError on CRDs with schema using x-kubernetes-preserve-unknown-fields on array types. (<a href=https://github.com/kubernetes/kubernetes/pull/94888>#94888</a>, <a href=https://github.com/sttts>@sttts</a>) [SIG API Machinery]</p></li><li><p>Fix memory leak in kube-apiserver when underlying time goes forth and back. (<a href=https://github.com/kubernetes/kubernetes/pull/96266>#96266</a>, <a href=https://github.com/chenyw1990>@chenyw1990</a>) [SIG API Machinery]</p></li><li><p>Fix missing csi annotations on node during parallel csinode update. (<a href=https://github.com/kubernetes/kubernetes/pull/94389>#94389</a>, <a href=https://github.com/pacoxu>@pacoxu</a>) [SIG Storage]</p></li><li><p>Fix network_programming_latency metric reporting for Endpoints/EndpointSlice deletions, where we don't have correct timestamp (<a href=https://github.com/kubernetes/kubernetes/pull/95363>#95363</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG Network and Scalability]</p></li><li><p>Fix paging issues when Azure API returns empty values with non-empty nextLink (<a href=https://github.com/kubernetes/kubernetes/pull/96211>#96211</a>, <a href=https://github.com/feiskyer>@feiskyer</a>) [SIG Cloud Provider]</p></li><li><p>Fix pull image error from multiple ACRs using azure managed identity (<a href=https://github.com/kubernetes/kubernetes/pull/96355>#96355</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix race condition on timeCache locks. (<a href=https://github.com/kubernetes/kubernetes/pull/94751>#94751</a>, <a href=https://github.com/auxten>@auxten</a>)</p></li><li><p>Fix regression on <code>kubectl portforward</code> when TCP and UCP services were configured on the same port. (<a href=https://github.com/kubernetes/kubernetes/pull/94728>#94728</a>, <a href=https://github.com/amorenoz>@amorenoz</a>)</p></li><li><p>Fix scheduler cache snapshot when a Node is deleted before its Pods (<a href=https://github.com/kubernetes/kubernetes/pull/95130>#95130</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</p></li><li><p>Fix the <code>cloudprovider_azure_api_request_duration_seconds</code> metric buckets to correctly capture the latency metrics. Previously, the majority of the calls would fall in the "+Inf" bucket. (<a href=https://github.com/kubernetes/kubernetes/pull/94873>#94873</a>, <a href=https://github.com/marwanad>@marwanad</a>) [SIG Cloud Provider and Instrumentation]</p></li><li><p>Fix vSphere volumes that could be erroneously attached to wrong node (<a href=https://github.com/kubernetes/kubernetes/pull/96224>#96224</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Fix verb & scope reporting for kube-apiserver metrics (LIST reported instead of GET) (<a href=https://github.com/kubernetes/kubernetes/pull/95562>#95562</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Testing]</p></li><li><p>Fix vsphere detach failure for static PVs (<a href=https://github.com/kubernetes/kubernetes/pull/95447>#95447</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Fix: azure disk resize error if source does not exist (<a href=https://github.com/kubernetes/kubernetes/pull/93011>#93011</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix: detach azure disk broken on Azure Stack (<a href=https://github.com/kubernetes/kubernetes/pull/94885>#94885</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix: resize Azure disk issue when it's in attached state (<a href=https://github.com/kubernetes/kubernetes/pull/96705>#96705</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix: smb valid path error (<a href=https://github.com/kubernetes/kubernetes/pull/95583>#95583</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Storage]</p></li><li><p>Fix: use sensitiveOptions on Windows mount (<a href=https://github.com/kubernetes/kubernetes/pull/94126>#94126</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Fixed a bug causing incorrect formatting of <code>kubectl describe ingress</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/94985>#94985</a>, <a href=https://github.com/howardjohn>@howardjohn</a>) [SIG CLI and Network]</p></li><li><p>Fixed a bug in client-go where new clients with customized <code>Dial</code>, <code>Proxy</code>, <code>GetCert</code> config may get stale HTTP transports. (<a href=https://github.com/kubernetes/kubernetes/pull/95427>#95427</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery]</p></li><li><p>Fixed a bug that prevents kubectl to validate CRDs with schema using x-kubernetes-preserve-unknown-fields on object fields. (<a href=https://github.com/kubernetes/kubernetes/pull/96369>#96369</a>, <a href=https://github.com/gautierdelorme>@gautierdelorme</a>) [SIG API Machinery and Testing]</p></li><li><p>Fixed a bug that prevents the use of ephemeral containers in the presence of a validating admission webhook. (<a href=https://github.com/kubernetes/kubernetes/pull/94685>#94685</a>, <a href=https://github.com/verb>@verb</a>) [SIG Node and Testing]</p></li><li><p>Fixed a bug where aggregator_unavailable_apiservice metrics were reported for deleted apiservices. (<a href=https://github.com/kubernetes/kubernetes/pull/96421>#96421</a>, <a href=https://github.com/dgrisonnet>@dgrisonnet</a>) [SIG API Machinery and Instrumentation]</p></li><li><p>Fixed a bug where improper storage and comparison of endpoints led to excessive API traffic from the endpoints controller (<a href=https://github.com/kubernetes/kubernetes/pull/94112>#94112</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Apps, Network and Testing]</p></li><li><p>Fixed a regression which prevented pods with <code>docker/default</code> seccomp annotations from being created in 1.19 if a PodSecurityPolicy was in place which did not allow <code>runtime/default</code> seccomp profiles. (<a href=https://github.com/kubernetes/kubernetes/pull/95985>#95985</a>, <a href=https://github.com/saschagrunert>@saschagrunert</a>) [SIG Auth]</p></li><li><p>Fixed bug in reflector that couldn't recover from "Too large resource version" errors with API servers 1.17.0-1.18.5 (<a href=https://github.com/kubernetes/kubernetes/pull/94316>#94316</a>, <a href=https://github.com/janeczku>@janeczku</a>) [SIG API Machinery]</p></li><li><p>Fixed bug where kubectl top pod output is not sorted when --sort-by and --containers flags are used together (<a href=https://github.com/kubernetes/kubernetes/pull/93692>#93692</a>, <a href=https://github.com/brianpursley>@brianpursley</a>) [SIG CLI]</p></li><li><p>Fixed kubelet creating extra sandbox for pods with RestartPolicyOnFailure after all containers succeeded (<a href=https://github.com/kubernetes/kubernetes/pull/92614>#92614</a>, <a href=https://github.com/tnqn>@tnqn</a>) [SIG Node and Testing]</p></li><li><p>Fixes an issue proxying to ipv6 pods without specifying a port (<a href=https://github.com/kubernetes/kubernetes/pull/94834>#94834</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and Network]</p></li><li><p>Fixes code generation for non-namespaced create subresources fake client test. (<a href=https://github.com/kubernetes/kubernetes/pull/96586>#96586</a>, <a href=https://github.com/Doude>@Doude</a>) [SIG API Machinery]</p></li><li><p>Fixes high CPU usage in kubectl drain (<a href=https://github.com/kubernetes/kubernetes/pull/95260>#95260</a>, <a href=https://github.com/amandahla>@amandahla</a>) [SIG CLI]</p></li><li><p>For vSphere Cloud Provider, If VM of worker node is deleted, the node will also be deleted by node controller (<a href=https://github.com/kubernetes/kubernetes/pull/92608>#92608</a>, <a href=https://github.com/lubronzhan>@lubronzhan</a>) [SIG Cloud Provider]</p></li><li><p>Gracefully delete nodes when their parent scale set went missing (<a href=https://github.com/kubernetes/kubernetes/pull/95289>#95289</a>, <a href=https://github.com/bpineau>@bpineau</a>) [SIG Cloud Provider]</p></li><li><p>HTTP/2 connection health check is enabled by default in all Kubernetes clients. The feature should work out-of-the-box. If needed, users can tune the feature via the HTTP2_READ_IDLE_TIMEOUT_SECONDS and HTTP2_PING_TIMEOUT_SECONDS environment variables. The feature is disabled if HTTP2_READ_IDLE_TIMEOUT_SECONDS is set to 0. (<a href=https://github.com/kubernetes/kubernetes/pull/95981>#95981</a>, <a href=https://github.com/caesarxuchao>@caesarxuchao</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation and Node]</p></li><li><p>If the user specifies an invalid timeout in the request URL, the request will be aborted with an HTTP 400.</p><ul><li>If the user specifies a timeout in the request URL that exceeds the maximum request deadline allowed by the apiserver, the request will be aborted with an HTTP 400. (<a href=https://github.com/kubernetes/kubernetes/pull/96061>#96061</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery, Network and Testing]</li></ul></li><li><p>If we set SelectPolicy MinPolicySelect on scaleUp behavior or scaleDown behavior,Horizontal Pod Autoscaler doesn`t automatically scale the number of pods correctly (<a href=https://github.com/kubernetes/kubernetes/pull/95647>#95647</a>, <a href=https://github.com/JoshuaAndrew>@JoshuaAndrew</a>) [SIG Apps and Autoscaling]</p></li><li><p>Ignore apparmor for non-linux operating systems (<a href=https://github.com/kubernetes/kubernetes/pull/93220>#93220</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node and Windows]</p></li><li><p>Ignore root user check when windows pod starts (<a href=https://github.com/kubernetes/kubernetes/pull/92355>#92355</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node and Windows]</p></li><li><p>Improve error messages related to nodePort endpoint changes conntrack entries cleanup. (<a href=https://github.com/kubernetes/kubernetes/pull/96251>#96251</a>, <a href=https://github.com/ravens>@ravens</a>) [SIG Network]</p></li><li><p>In dual-stack clusters, kubelet will now set up both IPv4 and IPv6 iptables rules, which may
fix some problems, eg with HostPorts. (<a href=https://github.com/kubernetes/kubernetes/pull/94474>#94474</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Network and Node]</p></li><li><p>Increase maximum IOPS of AWS EBS io1 volume to current maximum (64,000). (<a href=https://github.com/kubernetes/kubernetes/pull/90014>#90014</a>, <a href=https://github.com/jacobmarble>@jacobmarble</a>)</p></li><li><p>Ipvs: ensure selected scheduler kernel modules are loaded (<a href=https://github.com/kubernetes/kubernetes/pull/93040>#93040</a>, <a href=https://github.com/cmluciano>@cmluciano</a>) [SIG Network]</p></li><li><p>K8s.io/apimachinery: runtime.DefaultUnstructuredConverter.FromUnstructured now handles converting integer fields to typed float values (<a href=https://github.com/kubernetes/kubernetes/pull/93250>#93250</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery]</p></li><li><p>Kube-proxy now trims extra spaces found in loadBalancerSourceRanges to match Service validation. (<a href=https://github.com/kubernetes/kubernetes/pull/94107>#94107</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Network]</p></li><li><p>Kubeadm ensures "kubeadm reset" does not unmount the root "/var/lib/kubelet" directory if it is mounted by the user. (<a href=https://github.com/kubernetes/kubernetes/pull/93702>#93702</a>, <a href=https://github.com/thtanaka>@thtanaka</a>)</p></li><li><p>Kubeadm now makes sure the etcd manifest is regenerated upon upgrade even when no etcd version change takes place (<a href=https://github.com/kubernetes/kubernetes/pull/94395>#94395</a>, <a href=https://github.com/rosti>@rosti</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm now warns (instead of error out) on missing "ca.key" files for root CA, front-proxy CA and etcd CA, during "kubeadm join --control-plane" if the user has provided all certificates, keys and kubeconfig files which require signing with the given CA keys. (<a href=https://github.com/kubernetes/kubernetes/pull/94988>#94988</a>, <a href=https://github.com/neolit123>@neolit123</a>)</p></li><li><p>Kubeadm: add missing "--experimental-patches" flag to "kubeadm init phase control-plane" (<a href=https://github.com/kubernetes/kubernetes/pull/95786>#95786</a>, <a href=https://github.com/Sh4d1>@Sh4d1</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: avoid a panic when determining if the running version of CoreDNS is supported during upgrades (<a href=https://github.com/kubernetes/kubernetes/pull/94299>#94299</a>, <a href=https://github.com/zouyee>@zouyee</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: ensure the etcd data directory is created with 0700 permissions during control-plane init and join (<a href=https://github.com/kubernetes/kubernetes/pull/94102>#94102</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: fix coredns migration should be triggered when there are newdefault configs during kubeadm upgrade (<a href=https://github.com/kubernetes/kubernetes/pull/96907>#96907</a>, <a href=https://github.com/pacoxu>@pacoxu</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: fix the bug that kubeadm tries to call 'docker info' even if the CRI socket was for another CR (<a href=https://github.com/kubernetes/kubernetes/pull/94555>#94555</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: for Docker as the container runtime, make the "kubeadm reset" command stop containers before removing them (<a href=https://github.com/kubernetes/kubernetes/pull/94586>#94586</a>, <a href=https://github.com/BedivereZero>@BedivereZero</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: make the kubeconfig files for the kube-controller-manager and kube-scheduler use the LocalAPIEndpoint instead of the ControlPlaneEndpoint. This makes kubeadm clusters more reseliant to version skew problems during immutable upgrades: <a href=https://kubernetes.io/docs/setup/release/version-skew-policy/#kube-controller-manager-kube-scheduler-and-cloud-controller-manager>https://kubernetes.io/docs/setup/release/version-skew-policy/#kube-controller-manager-kube-scheduler-and-cloud-controller-manager</a> (<a href=https://github.com/kubernetes/kubernetes/pull/94398>#94398</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: relax the validation of kubeconfig server URLs. Allow the user to define custom kubeconfig server URLs without erroring out during validation of existing kubeconfig files (e.g. when using external CA mode). (<a href=https://github.com/kubernetes/kubernetes/pull/94816>#94816</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubectl: print error if users place flags before plugin name (<a href=https://github.com/kubernetes/kubernetes/pull/92343>#92343</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG CLI]</p></li><li><p>Kubelet: assume that swap is disabled when <code>/proc/swaps</code> does not exist (<a href=https://github.com/kubernetes/kubernetes/pull/93931>#93931</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG Node]</p></li><li><p>New Azure instance types do now have correct max data disk count information. (<a href=https://github.com/kubernetes/kubernetes/pull/94340>#94340</a>, <a href=https://github.com/ialidzhikov>@ialidzhikov</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Port mapping now allows the same <code>containerPort</code> of different containers to different <code>hostPort</code> without naming the mapping explicitly. (<a href=https://github.com/kubernetes/kubernetes/pull/94494>#94494</a>, <a href=https://github.com/SergeyKanzhelev>@SergeyKanzhelev</a>)</p></li><li><p>Print go stack traces at -v=4 and not -v=2 (<a href=https://github.com/kubernetes/kubernetes/pull/94663>#94663</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG CLI]</p></li><li><p>Recreate EndpointSlices on rapid Service creation. (<a href=https://github.com/kubernetes/kubernetes/pull/94730>#94730</a>, <a href=https://github.com/robscott>@robscott</a>)</p></li><li><p>Reduce volume name length for vsphere volumes (<a href=https://github.com/kubernetes/kubernetes/pull/96533>#96533</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Storage]</p></li><li><p>Remove ready file and its directory (which is created during volume SetUp) during emptyDir volume TearDown. (<a href=https://github.com/kubernetes/kubernetes/pull/95770>#95770</a>, <a href=https://github.com/jingxu97>@jingxu97</a>) [SIG Storage]</p></li><li><p>Reorganized iptables rules to fix a performance issue (<a href=https://github.com/kubernetes/kubernetes/pull/95252>#95252</a>, <a href=https://github.com/tssurya>@tssurya</a>) [SIG Network]</p></li><li><p>Require feature flag CustomCPUCFSQuotaPeriod if setting a non-default cpuCFSQuotaPeriod in kubelet config. (<a href=https://github.com/kubernetes/kubernetes/pull/94687>#94687</a>, <a href=https://github.com/karan>@karan</a>) [SIG Node]</p></li><li><p>Resolves a regression in 1.19+ with workloads targeting deprecated beta os/arch labels getting stuck in NodeAffinity status on node startup. (<a href=https://github.com/kubernetes/kubernetes/pull/96810>#96810</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG Node]</p></li><li><p>Resolves non-deterministic behavior of the garbage collection controller when ownerReferences with incorrect data are encountered. Events with a reason of <code>OwnerRefInvalidNamespace</code> are recorded when namespace mismatches between child and owner objects are detected. The <a href=https://github.com/kubernetes-sigs/kubectl-check-ownerreferences>kubectl-check-ownerreferences</a> tool can be run prior to upgrading to locate existing objects with invalid ownerReferences.</p><ul><li>A namespaced object with an ownerReference referencing a uid of a namespaced kind which does not exist in the same namespace is now consistently treated as though that owner does not exist, and the child object is deleted.</li><li>A cluster-scoped object with an ownerReference referencing a uid of a namespaced kind is now consistently treated as though that owner is not resolvable, and the child object is ignored by the garbage collector. (<a href=https://github.com/kubernetes/kubernetes/pull/92743>#92743</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery, Apps and Testing]</li></ul></li><li><p>Skip [k8s.io/kubernetes@v1.19.0/test/e2e/storage/testsuites/base.go:162]: Driver azure-disk doesn't support snapshot type DynamicSnapshot -- skipping
skip [k8s.io/kubernetes@v1.19.0/test/e2e/storage/testsuites/base.go:185]: Driver azure-disk doesn't support ntfs -- skipping (<a href=https://github.com/kubernetes/kubernetes/pull/96144>#96144</a>, <a href=https://github.com/qinpingli>@qinpingli</a>) [SIG Storage and Testing]</p></li><li><p>StatefulSet Controller now waits for PersistentVolumeClaim deletion before creating pods. (<a href=https://github.com/kubernetes/kubernetes/pull/93457>#93457</a>, <a href=https://github.com/ymmt2005>@ymmt2005</a>)</p></li><li><p>StreamWatcher now calls HandleCrash at appropriate sequence. (<a href=https://github.com/kubernetes/kubernetes/pull/93108>#93108</a>, <a href=https://github.com/lixiaobing1>@lixiaobing1</a>)</p></li><li><p>Support the node label <code>node.kubernetes.io/exclude-from-external-load-balancers</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95542>#95542</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>The AWS network load balancer attributes can now be specified during service creation (<a href=https://github.com/kubernetes/kubernetes/pull/95247>#95247</a>, <a href=https://github.com/kishorj>@kishorj</a>) [SIG Cloud Provider]</p></li><li><p>The <code>/debug/api_priority_and_fairness/dump_requests</code> path at an apiserver will no longer return a phantom line for each exempt priority level. (<a href=https://github.com/kubernetes/kubernetes/pull/93406>#93406</a>, <a href=https://github.com/MikeSpreitzer>@MikeSpreitzer</a>) [SIG API Machinery]</p></li><li><p>The kube-apiserver will no longer serve APIs that should have been deleted in GA non-alpha levels. Alpha levels will continue to serve the removed APIs so that CI doesn't immediately break. (<a href=https://github.com/kubernetes/kubernetes/pull/96525>#96525</a>, <a href=https://github.com/deads2k>@deads2k</a>) [SIG API Machinery]</p></li><li><p>The kubelet recognizes the --containerd-namespace flag to configure the namespace used by cadvisor. (<a href=https://github.com/kubernetes/kubernetes/pull/87054>#87054</a>, <a href=https://github.com/changyaowei>@changyaowei</a>) [SIG Node]</p></li><li><p>Unhealthy pods covered by PDBs can be successfully evicted if enough healthy pods are available. (<a href=https://github.com/kubernetes/kubernetes/pull/94381>#94381</a>, <a href=https://github.com/michaelgugino>@michaelgugino</a>) [SIG Apps]</p></li><li><p>Update Calico to v3.15.2 (<a href=https://github.com/kubernetes/kubernetes/pull/94241>#94241</a>, <a href=https://github.com/lmm>@lmm</a>) [SIG Cloud Provider]</p></li><li><p>Update default etcd server version to 3.4.13 (<a href=https://github.com/kubernetes/kubernetes/pull/94287>#94287</a>, <a href=https://github.com/jingyih>@jingyih</a>) [SIG API Machinery, Cloud Provider, Cluster Lifecycle and Testing]</p></li><li><p>Update max azure data disk count map (<a href=https://github.com/kubernetes/kubernetes/pull/96308>#96308</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Update the PIP when it is not in the Succeeded provisioning state during the LB update. (<a href=https://github.com/kubernetes/kubernetes/pull/95748>#95748</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Update the frontend IP config when the service's <code>pipName</code> annotation is changed (<a href=https://github.com/kubernetes/kubernetes/pull/95813>#95813</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Update the route table tag in the route reconcile loop (<a href=https://github.com/kubernetes/kubernetes/pull/96545>#96545</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Use NLB Subnet CIDRs instead of VPC CIDRs in Health Check SG Rules (<a href=https://github.com/kubernetes/kubernetes/pull/93515>#93515</a>, <a href=https://github.com/t0rr3sp3dr0>@t0rr3sp3dr0</a>) [SIG Cloud Provider]</p></li><li><p>Users will see increase in time for deletion of pods and also guarantee that removal of pod from api server would mean deletion of all the resources from container runtime. (<a href=https://github.com/kubernetes/kubernetes/pull/92817>#92817</a>, <a href=https://github.com/kmala>@kmala</a>) [SIG Node]</p></li><li><p>Very large patches may now be specified to <code>kubectl patch</code> with the <code>--patch-file</code> flag instead of including them directly on the command line. The <code>--patch</code> and <code>--patch-file</code> flags are mutually exclusive. (<a href=https://github.com/kubernetes/kubernetes/pull/93548>#93548</a>, <a href=https://github.com/smarterclayton>@smarterclayton</a>) [SIG CLI]</p></li><li><p>Volume binding: report UnschedulableAndUnresolvable status instead of an error when bound PVs not found (<a href=https://github.com/kubernetes/kubernetes/pull/95541>#95541</a>, <a href=https://github.com/cofyc>@cofyc</a>) [SIG Apps, Scheduling and Storage]</p></li><li><p>Warn instead of fail when creating Roles and ClusterRoles with custom verbs via kubectl (<a href=https://github.com/kubernetes/kubernetes/pull/92492>#92492</a>, <a href=https://github.com/eddiezane>@eddiezane</a>) [SIG CLI]</p></li><li><p>When creating a PVC with the volume.beta.kubernetes.io/storage-provisioner annotation already set, the PV controller might have incorrectly deleted the newly provisioned PV instead of binding it to the PVC, depending on timing and system load. (<a href=https://github.com/kubernetes/kubernetes/pull/95909>#95909</a>, <a href=https://github.com/pohly>@pohly</a>) [SIG Apps and Storage]</p></li><li><p>[kubectl] Fail when local source file doesn't exist (<a href=https://github.com/kubernetes/kubernetes/pull/90333>#90333</a>, <a href=https://github.com/bamarni>@bamarni</a>) [SIG CLI]</p></li></ul><h3 id=기타-정리-또는-플레이크-flake>기타 (정리 또는 플레이크(flake))</h3><ul><li><p><strong>Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.</strong>:</p>([#96443](https://github.com/kubernetes/kubernetes/pull/96443), [@alaypatel07](https://github.com/alaypatel07)) [SIG Apps]</li><li><p>--redirect-container-streaming is no longer functional. The flag will be removed in v1.22 (<a href=https://github.com/kubernetes/kubernetes/pull/95935>#95935</a>, <a href=https://github.com/tallclair>@tallclair</a>) [SIG Node]</p></li><li><p>A new metric <code>requestAbortsTotal</code> has been introduced that counts aborted requests for each <code>group</code>, <code>version</code>, <code>verb</code>, <code>resource</code>, <code>subresource</code> and <code>scope</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/95002>#95002</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery, Cloud Provider, Instrumentation and Scheduling]</p></li><li><p>API priority and fairness metrics use snake_case in label names (<a href=https://github.com/kubernetes/kubernetes/pull/96236>#96236</a>, <a href=https://github.com/adtac>@adtac</a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Testing]</p></li><li><p>Add fine grained debugging to intra-pod conformance test to troubleshoot networking issues for potentially unhealthy nodes when running conformance or sonobuoy tests. (<a href=https://github.com/kubernetes/kubernetes/pull/93837>#93837</a>, <a href=https://github.com/jayunit100>@jayunit100</a>)</p></li><li><p>Add the following metrics:</p><ul><li>network_plugin_operations_total</li><li>network_plugin_operations_errors_total (<a href=https://github.com/kubernetes/kubernetes/pull/93066>#93066</a>, <a href=https://github.com/AnishShah>@AnishShah</a>)</li></ul></li><li><p>Adds a bootstrapping ClusterRole, ClusterRoleBinding and group for /metrics, /livez/<em>, /readyz/</em>, & /healthz/- endpoints. (<a href=https://github.com/kubernetes/kubernetes/pull/93311>#93311</a>, <a href=https://github.com/logicalhan>@logicalhan</a>) [SIG API Machinery, Auth, Cloud Provider and Instrumentation]</p></li><li><p>AdmissionReview objects sent for the creation of Namespace API objects now populate the <code>namespace</code> attribute consistently (previously the <code>namespace</code> attribute was empty for Namespace creation via POST requests, and populated for Namespace creation via server-side-apply PATCH requests) (<a href=https://github.com/kubernetes/kubernetes/pull/95012>#95012</a>, <a href=https://github.com/nodo>@nodo</a>) [SIG API Machinery and Testing]</p></li><li><p>Applies translations on all command descriptions (<a href=https://github.com/kubernetes/kubernetes/pull/95439>#95439</a>, <a href=https://github.com/HerrNaN>@HerrNaN</a>) [SIG CLI]</p></li><li><p>Base-images: Update to debian-iptables:buster-v1.3.0</p><ul><li>Uses iptables 1.8.5</li><li>base-images: Update to debian-base:buster-v1.2.0</li><li>cluster/images/etcd: Build etcd:3.4.13-1 image<ul><li>Uses debian-base:buster-v1.2.0 (<a href=https://github.com/kubernetes/kubernetes/pull/94733>#94733</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG API Machinery, Release and Testing]</li></ul></li></ul></li><li><p>Changed: default "Accept-Encoding" header removed from HTTP probes. See <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes>https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes</a> (<a href=https://github.com/kubernetes/kubernetes/pull/96127>#96127</a>, <a href=https://github.com/fonsecas72>@fonsecas72</a>) [SIG Network and Node]</p></li><li><p>Client-go header logging (at verbosity levels >= 9) now masks <code>Authorization</code> header contents (<a href=https://github.com/kubernetes/kubernetes/pull/95316>#95316</a>, <a href=https://github.com/sfowl>@sfowl</a>) [SIG API Machinery]</p></li><li><p>Decrease warning message frequency on setting volume ownership for configmap/secret. (<a href=https://github.com/kubernetes/kubernetes/pull/92878>#92878</a>, <a href=https://github.com/jvanz>@jvanz</a>)</p></li><li><p>Enhance log information of verifyRunAsNonRoot, add pod, container information (<a href=https://github.com/kubernetes/kubernetes/pull/94911>#94911</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node]</p></li><li><p>Fix func name NewCreateCreateDeploymentOptions (<a href=https://github.com/kubernetes/kubernetes/pull/91931>#91931</a>, <a href=https://github.com/lixiaobing1>@lixiaobing1</a>) [SIG CLI]</p></li><li><p>Fix kubelet to properly log when a container is started. Previously, kubelet may log that container is dead and was restarted when it was actually started for the first time. This behavior only happened on pods with initContainers and regular containers. (<a href=https://github.com/kubernetes/kubernetes/pull/91469>#91469</a>, <a href=https://github.com/rata>@rata</a>)</p></li><li><p>Fixes the message about no auth for metrics in scheduler. (<a href=https://github.com/kubernetes/kubernetes/pull/94035>#94035</a>, <a href=https://github.com/zhouya0>@zhouya0</a>) [SIG Scheduling]</p></li><li><p>Generators for services are removed from kubectl (<a href=https://github.com/kubernetes/kubernetes/pull/95256>#95256</a>, <a href=https://github.com/Git-Jiro>@Git-Jiro</a>) [SIG CLI]</p></li><li><p>Introduce kubectl-convert plugin. (<a href=https://github.com/kubernetes/kubernetes/pull/96190>#96190</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG CLI and Testing]</p></li><li><p>Kube-scheduler now logs processed component config at startup (<a href=https://github.com/kubernetes/kubernetes/pull/96426>#96426</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Scheduling]</p></li><li><p>Kubeadm: Separate argument key/value in log msg (<a href=https://github.com/kubernetes/kubernetes/pull/94016>#94016</a>, <a href=https://github.com/mrueg>@mrueg</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: remove the CoreDNS check for known image digests when applying the addon (<a href=https://github.com/kubernetes/kubernetes/pull/94506>#94506</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: update the default pause image version to 1.4.0 on Windows. With this update the image supports Windows versions 1809 (2019LTS), 1903, 1909, 2004 (<a href=https://github.com/kubernetes/kubernetes/pull/95419>#95419</a>, <a href=https://github.com/jsturtevant>@jsturtevant</a>) [SIG Cluster Lifecycle and Windows]</p></li><li><p>Kubectl: the <code>generator</code> flag of <code>kubectl autoscale</code> has been deprecated and has no effect, it will be removed in a feature release (<a href=https://github.com/kubernetes/kubernetes/pull/92998>#92998</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG CLI]</p></li><li><p>Lock ExternalPolicyForExternalIP to default, this feature gate will be removed in 1.22. (<a href=https://github.com/kubernetes/kubernetes/pull/94581>#94581</a>, <a href=https://github.com/knabben>@knabben</a>) [SIG Network]</p></li><li><p>Mask ceph RBD adminSecrets in logs when logLevel >= 4. (<a href=https://github.com/kubernetes/kubernetes/pull/95245>#95245</a>, <a href=https://github.com/sfowl>@sfowl</a>)</p></li><li><p>Remove offensive words from kubectl cluster-info command. (<a href=https://github.com/kubernetes/kubernetes/pull/95202>#95202</a>, <a href=https://github.com/rikatz>@rikatz</a>)</p></li><li><p>Remove support for "ci/k8s-master" version label in kubeadm, use "ci/latest" instead. See <a href=https://github.com/kubernetes/test-infra/pull/18517>kubernetes/test-infra#18517</a>. (<a href=https://github.com/kubernetes/kubernetes/pull/93626>#93626</a>, <a href=https://github.com/vikkyomkar>@vikkyomkar</a>)</p></li><li><p>Remove the dependency of csi-translation-lib module on apiserver/cloud-provider/controller-manager (<a href=https://github.com/kubernetes/kubernetes/pull/95543>#95543</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Release]</p></li><li><p>Scheduler framework interface moved from pkg/scheduler/framework/v1alpha to pkg/scheduler/framework (<a href=https://github.com/kubernetes/kubernetes/pull/95069>#95069</a>, <a href=https://github.com/farah>@farah</a>) [SIG Scheduling, Storage and Testing]</p></li><li><p>Service.beta.kubernetes.io/azure-load-balancer-disable-tcp-reset is removed. All Standard load balancers will always enable tcp resets. (<a href=https://github.com/kubernetes/kubernetes/pull/94297>#94297</a>, <a href=https://github.com/MarcPow>@MarcPow</a>) [SIG Cloud Provider]</p></li><li><p>Stop propagating SelfLink (deprecated in 1.16) in kube-apiserver (<a href=https://github.com/kubernetes/kubernetes/pull/94397>#94397</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Testing]</p></li><li><p>Strip unnecessary security contexts on Windows (<a href=https://github.com/kubernetes/kubernetes/pull/93475>#93475</a>, <a href=https://github.com/ravisantoshgudimetla>@ravisantoshgudimetla</a>) [SIG Node, Testing and Windows]</p></li><li><p>To ensure the code be strong, add unit test for GetAddressAndDialer (<a href=https://github.com/kubernetes/kubernetes/pull/93180>#93180</a>, <a href=https://github.com/FreeZhang61>@FreeZhang61</a>) [SIG Node]</p></li><li><p>UDP and SCTP protocols can left stale connections that need to be cleared to avoid services disruption, but they can cause problems that are hard to debug.
Kubernetes components using a loglevel greater or equal than 4 will log the conntrack operations and its output, to show the entries that were deleted. (<a href=https://github.com/kubernetes/kubernetes/pull/95694>#95694</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Network]</p></li><li><p>Update CNI plugins to v0.8.7 (<a href=https://github.com/kubernetes/kubernetes/pull/94367>#94367</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Cloud Provider, Network, Node, Release and Testing]</p></li><li><p>Update cri-tools to <a href=https://github.com/kubernetes-sigs/cri-tools/releases/tag/v1.19.0>v1.19.0</a> (<a href=https://github.com/kubernetes/kubernetes/pull/94307>#94307</a>, <a href=https://github.com/xmudrii>@xmudrii</a>) [SIG Cloud Provider]</p></li><li><p>Update etcd client side to v3.4.13 (<a href=https://github.com/kubernetes/kubernetes/pull/94259>#94259</a>, <a href=https://github.com/jingyih>@jingyih</a>) [SIG API Machinery and Cloud Provider]</p></li><li><p>Users will now be able to configure all supported values for AWS NLB health check interval and thresholds for new resources. (<a href=https://github.com/kubernetes/kubernetes/pull/96312>#96312</a>, <a href=https://github.com/kishorj>@kishorj</a>) [SIG Cloud Provider]</p></li><li><p>V1helpers.MatchNodeSelectorTerms now accepts just a Node and a list of Terms (<a href=https://github.com/kubernetes/kubernetes/pull/95871>#95871</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Apps, Scheduling and Storage]</p></li><li><p>Vsphere: improve logging message on node cache refresh event (<a href=https://github.com/kubernetes/kubernetes/pull/95236>#95236</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Cloud Provider]</p></li><li><p><code>MatchNodeSelectorTerms</code> function moved to <code>k8s.io/component-helpers</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95531>#95531</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Apps, Scheduling and Storage]</p></li><li><p><code>kubectl api-resources</code> now prints the API version (as 'API group/version', same as output of <code>kubectl api-versions</code>). The column APIGROUP is now APIVERSION (<a href=https://github.com/kubernetes/kubernetes/pull/95253>#95253</a>, <a href=https://github.com/sallyom>@sallyom</a>) [SIG CLI]</p></li><li><p><code>kubectl get ingress</code> now prefers the <code>networking.k8s.io/v1</code> over <code>extensions/v1beta1</code> (deprecated since v1.14). To explicitly request the deprecated version, use <code>kubectl get ingress.v1beta1.extensions</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/94309>#94309</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and CLI]</p></li></ul><h2 id=의존성>의존성</h2><h3 id=추가>추가</h3><ul><li>cloud.google.com/go/firestore: v1.1.0</li><li>github.com/Azure/go-autorest: <a href=https://github.com/Azure/go-autorest/tree/v14.2.0>v14.2.0+incompatible</a></li><li>github.com/armon/go-metrics: <a href=https://github.com/armon/go-metrics/tree/f0300d1>f0300d1</a></li><li>github.com/armon/go-radix: <a href=https://github.com/armon/go-radix/tree/7fddfc3>7fddfc3</a></li><li>github.com/bketelsen/crypt: <a href=https://github.com/bketelsen/crypt/tree/5cbc8cc>5cbc8cc</a></li><li>github.com/form3tech-oss/jwt-go: <a href=https://github.com/form3tech-oss/jwt-go/tree/v3.2.2>v3.2.2+incompatible</a></li><li>github.com/fvbommel/sortorder: <a href=https://github.com/fvbommel/sortorder/tree/v1.0.1>v1.0.1</a></li><li>github.com/hashicorp/consul/api: <a href=https://github.com/hashicorp/consul/api/tree/v1.1.0>v1.1.0</a></li><li>github.com/hashicorp/consul/sdk: <a href=https://github.com/hashicorp/consul/sdk/tree/v0.1.1>v0.1.1</a></li><li>github.com/hashicorp/errwrap: <a href=https://github.com/hashicorp/errwrap/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-cleanhttp: <a href=https://github.com/hashicorp/go-cleanhttp/tree/v0.5.1>v0.5.1</a></li><li>github.com/hashicorp/go-immutable-radix: <a href=https://github.com/hashicorp/go-immutable-radix/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-msgpack: <a href=https://github.com/hashicorp/go-msgpack/tree/v0.5.3>v0.5.3</a></li><li>github.com/hashicorp/go-multierror: <a href=https://github.com/hashicorp/go-multierror/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-rootcerts: <a href=https://github.com/hashicorp/go-rootcerts/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-sockaddr: <a href=https://github.com/hashicorp/go-sockaddr/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-uuid: <a href=https://github.com/hashicorp/go-uuid/tree/v1.0.1>v1.0.1</a></li><li>github.com/hashicorp/go.net: <a href=https://github.com/hashicorp/go.net/tree/v0.0.1>v0.0.1</a></li><li>github.com/hashicorp/logutils: <a href=https://github.com/hashicorp/logutils/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/mdns: <a href=https://github.com/hashicorp/mdns/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/memberlist: <a href=https://github.com/hashicorp/memberlist/tree/v0.1.3>v0.1.3</a></li><li>github.com/hashicorp/serf: <a href=https://github.com/hashicorp/serf/tree/v0.8.2>v0.8.2</a></li><li>github.com/jmespath/go-jmespath/internal/testify: <a href=https://github.com/jmespath/go-jmespath/internal/testify/tree/v1.5.1>v1.5.1</a></li><li>github.com/mitchellh/cli: <a href=https://github.com/mitchellh/cli/tree/v1.0.0>v1.0.0</a></li><li>github.com/mitchellh/go-testing-interface: <a href=https://github.com/mitchellh/go-testing-interface/tree/v1.0.0>v1.0.0</a></li><li>github.com/mitchellh/gox: <a href=https://github.com/mitchellh/gox/tree/v0.4.0>v0.4.0</a></li><li>github.com/mitchellh/iochan: <a href=https://github.com/mitchellh/iochan/tree/v1.0.0>v1.0.0</a></li><li>github.com/pascaldekloe/goe: <a href=https://github.com/pascaldekloe/goe/tree/57f6aae>57f6aae</a></li><li>github.com/posener/complete: <a href=https://github.com/posener/complete/tree/v1.1.1>v1.1.1</a></li><li>github.com/ryanuber/columnize: <a href=https://github.com/ryanuber/columnize/tree/9b3edd6>9b3edd6</a></li><li>github.com/sean-/seed: <a href=https://github.com/sean-/seed/tree/e2103e2>e2103e2</a></li><li>github.com/subosito/gotenv: <a href=https://github.com/subosito/gotenv/tree/v1.2.0>v1.2.0</a></li><li>github.com/willf/bitset: <a href=https://github.com/willf/bitset/tree/d5bec33>d5bec33</a></li><li>gopkg.in/ini.v1: v1.51.0</li><li>gopkg.in/yaml.v3: 9f266ea</li><li>rsc.io/quote/v3: v3.1.0</li><li>rsc.io/sampler: v1.3.0</li></ul><h3 id=변경>변경</h3><ul><li>cloud.google.com/go/bigquery: v1.0.1 → v1.4.0</li><li>cloud.google.com/go/datastore: v1.0.0 → v1.1.0</li><li>cloud.google.com/go/pubsub: v1.0.1 → v1.2.0</li><li>cloud.google.com/go/storage: v1.0.0 → v1.6.0</li><li>cloud.google.com/go: v0.51.0 → v0.54.0</li><li>github.com/Azure/go-autorest/autorest/adal: <a href=https://github.com/Azure/go-autorest/autorest/adal/compare/v0.8.2...v0.9.5>v0.8.2 → v0.9.5</a></li><li>github.com/Azure/go-autorest/autorest/date: <a href=https://github.com/Azure/go-autorest/autorest/date/compare/v0.2.0...v0.3.0>v0.2.0 → v0.3.0</a></li><li>github.com/Azure/go-autorest/autorest/mocks: <a href=https://github.com/Azure/go-autorest/autorest/mocks/compare/v0.3.0...v0.4.1>v0.3.0 → v0.4.1</a></li><li>github.com/Azure/go-autorest/autorest: <a href=https://github.com/Azure/go-autorest/autorest/compare/v0.9.6...v0.11.1>v0.9.6 → v0.11.1</a></li><li>github.com/Azure/go-autorest/logger: <a href=https://github.com/Azure/go-autorest/logger/compare/v0.1.0...v0.2.0>v0.1.0 → v0.2.0</a></li><li>github.com/Azure/go-autorest/tracing: <a href=https://github.com/Azure/go-autorest/tracing/compare/v0.5.0...v0.6.0>v0.5.0 → v0.6.0</a></li><li>github.com/Microsoft/go-winio: <a href=https://github.com/Microsoft/go-winio/compare/fc70bd9...v0.4.15>fc70bd9 → v0.4.15</a></li><li>github.com/aws/aws-sdk-go: <a href=https://github.com/aws/aws-sdk-go/compare/v1.28.2...v1.35.24>v1.28.2 → v1.35.24</a></li><li>github.com/blang/semver: <a href=https://github.com/blang/semver/compare/v3.5.0...v3.5.1>v3.5.0+incompatible → v3.5.1+incompatible</a></li><li>github.com/checkpoint-restore/go-criu/v4: <a href=https://github.com/checkpoint-restore/go-criu/v4/compare/v4.0.2...v4.1.0>v4.0.2 → v4.1.0</a></li><li>github.com/containerd/containerd: <a href=https://github.com/containerd/containerd/compare/v1.3.3...v1.4.1>v1.3.3 → v1.4.1</a></li><li>github.com/containerd/ttrpc: <a href=https://github.com/containerd/ttrpc/compare/v1.0.0...v1.0.2>v1.0.0 → v1.0.2</a></li><li>github.com/containerd/typeurl: <a href=https://github.com/containerd/typeurl/compare/v1.0.0...v1.0.1>v1.0.0 → v1.0.1</a></li><li>github.com/coreos/etcd: <a href=https://github.com/coreos/etcd/compare/v3.3.10...v3.3.13>v3.3.10+incompatible → v3.3.13+incompatible</a></li><li>github.com/docker/docker: <a href=https://github.com/docker/docker/compare/aa6a989...bd33bbf>aa6a989 → bd33bbf</a></li><li>github.com/go-gl/glfw/v3.3/glfw: <a href=https://github.com/go-gl/glfw/v3.3/glfw/compare/12ad95a...6f7a984>12ad95a → 6f7a984</a></li><li>github.com/golang/groupcache: <a href=https://github.com/golang/groupcache/compare/215e871...8c9f03a>215e871 → 8c9f03a</a></li><li>github.com/golang/mock: <a href=https://github.com/golang/mock/compare/v1.3.1...v1.4.1>v1.3.1 → v1.4.1</a></li><li>github.com/golang/protobuf: <a href=https://github.com/golang/protobuf/compare/v1.4.2...v1.4.3>v1.4.2 → v1.4.3</a></li><li>github.com/google/cadvisor: <a href=https://github.com/google/cadvisor/compare/v0.37.0...v0.38.5>v0.37.0 → v0.38.5</a></li><li>github.com/google/go-cmp: <a href=https://github.com/google/go-cmp/compare/v0.4.0...v0.5.2>v0.4.0 → v0.5.2</a></li><li>github.com/google/pprof: <a href=https://github.com/google/pprof/compare/d4f498a...1ebb73c>d4f498a → 1ebb73c</a></li><li>github.com/google/uuid: <a href=https://github.com/google/uuid/compare/v1.1.1...v1.1.2>v1.1.1 → v1.1.2</a></li><li>github.com/gorilla/mux: <a href=https://github.com/gorilla/mux/compare/v1.7.3...v1.8.0>v1.7.3 → v1.8.0</a></li><li>github.com/gorilla/websocket: <a href=https://github.com/gorilla/websocket/compare/v1.4.0...v1.4.2>v1.4.0 → v1.4.2</a></li><li>github.com/jmespath/go-jmespath: <a href=https://github.com/jmespath/go-jmespath/compare/c2b33e8...v0.4.0>c2b33e8 → v0.4.0</a></li><li>github.com/karrick/godirwalk: <a href=https://github.com/karrick/godirwalk/compare/v1.7.5...v1.16.1>v1.7.5 → v1.16.1</a></li><li>github.com/opencontainers/go-digest: <a href=https://github.com/opencontainers/go-digest/compare/v1.0.0-rc1...v1.0.0>v1.0.0-rc1 → v1.0.0</a></li><li>github.com/opencontainers/runc: <a href=https://github.com/opencontainers/runc/compare/819fcc6...v1.0.0-rc92>819fcc6 → v1.0.0-rc92</a></li><li>github.com/opencontainers/runtime-spec: <a href=https://github.com/opencontainers/runtime-spec/compare/237cc4f...4d89ac9>237cc4f → 4d89ac9</a></li><li>github.com/opencontainers/selinux: <a href=https://github.com/opencontainers/selinux/compare/v1.5.2...v1.6.0>v1.5.2 → v1.6.0</a></li><li>github.com/prometheus/procfs: <a href=https://github.com/prometheus/procfs/compare/v0.1.3...v0.2.0>v0.1.3 → v0.2.0</a></li><li>github.com/quobyte/api: <a href=https://github.com/quobyte/api/compare/v0.1.2...v0.1.8>v0.1.2 → v0.1.8</a></li><li>github.com/spf13/cobra: <a href=https://github.com/spf13/cobra/compare/v1.0.0...v1.1.1>v1.0.0 → v1.1.1</a></li><li>github.com/spf13/viper: <a href=https://github.com/spf13/viper/compare/v1.4.0...v1.7.0>v1.4.0 → v1.7.0</a></li><li>github.com/storageos/go-api: <a href=https://github.com/storageos/go-api/compare/343b3ef...v2.2.0>343b3ef → v2.2.0+incompatible</a></li><li>github.com/stretchr/testify: <a href=https://github.com/stretchr/testify/compare/v1.4.0...v1.6.1>v1.4.0 → v1.6.1</a></li><li>github.com/vishvananda/netns: <a href=https://github.com/vishvananda/netns/compare/52d707b...db3c7e5>52d707b → db3c7e5</a></li><li>go.etcd.io/etcd: 17cef6e → dd1b699</li><li>go.opencensus.io: v0.22.2 → v0.22.3</li><li>golang.org/x/crypto: 75b2880 → 7f63de1</li><li>golang.org/x/exp: da58074 → 6cc2880</li><li>golang.org/x/lint: fdd1cda → 738671d</li><li>golang.org/x/net: ab34263 → 69a7880</li><li>golang.org/x/oauth2: 858c2ad → bf48bf1</li><li>golang.org/x/sys: ed371f2 → 5cba982</li><li>golang.org/x/text: v0.3.3 → v0.3.4</li><li>golang.org/x/time: 555d28b → 3af7569</li><li>golang.org/x/xerrors: 9bdfabe → 5ec99f8</li><li>google.golang.org/api: v0.15.1 → v0.20.0</li><li>google.golang.org/genproto: cb27e3a → 8816d57</li><li>google.golang.org/grpc: v1.27.0 → v1.27.1</li><li>google.golang.org/protobuf: v1.24.0 → v1.25.0</li><li>honnef.co/go/tools: v0.0.1-2019.2.3 → v0.0.1-2020.1.3</li><li>k8s.io/gengo: 8167cfd → 83324d8</li><li>k8s.io/klog/v2: v2.2.0 → v2.4.0</li><li>k8s.io/kube-openapi: 6aeccd4 → d219536</li><li>k8s.io/system-validators: v1.1.2 → v1.2.0</li><li>k8s.io/utils: d5654de → 67b214c</li><li>sigs.k8s.io/apiserver-network-proxy/konnectivity-client: v0.0.9 → v0.0.14</li><li>sigs.k8s.io/structured-merge-diff/v4: v4.0.1 → v4.0.2</li></ul><h3 id=제거>제거</h3><ul><li>github.com/armon/consul-api: <a href=https://github.com/armon/consul-api/tree/eb2c6b5>eb2c6b5</a></li><li>github.com/go-ini/ini: <a href=https://github.com/go-ini/ini/tree/v1.9.0>v1.9.0</a></li><li>github.com/ugorji/go: <a href=https://github.com/ugorji/go/tree/v1.1.4>v1.1.4</a></li><li>github.com/xlab/handysort: <a href=https://github.com/xlab/handysort/tree/fb3537e>fb3537e</a></li><li>github.com/xordataexchange/crypt: <a href=https://github.com/xordataexchange/crypt/tree/b2862e3>b2862e3</a></li><li>vbom.ml/util: db5cfe1</li></ul><h2 id=의존성-1>의존성</h2><h3 id=추가-1>추가</h3><ul><li>cloud.google.com/go/firestore: v1.1.0</li><li>github.com/Azure/go-autorest: <a href=https://github.com/Azure/go-autorest/tree/v14.2.0>v14.2.0+incompatible</a></li><li>github.com/armon/go-metrics: <a href=https://github.com/armon/go-metrics/tree/f0300d1>f0300d1</a></li><li>github.com/armon/go-radix: <a href=https://github.com/armon/go-radix/tree/7fddfc3>7fddfc3</a></li><li>github.com/bketelsen/crypt: <a href=https://github.com/bketelsen/crypt/tree/5cbc8cc>5cbc8cc</a></li><li>github.com/form3tech-oss/jwt-go: <a href=https://github.com/form3tech-oss/jwt-go/tree/v3.2.2>v3.2.2+incompatible</a></li><li>github.com/fvbommel/sortorder: <a href=https://github.com/fvbommel/sortorder/tree/v1.0.1>v1.0.1</a></li><li>github.com/hashicorp/consul/api: <a href=https://github.com/hashicorp/consul/api/tree/v1.1.0>v1.1.0</a></li><li>github.com/hashicorp/consul/sdk: <a href=https://github.com/hashicorp/consul/sdk/tree/v0.1.1>v0.1.1</a></li><li>github.com/hashicorp/errwrap: <a href=https://github.com/hashicorp/errwrap/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-cleanhttp: <a href=https://github.com/hashicorp/go-cleanhttp/tree/v0.5.1>v0.5.1</a></li><li>github.com/hashicorp/go-immutable-radix: <a href=https://github.com/hashicorp/go-immutable-radix/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-msgpack: <a href=https://github.com/hashicorp/go-msgpack/tree/v0.5.3>v0.5.3</a></li><li>github.com/hashicorp/go-multierror: <a href=https://github.com/hashicorp/go-multierror/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-rootcerts: <a href=https://github.com/hashicorp/go-rootcerts/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-sockaddr: <a href=https://github.com/hashicorp/go-sockaddr/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-uuid: <a href=https://github.com/hashicorp/go-uuid/tree/v1.0.1>v1.0.1</a></li><li>github.com/hashicorp/go.net: <a href=https://github.com/hashicorp/go.net/tree/v0.0.1>v0.0.1</a></li><li>github.com/hashicorp/logutils: <a href=https://github.com/hashicorp/logutils/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/mdns: <a href=https://github.com/hashicorp/mdns/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/memberlist: <a href=https://github.com/hashicorp/memberlist/tree/v0.1.3>v0.1.3</a></li><li>github.com/hashicorp/serf: <a href=https://github.com/hashicorp/serf/tree/v0.8.2>v0.8.2</a></li><li>github.com/jmespath/go-jmespath/internal/testify: <a href=https://github.com/jmespath/go-jmespath/internal/testify/tree/v1.5.1>v1.5.1</a></li><li>github.com/mitchellh/cli: <a href=https://github.com/mitchellh/cli/tree/v1.0.0>v1.0.0</a></li><li>github.com/mitchellh/go-testing-interface: <a href=https://github.com/mitchellh/go-testing-interface/tree/v1.0.0>v1.0.0</a></li><li>github.com/mitchellh/gox: <a href=https://github.com/mitchellh/gox/tree/v0.4.0>v0.4.0</a></li><li>github.com/mitchellh/iochan: <a href=https://github.com/mitchellh/iochan/tree/v1.0.0>v1.0.0</a></li><li>github.com/pascaldekloe/goe: <a href=https://github.com/pascaldekloe/goe/tree/57f6aae>57f6aae</a></li><li>github.com/posener/complete: <a href=https://github.com/posener/complete/tree/v1.1.1>v1.1.1</a></li><li>github.com/ryanuber/columnize: <a href=https://github.com/ryanuber/columnize/tree/9b3edd6>9b3edd6</a></li><li>github.com/sean-/seed: <a href=https://github.com/sean-/seed/tree/e2103e2>e2103e2</a></li><li>github.com/subosito/gotenv: <a href=https://github.com/subosito/gotenv/tree/v1.2.0>v1.2.0</a></li><li>github.com/willf/bitset: <a href=https://github.com/willf/bitset/tree/d5bec33>d5bec33</a></li><li>gopkg.in/ini.v1: v1.51.0</li><li>gopkg.in/yaml.v3: 9f266ea</li><li>rsc.io/quote/v3: v3.1.0</li><li>rsc.io/sampler: v1.3.0</li></ul><h3 id=변경-1>변경</h3><ul><li>cloud.google.com/go/bigquery: v1.0.1 → v1.4.0</li><li>cloud.google.com/go/datastore: v1.0.0 → v1.1.0</li><li>cloud.google.com/go/pubsub: v1.0.1 → v1.2.0</li><li>cloud.google.com/go/storage: v1.0.0 → v1.6.0</li><li>cloud.google.com/go: v0.51.0 → v0.54.0</li><li>github.com/Azure/go-autorest/autorest/adal: <a href=https://github.com/Azure/go-autorest/autorest/adal/compare/v0.8.2...v0.9.5>v0.8.2 → v0.9.5</a></li><li>github.com/Azure/go-autorest/autorest/date: <a href=https://github.com/Azure/go-autorest/autorest/date/compare/v0.2.0...v0.3.0>v0.2.0 → v0.3.0</a></li><li>github.com/Azure/go-autorest/autorest/mocks: <a href=https://github.com/Azure/go-autorest/autorest/mocks/compare/v0.3.0...v0.4.1>v0.3.0 → v0.4.1</a></li><li>github.com/Azure/go-autorest/autorest: <a href=https://github.com/Azure/go-autorest/autorest/compare/v0.9.6...v0.11.1>v0.9.6 → v0.11.1</a></li><li>github.com/Azure/go-autorest/logger: <a href=https://github.com/Azure/go-autorest/logger/compare/v0.1.0...v0.2.0>v0.1.0 → v0.2.0</a></li><li>github.com/Azure/go-autorest/tracing: <a href=https://github.com/Azure/go-autorest/tracing/compare/v0.5.0...v0.6.0>v0.5.0 → v0.6.0</a></li><li>github.com/Microsoft/go-winio: <a href=https://github.com/Microsoft/go-winio/compare/fc70bd9...v0.4.15>fc70bd9 → v0.4.15</a></li><li>github.com/aws/aws-sdk-go: <a href=https://github.com/aws/aws-sdk-go/compare/v1.28.2...v1.35.24>v1.28.2 → v1.35.24</a></li><li>github.com/blang/semver: <a href=https://github.com/blang/semver/compare/v3.5.0...v3.5.1>v3.5.0+incompatible → v3.5.1+incompatible</a></li><li>github.com/checkpoint-restore/go-criu/v4: <a href=https://github.com/checkpoint-restore/go-criu/v4/compare/v4.0.2...v4.1.0>v4.0.2 → v4.1.0</a></li><li>github.com/containerd/containerd: <a href=https://github.com/containerd/containerd/compare/v1.3.3...v1.4.1>v1.3.3 → v1.4.1</a></li><li>github.com/containerd/ttrpc: <a href=https://github.com/containerd/ttrpc/compare/v1.0.0...v1.0.2>v1.0.0 → v1.0.2</a></li><li>github.com/containerd/typeurl: <a href=https://github.com/containerd/typeurl/compare/v1.0.0...v1.0.1>v1.0.0 → v1.0.1</a></li><li>github.com/coreos/etcd: <a href=https://github.com/coreos/etcd/compare/v3.3.10...v3.3.13>v3.3.10+incompatible → v3.3.13+incompatible</a></li><li>github.com/docker/docker: <a href=https://github.com/docker/docker/compare/aa6a989...bd33bbf>aa6a989 → bd33bbf</a></li><li>github.com/go-gl/glfw/v3.3/glfw: <a href=https://github.com/go-gl/glfw/v3.3/glfw/compare/12ad95a...6f7a984>12ad95a → 6f7a984</a></li><li>github.com/golang/groupcache: <a href=https://github.com/golang/groupcache/compare/215e871...8c9f03a>215e871 → 8c9f03a</a></li><li>github.com/golang/mock: <a href=https://github.com/golang/mock/compare/v1.3.1...v1.4.1>v1.3.1 → v1.4.1</a></li><li>github.com/golang/protobuf: <a href=https://github.com/golang/protobuf/compare/v1.4.2...v1.4.3>v1.4.2 → v1.4.3</a></li><li>github.com/google/cadvisor: <a href=https://github.com/google/cadvisor/compare/v0.37.0...v0.38.5>v0.37.0 → v0.38.5</a></li><li>github.com/google/go-cmp: <a href=https://github.com/google/go-cmp/compare/v0.4.0...v0.5.2>v0.4.0 → v0.5.2</a></li><li>github.com/google/pprof: <a href=https://github.com/google/pprof/compare/d4f498a...1ebb73c>d4f498a → 1ebb73c</a></li><li>github.com/google/uuid: <a href=https://github.com/google/uuid/compare/v1.1.1...v1.1.2>v1.1.1 → v1.1.2</a></li><li>github.com/gorilla/mux: <a href=https://github.com/gorilla/mux/compare/v1.7.3...v1.8.0>v1.7.3 → v1.8.0</a></li><li>github.com/gorilla/websocket: <a href=https://github.com/gorilla/websocket/compare/v1.4.0...v1.4.2>v1.4.0 → v1.4.2</a></li><li>github.com/jmespath/go-jmespath: <a href=https://github.com/jmespath/go-jmespath/compare/c2b33e8...v0.4.0>c2b33e8 → v0.4.0</a></li><li>github.com/karrick/godirwalk: <a href=https://github.com/karrick/godirwalk/compare/v1.7.5...v1.16.1>v1.7.5 → v1.16.1</a></li><li>github.com/opencontainers/go-digest: <a href=https://github.com/opencontainers/go-digest/compare/v1.0.0-rc1...v1.0.0>v1.0.0-rc1 → v1.0.0</a></li><li>github.com/opencontainers/runc: <a href=https://github.com/opencontainers/runc/compare/819fcc6...v1.0.0-rc92>819fcc6 → v1.0.0-rc92</a></li><li>github.com/opencontainers/runtime-spec: <a href=https://github.com/opencontainers/runtime-spec/compare/237cc4f...4d89ac9>237cc4f → 4d89ac9</a></li><li>github.com/opencontainers/selinux: <a href=https://github.com/opencontainers/selinux/compare/v1.5.2...v1.6.0>v1.5.2 → v1.6.0</a></li><li>github.com/prometheus/procfs: <a href=https://github.com/prometheus/procfs/compare/v0.1.3...v0.2.0>v0.1.3 → v0.2.0</a></li><li>github.com/quobyte/api: <a href=https://github.com/quobyte/api/compare/v0.1.2...v0.1.8>v0.1.2 → v0.1.8</a></li><li>github.com/spf13/cobra: <a href=https://github.com/spf13/cobra/compare/v1.0.0...v1.1.1>v1.0.0 → v1.1.1</a></li><li>github.com/spf13/viper: <a href=https://github.com/spf13/viper/compare/v1.4.0...v1.7.0>v1.4.0 → v1.7.0</a></li><li>github.com/storageos/go-api: <a href=https://github.com/storageos/go-api/compare/343b3ef...v2.2.0>343b3ef → v2.2.0+incompatible</a></li><li>github.com/stretchr/testify: <a href=https://github.com/stretchr/testify/compare/v1.4.0...v1.6.1>v1.4.0 → v1.6.1</a></li><li>github.com/vishvananda/netns: <a href=https://github.com/vishvananda/netns/compare/52d707b...db3c7e5>52d707b → db3c7e5</a></li><li>go.etcd.io/etcd: 17cef6e → dd1b699</li><li>go.opencensus.io: v0.22.2 → v0.22.3</li><li>golang.org/x/crypto: 75b2880 → 7f63de1</li><li>golang.org/x/exp: da58074 → 6cc2880</li><li>golang.org/x/lint: fdd1cda → 738671d</li><li>golang.org/x/net: ab34263 → 69a7880</li><li>golang.org/x/oauth2: 858c2ad → bf48bf1</li><li>golang.org/x/sys: ed371f2 → 5cba982</li><li>golang.org/x/text: v0.3.3 → v0.3.4</li><li>golang.org/x/time: 555d28b → 3af7569</li><li>golang.org/x/xerrors: 9bdfabe → 5ec99f8</li><li>google.golang.org/api: v0.15.1 → v0.20.0</li><li>google.golang.org/genproto: cb27e3a → 8816d57</li><li>google.golang.org/grpc: v1.27.0 → v1.27.1</li><li>google.golang.org/protobuf: v1.24.0 → v1.25.0</li><li>honnef.co/go/tools: v0.0.1-2019.2.3 → v0.0.1-2020.1.3</li><li>k8s.io/gengo: 8167cfd → 83324d8</li><li>k8s.io/klog/v2: v2.2.0 → v2.4.0</li><li>k8s.io/kube-openapi: 6aeccd4 → d219536</li><li>k8s.io/system-validators: v1.1.2 → v1.2.0</li><li>k8s.io/utils: d5654de → 67b214c</li><li>sigs.k8s.io/apiserver-network-proxy/konnectivity-client: v0.0.9 → v0.0.14</li><li>sigs.k8s.io/structured-merge-diff/v4: v4.0.1 → v4.0.2</li></ul><h3 id=제거-1>제거</h3><ul><li>github.com/armon/consul-api: <a href=https://github.com/armon/consul-api/tree/eb2c6b5>eb2c6b5</a></li><li>github.com/go-ini/ini: <a href=https://github.com/go-ini/ini/tree/v1.9.0>v1.9.0</a></li><li>github.com/ugorji/go: <a href=https://github.com/ugorji/go/tree/v1.1.4>v1.1.4</a></li><li>github.com/xlab/handysort: <a href=https://github.com/xlab/handysort/tree/fb3537e>fb3537e</a></li><li>github.com/xordataexchange/crypt: <a href=https://github.com/xordataexchange/crypt/tree/b2862e3>b2862e3</a></li><li>vbom.ml/util: db5cfe1</li></ul><h1 id=v1-20-0-rc-0>v1.20.0-rc.0</h1><h2 id=downloads-for-v1-20-0-rc-0>Downloads for v1.20.0-rc.0</h2><h3 id=source-code>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>acfee8658831f9503fccda0904798405434f17be7064a361a9f34c6ed04f1c0f685e79ca40cef5fcf34e3193bacbf467665e8dc277e0562ebdc929170034b5ae</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>9d962f8845e1fa221649cf0c0e178f0f03808486c49ea15ab5ec67861ec5aa948cf18bc0ee9b2067643c8332227973dd592e6a4457456a9d9d80e8ef28d5f7c3</td></tr></tbody></table><h3 id=client-binaries>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>062b57f1a450fe01d6184f104d81d376bdf5720010412821e315fd9b1b622a400ac91f996540daa66cee172006f3efade4eccc19265494f1a1d7cc9450f0b50a</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>86e96d2c2046c5e62e02bef30a6643f25e01f1b3eba256cab7dd61252908540c26cb058490e9cecc5a9bad97d2b577f5968884e9f1a90237e302419f39e068bc</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>619d3afb9ce902368390e71633396010e88e87c5fd848e3adc71571d1d4a25be002588415e5f83afee82460f8a7c9e0bd968335277cb8f8cb51e58d4bb43e64e</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>60965150a60ab3d05a248339786e0c7da4b89a04539c3719737b13d71302bac1dd9bcaa427d8a1f84a7b42d0c67801dce2de0005e9e47d21122868b32ac3d40f</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>688e064f4ef6a17189dbb5af468c279b9de35e215c40500fb97b1d46692d222747023f9e07a7f7ba006400f9532a8912e69d7c5143f956b1dadca144c67ee711</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>47b8abc02b42b3b1de67da184921b5801d7e3cb09befac840c85913193fc5ac4e5e3ecfcb57da6b686ff21af9a3bd42ae6949d4744dbe6ad976794340e328b83</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>971b41d3169f30e6c412e0254c180636abb7ccc8dcee6641b0e9877b69752fc61aa30b76c19c108969df654fe385da3cb3a44dd59d3c28dc45561392d7e08874</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>2d34e8387e31531d9aca5655f2f0d18e75b01825dc1c39b7beb73a7b7b610e2ba429e5ca97d5c41a71b67e75e7096c86ab63fda9baab4c0878c1ccb3a1aefac8</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>f909640f4140693bb871936f10a40e79b43502105d0adb318b35bb7a64a770ad9d05a3a732368ccd3d15d496d75454789165bd1f5c2571da9a00569b3e6c007c</td></tr></tbody></table><h3 id=server-binaries>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>0ea4458ae34108c633b4d48f1f128c6274dbc82b613492e78b3e0a2f656ac0df0bb9a75124e15d67c8e81850adcecf19f4ab0234c17247ee7ddf84f2df3e5eaa</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>aef6a4d457faa29936603370f29a8523bb274211c3cb5101bd31aaf469c91ba6bd149ea99a4ccdd83352cf37e4d6508c5ee475ec10292bccd2f77ceea31e1c28</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>4829f473e9d60f9929ad17c70fdc2b6b6509ed75418be0b23a75b28580949736cb5b0bd6382070f93aa0a2a8863f0b1596daf965186ca749996c29d03ef7d8b8</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>9ab0790d382a3e28df1c013762c09da0085449cfd09d176d80be932806c24a715ea829be0075c3e221a2ad9cf06e726b4c39ab41987c1fb0fee2563e48206763</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>98670b587e299856dd9821b7517a35f9a65835b915b153de08b66c54d82160438b66f774bf5306c07bc956d70ff709860bc23162225da5e89f995d3fdc1f0122</td></tr></tbody></table><h3 id=node-binaries>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>699e9c8d1837198312eade8eb6fec390f6a2fea9e08207d2f58e8bb6e3e799028aca69e4670aac0a4ba7cf0af683aee2c158bf78cc520c80edc876c8d94d521a</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>f3b5eab0669490e3cd7e802693daf3555d08323dfff6e73a881fce00fed4690e8bdaf1610278d9de74036ca37631016075e5695a02158b7d3e7582b20ef7fa35</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>e5012f77363561a609aaf791baaa17d09009819c4085a57132e5feb5366275a54640094e6ed1cba527f42b586c6d62999c2a5435edf5665ff0e114db4423c2ae</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>2a6d6501620b1a9838dff05c66a40260cc22154a28027813346eb16e18c386bc3865298a46a0f08da71cd55149c5e7d07c4c4c431b4fd231486dd9d716548adb</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>5eca02777519e31428a1e5842fe540b813fb8c929c341bbc71dcfd60d98deb89060f8f37352e8977020e21e053379eead6478eb2d54ced66fb9d38d5f3142bf0</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-rc.0/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>8ace02e7623dff894e863a2e0fa7dfb916368431d1723170713fe82e334c0ae0481b370855b71e2561de0fb64fed124281be604761ec08607230b66fb9ed1c03</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-beta-2>Changelog since v1.20.0-beta.2</h2><h2 id=changes-by-kind>Changes by Kind</h2><h3 id=feature>Feature</h3><ul><li>Kubernetes is now built using go1.15.5<ul><li>build: Update to <a href=mailto:k/repo-infra@v0.1.2>k/repo-infra@v0.1.2</a> (supports go1.15.5) (<a href=https://github.com/kubernetes/kubernetes/pull/95776>#95776</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Cloud Provider, Instrumentation, Release and Testing]</li></ul></li></ul><h3 id=failing-test>Failing Test</h3><ul><li>Resolves an issue running Ingress conformance tests on clusters which use finalizers on Ingress objects to manage releasing load balancer resources (<a href=https://github.com/kubernetes/kubernetes/pull/96742>#96742</a>, <a href=https://github.com/spencerhance>@spencerhance</a>) [SIG Network and Testing]</li><li>The Conformance test "validates that there is no conflict between pods with same hostPort but different hostIP and protocol" now validates the connectivity to each hostPort, in addition to the functionality. (<a href=https://github.com/kubernetes/kubernetes/pull/96627>#96627</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Scheduling and Testing]</li></ul><h3 id=bug-or-regression>Bug or Regression</h3><ul><li>Bump node-problem-detector version to v0.8.5 to fix OOM detection in with Linux kernels 5.1+ (<a href=https://github.com/kubernetes/kubernetes/pull/96716>#96716</a>, <a href=https://github.com/tosi3k>@tosi3k</a>) [SIG Cloud Provider, Scalability and Testing]</li><li>Changes to timeout parameter handling in 1.20.0-beta.2 have been reverted to avoid breaking backwards compatibility with existing clients. (<a href=https://github.com/kubernetes/kubernetes/pull/96727>#96727</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and Testing]</li><li>Duplicate owner reference entries in create/update/patch requests now get deduplicated by the API server. The client sending the request now receives a warning header in the API response. Clients should stop sending requests with duplicate owner references. The API server may reject such requests as early as 1.24. (<a href=https://github.com/kubernetes/kubernetes/pull/96185>#96185</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery and Testing]</li><li>Fix: resize Azure disk issue when it's in attached state (<a href=https://github.com/kubernetes/kubernetes/pull/96705>#96705</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</li><li>Fixed a bug where aggregator_unavailable_apiservice metrics were reported for deleted apiservices. (<a href=https://github.com/kubernetes/kubernetes/pull/96421>#96421</a>, <a href=https://github.com/dgrisonnet>@dgrisonnet</a>) [SIG API Machinery and Instrumentation]</li><li>Fixes code generation for non-namespaced create subresources fake client test. (<a href=https://github.com/kubernetes/kubernetes/pull/96586>#96586</a>, <a href=https://github.com/Doude>@Doude</a>) [SIG API Machinery]</li><li>HTTP/2 connection health check is enabled by default in all Kubernetes clients. The feature should work out-of-the-box. If needed, users can tune the feature via the HTTP2_READ_IDLE_TIMEOUT_SECONDS and HTTP2_PING_TIMEOUT_SECONDS environment variables. The feature is disabled if HTTP2_READ_IDLE_TIMEOUT_SECONDS is set to 0. (<a href=https://github.com/kubernetes/kubernetes/pull/95981>#95981</a>, <a href=https://github.com/caesarxuchao>@caesarxuchao</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation and Node]</li><li>Kubeadm: fix coredns migration should be triggered when there are newdefault configs during kubeadm upgrade (<a href=https://github.com/kubernetes/kubernetes/pull/96907>#96907</a>, <a href=https://github.com/pacoxu>@pacoxu</a>) [SIG Cluster Lifecycle]</li><li>Reduce volume name length for vsphere volumes (<a href=https://github.com/kubernetes/kubernetes/pull/96533>#96533</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Storage]</li><li>Resolves a regression in 1.19+ with workloads targeting deprecated beta os/arch labels getting stuck in NodeAffinity status on node startup. (<a href=https://github.com/kubernetes/kubernetes/pull/96810>#96810</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG Node]</li></ul><h2 id=dependencies>Dependencies</h2><h3 id=added>Added</h3><p><em>Nothing has changed.</em></p><h3 id=changed>Changed</h3><ul><li>github.com/google/cadvisor: <a href=https://github.com/google/cadvisor/compare/v0.38.4...v0.38.5>v0.38.4 → v0.38.5</a></li></ul><h3 id=removed>Removed</h3><p><em>Nothing has changed.</em></p><h1 id=v1-20-0-beta-2>v1.20.0-beta.2</h1><h2 id=downloads-for-v1-20-0-beta-2>Downloads for v1.20.0-beta.2</h2><h3 id=source-code-1>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>fe769280aa623802a949b6a35fbddadbba1d6f9933a54132a35625683719595ecf58096a9aa0f7456f8d4931774df21bfa98e148bc3d85913f1da915134f77bd</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>ce1c8d97c52e5189af335d673bd7e99c564816f6adebf249838f7e3f0e920f323b4e398a5d163ea767091497012ec38843c59ff14e6fdd07683b682135eed645</td></tr></tbody></table><h3 id=client-binaries-1>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>d6c14bd0f6702f4bbdf14a6abdfa4e5936de5b4efee38aa86c2bd7272967ec6d7868b88fc00ad4a7c3a20717a35e6be2b84e56dec04154fd702315f641409f7c</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>b923c44cb0acb91a8f6fd442c2168aa6166c848f5d037ce50a7cb11502be3698db65836b373c916f75b648d6ac8d9158807a050eecc4e1c77cffa25b386c8cdb</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>8cae14146a9034dcd4e9d69d5d700f195a77aac35f629a148960ae028ed8b4fe12213993fe3e6e464b4b3e111adebe6f3dd7ca0accc70c738ed5cfd8993edd7c</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>1f54e5262a0432945ead57fcb924e6bfedd9ea76db1dd9ebd946787a2923c247cf16e10505307b47e365905a1b398678dac5af0f433c439c158a33e08362d97b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>31cf79c01e4878a231b4881fe3ed5ef790bd5fb5419388438d3f8c6a2129e655aba9e00b8e1d77e0bc5d05ecc75cf4ae02cf8266788822d0306c49c85ee584ed</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>2527948c40be2e16724d939316ad5363f15aa22ebf42d59359d8b6f757d30cfef6447434cc93bc5caa5a23a6a00a2da8d8191b6441e06bba469d9d4375989a97</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>b777ad764b3a46651ecb0846e5b7f860bb2c1c4bd4d0fcc468c6ccffb7d3b8dcb6dcdd73b13c16ded7219f91bba9f1e92f9258527fd3bb162b54d7901ac303ff</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>8a2f58aaab01be9fe298e4d01456536047cbdd39a37d3e325c1f69ceab3a0504998be41a9f41a894735dfc4ed22bed02591eea5f3c75ce12d9e95ba134e72ec5</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>2f69cda177a178df149f5de66b7dba7f5ce14c1ffeb7c8d7dc4130c701b47d89bb2fbe74e7a262f573e4d21dee2c92414d050d7829e7c6fc3637a9d6b0b9c5c1</td></tr></tbody></table><h3 id=server-binaries-1>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>3ecaac0213d369eab691ac55376821a80df5013cb12e1263f18d1c236a9e49d42b3cea422175556d8f929cdf3109b22c0b6212ac0f2e80cc7a5f4afa3aba5f24</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>580030b57ff207e177208fec0801a43389cae10cc2c9306327d354e7be6a055390184531d54b6742e0983550b7a76693cc4a705c2d2f4ac30495cf63cef26b9b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>3e3286bd54671549fbef0dfdaaf1da99bc5c3efb32cc8d1e1985d9926520cea0c43bcf7cbcbbc8b1c1a95eab961255693008af3bb1ba743362998b5f0017d6d7</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>9fa051e7e97648e97e26b09ab6d26be247b41b1a5938d2189204c9e6688e455afe76612bbcdd994ed5692935d0d960bd96dc222bce4b83f61d62557752b9d75b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>fa85d432eff586f30975c95664ac130b9f5ae02dc52b97613ed7a41324496631ea11d1a267daba564cf2485a9e49707814d86bbd3175486c7efc8b58a9314af5</td></tr></tbody></table><h3 id=node-binaries-1>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>86e631f95fe670b467ead2b88d34e0364eaa275935af433d27cc378d82dcaa22041ccce40f5fa9561b9656dadaa578dc018ad458a59b1690d35f86dca4776b5c</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>a8754ff58a0e902397056b8615ab49af07aca347ba7cc4a812c238e3812234862270f25106b6a94753b157bb153b8eae8b39a01ed67384774d798598c243583b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>28d727d7d08e2c856c9b4a574ef2dbf9e37236a0555f7ec5258b4284fa0582fb94b06783aaf50bf661f7503d101fbd70808aba6de02a2f0af94db7d065d25947</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>a1283449f1a0b155c11449275e9371add544d0bdd4609d6dc737ed5f7dd228e84e24ff249613a2a153691627368dd894ad64f4e6c0010eecc6efd2c13d4fb133</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>5806028ba15a6a9c54a34f90117bc3181428dbb0e7ced30874c9f4a953ea5a0e9b2c73e6b1e2545e1b4e5253e9c7691588538b44cdfa666ce6865964b92d2fa8</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.2/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>d5327e3b7916c78777b9b69ba0f3758c3a8645c67af80114a0ae52babd7af27bb504febbaf51b1bfe5bd2d74c8c5c573471e1cb449f2429453f4b1be9d5e682a</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-beta-1>Changelog since v1.20.0-beta.1</h2><h2 id=urgent-upgrade-notes>Urgent Upgrade Notes</h2><h3 id=no-really-you-must-read-this-before-you-upgrade>(No, really, you MUST read this before you upgrade)</h3><ul><li>A bug was fixed in kubelet where exec probe timeouts were not respected. Ensure that pods relying on this behavior are updated to correctly handle probe timeouts.</li></ul><p>This change in behavior may be unexpected for some clusters and can be disabled by turning off the ExecProbeTimeout feature gate. This gate will be locked and removed in future releases so that exec probe timeouts are always respected. (<a href=https://github.com/kubernetes/kubernetes/pull/94115>#94115</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Node and Testing]</p><ul><li><p>For CSI drivers, kubelet no longer creates the target_path for NodePublishVolume in accordance with the CSI spec. Kubelet also no longer checks if staging and target paths are mounts or corrupted. CSI drivers need to be idempotent and do any necessary mount verification. (<a href=https://github.com/kubernetes/kubernetes/pull/88759>#88759</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Storage]</p></li><li><p>Kubeadm:</p></li><li><p>The label applied to control-plane nodes "node-role.kubernetes.io/master" is now deprecated and will be removed in a future release after a GA deprecation period.</p></li><li><p>Introduce a new label "node-role.kubernetes.io/control-plane" that will be applied in parallel to "node-role.kubernetes.io/master" until the removal of the "node-role.kubernetes.io/master" label.</p></li><li><p>Make "kubeadm upgrade apply" add the "node-role.kubernetes.io/control-plane" label on existing nodes that only have the "node-role.kubernetes.io/master" label during upgrade.</p></li><li><p>Please adapt your tooling built on top of kubeadm to use the "node-role.kubernetes.io/control-plane" label.</p></li><li><p>The taint applied to control-plane nodes "node-role.kubernetes.io/master:NoSchedule" is now deprecated and will be removed in a future release after a GA deprecation period.</p></li><li><p>Apply toleration for a new, future taint "node-role.kubernetes.io/control-plane:NoSchedule" to the kubeadm CoreDNS / kube-dns managed manifests. Note that this taint is not yet applied to kubeadm control-plane nodes.</p></li><li><p>Please adapt your workloads to tolerate the same future taint preemptively.</p></li></ul><p>For more details see: <a href=http://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/kubeadm/2067-rename-master-label-taint/README.md>http://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/kubeadm/2067-rename-master-label-taint/README.md</a> (<a href=https://github.com/kubernetes/kubernetes/pull/95382>#95382</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p><h2 id=changes-by-kind-1>Changes by Kind</h2><h3 id=deprecation>Deprecation</h3><ul><li>Docker support in the kubelet is now deprecated and will be removed in a future release. The kubelet uses a module called "dockershim" which implements CRI support for Docker and it has seen maintenance issues in the Kubernetes community. We encourage you to evaluate moving to a container runtime that is a full-fledged implementation of CRI (v1alpha1 or v1 compliant) as they become available. (<a href=https://github.com/kubernetes/kubernetes/pull/94624>#94624</a>, <a href=https://github.com/dims>@dims</a>) [SIG Node]</li><li>Kubectl: deprecate --delete-local-data (<a href=https://github.com/kubernetes/kubernetes/pull/95076>#95076</a>, <a href=https://github.com/dougsland>@dougsland</a>) [SIG CLI, Cloud Provider and Scalability]</li></ul><h3 id=api-change>API Change</h3><ul><li><p>API priority and fairness graduated to beta
1.19 servers with APF turned on should not be run in a multi-server cluster with 1.20+ servers. (<a href=https://github.com/kubernetes/kubernetes/pull/96527>#96527</a>, <a href=https://github.com/adtac>@adtac</a>) [SIG API Machinery and Testing]</p></li><li><p>Add LoadBalancerIPMode feature gate (<a href=https://github.com/kubernetes/kubernetes/pull/92312>#92312</a>, <a href=https://github.com/Sh4d1>@Sh4d1</a>) [SIG Apps, CLI, Cloud Provider and Network]</p></li><li><p>Add WindowsContainerResources and Annotations to CRI-API UpdateContainerResourcesRequest (<a href=https://github.com/kubernetes/kubernetes/pull/95741>#95741</a>, <a href=https://github.com/katiewasnothere>@katiewasnothere</a>) [SIG Node]</p></li><li><p>Add a 'serving' and <code>terminating</code> condition to the EndpointSlice API.</p><p><code>serving</code> tracks the readiness of endpoints regardless of their terminating state. This is distinct from <code>ready</code> since <code>ready</code> is only true when pods are not terminating.
<code>terminating</code> is true when an endpoint is terminating. For pods this is any endpoint with a deletion timestamp. (<a href=https://github.com/kubernetes/kubernetes/pull/92968>#92968</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Apps and Network]</p></li><li><p>Add support for hugepages to downward API (<a href=https://github.com/kubernetes/kubernetes/pull/86102>#86102</a>, <a href=https://github.com/derekwaynecarr>@derekwaynecarr</a>) [SIG API Machinery, Apps, CLI, Network, Node, Scheduling and Testing]</p></li><li><p>Adds kubelet alpha feature, <code>GracefulNodeShutdown</code> which makes kubelet aware of node system shutdowns and result in graceful termination of pods during a system shutdown. (<a href=https://github.com/kubernetes/kubernetes/pull/96129>#96129</a>, <a href=https://github.com/bobbypage>@bobbypage</a>) [SIG Node]</p></li><li><p>AppProtocol is now GA for Endpoints and Services. The ServiceAppProtocol feature gate will be deprecated in 1.21. (<a href=https://github.com/kubernetes/kubernetes/pull/96327>#96327</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps and Network]</p></li><li><p>Automatic allocation of NodePorts for services with type LoadBalancer can now be disabled by setting the (new) parameter
Service.spec.allocateLoadBalancerNodePorts=false. The default is to allocate NodePorts for services with type LoadBalancer which is the existing behavior. (<a href=https://github.com/kubernetes/kubernetes/pull/92744>#92744</a>, <a href=https://github.com/uablrek>@uablrek</a>) [SIG Apps and Network]</p></li><li><p>Document that ServiceTopology feature is required to use <code>service.spec.topologyKeys</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/96528>#96528</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Apps]</p></li><li><p>EndpointSlice has a new NodeName field guarded by the EndpointSliceNodeName feature gate.</p><ul><li>EndpointSlice topology field will be deprecated in an upcoming release.</li><li>EndpointSlice "IP" address type is formally removed after being deprecated in Kubernetes 1.17.</li><li>The discovery.k8s.io/v1alpha1 API is deprecated and will be removed in Kubernetes 1.21. (<a href=https://github.com/kubernetes/kubernetes/pull/96440>#96440</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG API Machinery, Apps and Network]</li></ul></li><li><p>Fewer candidates are enumerated for preemption to improve performance in large clusters (<a href=https://github.com/kubernetes/kubernetes/pull/94814>#94814</a>, <a href=https://github.com/adtac>@adtac</a>) [SIG Scheduling]</p></li><li><p>If BoundServiceAccountTokenVolume is enabled, cluster admins can use metric <code>serviceaccount_stale_tokens_total</code> to monitor workloads that are depending on the extended tokens. If there are no such workloads, turn off extended tokens by starting <code>kube-apiserver</code> with flag <code>--service-account-extend-token-expiration=false</code> (<a href=https://github.com/kubernetes/kubernetes/pull/96273>#96273</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery and Auth]</p></li><li><p>Introduce alpha support for exec-based container registry credential provider plugins in the kubelet. (<a href=https://github.com/kubernetes/kubernetes/pull/94196>#94196</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Node and Release]</p></li><li><p>Kube-apiserver now deletes expired kube-apiserver Lease objects:</p><ul><li>The feature is under feature gate <code>APIServerIdentity</code>.</li><li>A flag is added to kube-apiserver: <code>identity-lease-garbage-collection-check-period-seconds</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95895>#95895</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery, Apps, Auth and Testing]</li></ul></li><li><p>Move configurable fsgroup change policy for pods to beta (<a href=https://github.com/kubernetes/kubernetes/pull/96376>#96376</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Apps and Storage]</p></li><li><p>New flag is introduced, i.e. --topology-manager-scope=container|pod.
The default value is the "container" scope. (<a href=https://github.com/kubernetes/kubernetes/pull/92967>#92967</a>, <a href=https://github.com/cezaryzukowski>@cezaryzukowski</a>) [SIG Instrumentation, Node and Testing]</p></li><li><p>NodeAffinity plugin can be configured with AddedAffinity. (<a href=https://github.com/kubernetes/kubernetes/pull/96202>#96202</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Node, Scheduling and Testing]</p></li><li><p>Promote RuntimeClass feature to GA.
Promote node.k8s.io API groups from v1beta1 to v1. (<a href=https://github.com/kubernetes/kubernetes/pull/95718>#95718</a>, <a href=https://github.com/SergeyKanzhelev>@SergeyKanzhelev</a>) [SIG Apps, Auth, Node, Scheduling and Testing]</p></li><li><p>Reminder: The labels "failure-domain.beta.kubernetes.io/zone" and "failure-domain.beta.kubernetes.io/region" are deprecated in favor of "topology.kubernetes.io/zone" and "topology.kubernetes.io/region" respectively. All users of the "failure-domain.beta..." labels should switch to the "topology..." equivalents. (<a href=https://github.com/kubernetes/kubernetes/pull/96033>#96033</a>, <a href=https://github.com/thockin>@thockin</a>) [SIG API Machinery, Apps, CLI, Cloud Provider, Network, Node, Scheduling, Storage and Testing]</p></li><li><p>The usage of mixed protocol values in the same LoadBalancer Service is possible if the new feature gate MixedProtocolLBSVC is enabled.
"action required"
The feature gate is disabled by default. The user has to enable it for the API Server. (<a href=https://github.com/kubernetes/kubernetes/pull/94028>#94028</a>, <a href=https://github.com/janosi>@janosi</a>) [SIG API Machinery and Apps]</p></li><li><p>This PR will introduce a feature gate CSIServiceAccountToken with two additional fields in <code>CSIDriverSpec</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/93130>#93130</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Apps, Auth, CLI, Network, Node, Storage and Testing]</p></li><li><p>Users can try the cronjob controller v2 using the feature gate. This will be the default controller in future releases. (<a href=https://github.com/kubernetes/kubernetes/pull/93370>#93370</a>, <a href=https://github.com/alaypatel07>@alaypatel07</a>) [SIG API Machinery, Apps, Auth and Testing]</p></li><li><p>VolumeSnapshotDataSource moves to GA in 1.20 release (<a href=https://github.com/kubernetes/kubernetes/pull/95282>#95282</a>, <a href=https://github.com/xing-yang>@xing-yang</a>) [SIG Apps]</p></li></ul><h3 id=feature-1>Feature</h3><ul><li><strong>Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.</strong>: (<a href=https://github.com/kubernetes/kubernetes/pull/95896>#95896</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery and Cluster Lifecycle]</li><li>A new set of alpha metrics are reported by the Kubernetes scheduler under the <code>/metrics/resources</code> endpoint that allow administrators to easily see the resource consumption (requests and limits for all resources on the pods) and compare it to actual pod usage or node capacity. (<a href=https://github.com/kubernetes/kubernetes/pull/94866>#94866</a>, <a href=https://github.com/smarterclayton>@smarterclayton</a>) [SIG API Machinery, Instrumentation, Node and Scheduling]</li><li>Add --experimental-logging-sanitization flag enabling runtime protection from leaking sensitive data in logs (<a href=https://github.com/kubernetes/kubernetes/pull/96370>#96370</a>, <a href=https://github.com/serathius>@serathius</a>) [SIG API Machinery, Cluster Lifecycle and Instrumentation]</li><li>Add a StorageVersionAPI feature gate that makes API server update storageversions before serving certain write requests.
This feature allows the storage migrator to manage storage migration for built-in resources.
Enabling internal.apiserver.k8s.io/v1alpha1 API and APIServerIdentity feature gate are required to use this feature. (<a href=https://github.com/kubernetes/kubernetes/pull/93873>#93873</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery, Auth and Testing]</li><li>Add a new <code>vSphere</code> metric: <code>cloudprovider_vsphere_vcenter_versions</code>. It's content show <code>vCenter</code> hostnames with the associated server version. (<a href=https://github.com/kubernetes/kubernetes/pull/94526>#94526</a>, <a href=https://github.com/Danil-Grigorev>@Danil-Grigorev</a>) [SIG Cloud Provider and Instrumentation]</li><li>Add feature to size memory backed volumes (<a href=https://github.com/kubernetes/kubernetes/pull/94444>#94444</a>, <a href=https://github.com/derekwaynecarr>@derekwaynecarr</a>) [SIG Storage and Testing]</li><li>Add node_authorizer_actions_duration_seconds metric that can be used to estimate load to node authorizer. (<a href=https://github.com/kubernetes/kubernetes/pull/92466>#92466</a>, <a href=https://github.com/mborsz>@mborsz</a>) [SIG API Machinery, Auth and Instrumentation]</li><li>Add pod_ based CPU and memory metrics to Kubelet's /metrics/resource endpoint (<a href=https://github.com/kubernetes/kubernetes/pull/95839>#95839</a>, <a href=https://github.com/egernst>@egernst</a>) [SIG Instrumentation, Node and Testing]</li><li>Adds a headless service on node-local-cache addon. (<a href=https://github.com/kubernetes/kubernetes/pull/88412>#88412</a>, <a href=https://github.com/stafot>@stafot</a>) [SIG Cloud Provider and Network]</li><li>CRDs: For structural schemas, non-nullable null map fields will now be dropped and defaulted if a default is available. null items in list will continue being preserved, and fail validation if not nullable. (<a href=https://github.com/kubernetes/kubernetes/pull/95423>#95423</a>, <a href=https://github.com/apelisse>@apelisse</a>) [SIG API Machinery]</li><li>E2e test for PodFsGroupChangePolicy (<a href=https://github.com/kubernetes/kubernetes/pull/96247>#96247</a>, <a href=https://github.com/saikat-royc>@saikat-royc</a>) [SIG Storage and Testing]</li><li>Gradudate the Pod Resources API to G.A
Introduces the pod_resources_endpoint_requests_total metric which tracks the total number of requests to the pod resources API (<a href=https://github.com/kubernetes/kubernetes/pull/92165>#92165</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>) [SIG Instrumentation, Node and Testing]</li><li>Introduce api-extensions category which will return: mutating admission configs, validating admission configs, CRDs and APIServices when used in kubectl get, for example. (<a href=https://github.com/kubernetes/kubernetes/pull/95603>#95603</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG API Machinery]</li><li>Kube-apiserver now maintains a Lease object to identify itself:<ul><li>The feature is under feature gate <code>APIServerIdentity</code>.</li><li>Two flags are added to kube-apiserver: <code>identity-lease-duration-seconds</code>, <code>identity-lease-renew-interval-seconds</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95533>#95533</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery]</li></ul></li><li>Kube-apiserver: The timeout used when making health check calls to etcd can now be configured with <code>--etcd-healthcheck-timeout</code>. The default timeout is 2 seconds, matching the previous behavior. (<a href=https://github.com/kubernetes/kubernetes/pull/93244>#93244</a>, <a href=https://github.com/Sh4d1>@Sh4d1</a>) [SIG API Machinery]</li><li>Kubectl: Previously users cannot provide arguments to a external diff tool via KUBECTL_EXTERNAL_DIFF env. This release now allow users to specify args to KUBECTL_EXTERNAL_DIFF env. (<a href=https://github.com/kubernetes/kubernetes/pull/95292>#95292</a>, <a href=https://github.com/dougsland>@dougsland</a>) [SIG CLI]</li><li>Scheduler now ignores Pod update events if the resourceVersion of old and new Pods are identical. (<a href=https://github.com/kubernetes/kubernetes/pull/96071>#96071</a>, <a href=https://github.com/Huang-Wei>@Huang-Wei</a>) [SIG Scheduling]</li><li>Support custom tags for cloud provider managed resources (<a href=https://github.com/kubernetes/kubernetes/pull/96450>#96450</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li><li>Support customize load balancer health probe protocol and request path (<a href=https://github.com/kubernetes/kubernetes/pull/96338>#96338</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li><li>Support multiple standard load balancers in one cluster (<a href=https://github.com/kubernetes/kubernetes/pull/96111>#96111</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li><li>The beta <code>RootCAConfigMap</code> feature gate is enabled by default and causes kube-controller-manager to publish a "kube-root-ca.crt" ConfigMap to every namespace. This ConfigMap contains a CA bundle used for verifying connections to the kube-apiserver. (<a href=https://github.com/kubernetes/kubernetes/pull/96197>#96197</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Apps, Auth and Testing]</li><li>The kubelet_runtime_operations_duration_seconds metric got additional buckets of 60, 300, 600, 900 and 1200 seconds (<a href=https://github.com/kubernetes/kubernetes/pull/96054>#96054</a>, <a href=https://github.com/alvaroaleman>@alvaroaleman</a>) [SIG Instrumentation and Node]</li><li>There is a new pv_collector_total_pv_count metric that counts persistent volumes by the volume plugin name and volume mode. (<a href=https://github.com/kubernetes/kubernetes/pull/95719>#95719</a>, <a href=https://github.com/tsmetana>@tsmetana</a>) [SIG Apps, Instrumentation, Storage and Testing]</li><li>Volume snapshot e2e test to validate PVC and VolumeSnapshotContent finalizer (<a href=https://github.com/kubernetes/kubernetes/pull/95863>#95863</a>, <a href=https://github.com/RaunakShah>@RaunakShah</a>) [SIG Cloud Provider, Storage and Testing]</li><li>Warns user when executing kubectl apply/diff to resource currently being deleted. (<a href=https://github.com/kubernetes/kubernetes/pull/95544>#95544</a>, <a href=https://github.com/SaiHarshaK>@SaiHarshaK</a>) [SIG CLI]</li><li><code>kubectl alpha debug</code> has graduated to beta and is now <code>kubectl debug</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/96138>#96138</a>, <a href=https://github.com/verb>@verb</a>) [SIG CLI and Testing]</li><li><code>kubectl debug</code> gains support for changing container images when copying a pod for debugging, similar to how <code>kubectl set image</code> works. See <code>kubectl help debug</code> for more information. (<a href=https://github.com/kubernetes/kubernetes/pull/96058>#96058</a>, <a href=https://github.com/verb>@verb</a>) [SIG CLI]</li></ul><h3 id=documentation>Documentation</h3><ul><li>Updates docs and guidance on cloud provider InstancesV2 and Zones interface for external cloud providers:<ul><li>removes experimental warning for InstancesV2</li><li>document that implementation of InstancesV2 will disable calls to Zones</li><li>deprecate Zones in favor of InstancesV2 (<a href=https://github.com/kubernetes/kubernetes/pull/96397>#96397</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Cloud Provider]</li></ul></li></ul><h3 id=bug-or-regression-1>Bug or Regression</h3><ul><li>Change plugin name in fsgroupapplymetrics of csi and flexvolume to distinguish different driver (<a href=https://github.com/kubernetes/kubernetes/pull/95892>#95892</a>, <a href=https://github.com/JornShen>@JornShen</a>) [SIG Instrumentation, Storage and Testing]</li><li>Clear UDP conntrack entry on endpoint changes when using nodeport (<a href=https://github.com/kubernetes/kubernetes/pull/71573>#71573</a>, <a href=https://github.com/JacobTanenbaum>@JacobTanenbaum</a>) [SIG Network]</li><li>Exposes and sets a default timeout for the TokenReview client for DelegatingAuthenticationOptions (<a href=https://github.com/kubernetes/kubernetes/pull/96217>#96217</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery and Cloud Provider]</li><li>Fix CVE-2020-8555 for Quobyte client connections. (<a href=https://github.com/kubernetes/kubernetes/pull/95206>#95206</a>, <a href=https://github.com/misterikkit>@misterikkit</a>) [SIG Storage]</li><li>Fix IP fragmentation of UDP and TCP packets not supported issues on LoadBalancer rules (<a href=https://github.com/kubernetes/kubernetes/pull/96464>#96464</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li><li>Fix a bug that DefaultPreemption plugin is disabled when using (legacy) scheduler policy. (<a href=https://github.com/kubernetes/kubernetes/pull/96439>#96439</a>, <a href=https://github.com/Huang-Wei>@Huang-Wei</a>) [SIG Scheduling and Testing]</li><li>Fix bug in JSON path parser where an error occurs when a range is empty (<a href=https://github.com/kubernetes/kubernetes/pull/95933>#95933</a>, <a href=https://github.com/brianpursley>@brianpursley</a>) [SIG API Machinery]</li><li>Fix client-go prometheus metrics to correctly present the API path accessed in some environments. (<a href=https://github.com/kubernetes/kubernetes/pull/74363>#74363</a>, <a href=https://github.com/aanm>@aanm</a>) [SIG API Machinery]</li><li>Fix memory leak in kube-apiserver when underlying time goes forth and back. (<a href=https://github.com/kubernetes/kubernetes/pull/96266>#96266</a>, <a href=https://github.com/chenyw1990>@chenyw1990</a>) [SIG API Machinery]</li><li>Fix paging issues when Azure API returns empty values with non-empty nextLink (<a href=https://github.com/kubernetes/kubernetes/pull/96211>#96211</a>, <a href=https://github.com/feiskyer>@feiskyer</a>) [SIG Cloud Provider]</li><li>Fix pull image error from multiple ACRs using azure managed identity (<a href=https://github.com/kubernetes/kubernetes/pull/96355>#96355</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</li><li>Fix vSphere volumes that could be erroneously attached to wrong node (<a href=https://github.com/kubernetes/kubernetes/pull/96224>#96224</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Cloud Provider and Storage]</li><li>Fixed a bug that prevents kubectl to validate CRDs with schema using x-kubernetes-preserve-unknown-fields on object fields. (<a href=https://github.com/kubernetes/kubernetes/pull/96369>#96369</a>, <a href=https://github.com/gautierdelorme>@gautierdelorme</a>) [SIG API Machinery and Testing]</li><li>For vSphere Cloud Provider, If VM of worker node is deleted, the node will also be deleted by node controller (<a href=https://github.com/kubernetes/kubernetes/pull/92608>#92608</a>, <a href=https://github.com/lubronzhan>@lubronzhan</a>) [SIG Cloud Provider]</li><li>HTTP/2 connection health check is enabled by default in all Kubernetes clients. The feature should work out-of-the-box. If needed, users can tune the feature via the HTTP2_READ_IDLE_TIMEOUT_SECONDS and HTTP2_PING_TIMEOUT_SECONDS environment variables. The feature is disabled if HTTP2_READ_IDLE_TIMEOUT_SECONDS is set to 0. (<a href=https://github.com/kubernetes/kubernetes/pull/95981>#95981</a>, <a href=https://github.com/caesarxuchao>@caesarxuchao</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation and Node]</li><li>If the user specifies an invalid timeout in the request URL, the request will be aborted with an HTTP 400.<ul><li>If the user specifies a timeout in the request URL that exceeds the maximum request deadline allowed by the apiserver, the request will be aborted with an HTTP 400. (<a href=https://github.com/kubernetes/kubernetes/pull/96061>#96061</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery, Network and Testing]</li></ul></li><li>Improve error messages related to nodePort endpoint changes conntrack entries cleanup. (<a href=https://github.com/kubernetes/kubernetes/pull/96251>#96251</a>, <a href=https://github.com/ravens>@ravens</a>) [SIG Network]</li><li>Print go stack traces at -v=4 and not -v=2 (<a href=https://github.com/kubernetes/kubernetes/pull/94663>#94663</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG CLI]</li><li>Remove ready file and its directory (which is created during volume SetUp) during emptyDir volume TearDown. (<a href=https://github.com/kubernetes/kubernetes/pull/95770>#95770</a>, <a href=https://github.com/jingxu97>@jingxu97</a>) [SIG Storage]</li><li>Resolves non-deterministic behavior of the garbage collection controller when ownerReferences with incorrect data are encountered. Events with a reason of <code>OwnerRefInvalidNamespace</code> are recorded when namespace mismatches between child and owner objects are detected.<ul><li>A namespaced object with an ownerReference referencing a uid of a namespaced kind which does not exist in the same namespace is now consistently treated as though that owner does not exist, and the child object is deleted.</li><li>A cluster-scoped object with an ownerReference referencing a uid of a namespaced kind is now consistently treated as though that owner is not resolvable, and the child object is ignored by the garbage collector. (<a href=https://github.com/kubernetes/kubernetes/pull/92743>#92743</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery, Apps and Testing]</li></ul></li><li>Skip [k8s.io/kubernetes@v1.19.0/test/e2e/storage/testsuites/base.go:162]: Driver azure-disk doesn't support snapshot type DynamicSnapshot -- skipping
skip [k8s.io/kubernetes@v1.19.0/test/e2e/storage/testsuites/base.go:185]: Driver azure-disk doesn't support ntfs -- skipping (<a href=https://github.com/kubernetes/kubernetes/pull/96144>#96144</a>, <a href=https://github.com/qinpingli>@qinpingli</a>) [SIG Storage and Testing]</li><li>The AWS network load balancer attributes can now be specified during service creation (<a href=https://github.com/kubernetes/kubernetes/pull/95247>#95247</a>, <a href=https://github.com/kishorj>@kishorj</a>) [SIG Cloud Provider]</li><li>The kube-apiserver will no longer serve APIs that should have been deleted in GA non-alpha levels. Alpha levels will continue to serve the removed APIs so that CI doesn't immediately break. (<a href=https://github.com/kubernetes/kubernetes/pull/96525>#96525</a>, <a href=https://github.com/deads2k>@deads2k</a>) [SIG API Machinery]</li><li>Update max azure data disk count map (<a href=https://github.com/kubernetes/kubernetes/pull/96308>#96308</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</li><li>Update the route table tag in the route reconcile loop (<a href=https://github.com/kubernetes/kubernetes/pull/96545>#96545</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li><li>Volume binding: report UnschedulableAndUnresolvable status instead of an error when bound PVs not found (<a href=https://github.com/kubernetes/kubernetes/pull/95541>#95541</a>, <a href=https://github.com/cofyc>@cofyc</a>) [SIG Apps, Scheduling and Storage]</li><li>[kubectl] Fail when local source file doesn't exist (<a href=https://github.com/kubernetes/kubernetes/pull/90333>#90333</a>, <a href=https://github.com/bamarni>@bamarni</a>) [SIG CLI]</li></ul><h3 id=other-cleanup-or-flake>Other (Cleanup or Flake)</h3><ul><li>Handle slow cronjob lister in cronjob controller v2 and improve memory footprint. (<a href=https://github.com/kubernetes/kubernetes/pull/96443>#96443</a>, <a href=https://github.com/alaypatel07>@alaypatel07</a>) [SIG Apps]</li><li>--redirect-container-streaming is no longer functional. The flag will be removed in v1.22 (<a href=https://github.com/kubernetes/kubernetes/pull/95935>#95935</a>, <a href=https://github.com/tallclair>@tallclair</a>) [SIG Node]</li><li>A new metric <code>requestAbortsTotal</code> has been introduced that counts aborted requests for each <code>group</code>, <code>version</code>, <code>verb</code>, <code>resource</code>, <code>subresource</code> and <code>scope</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/95002>#95002</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery, Cloud Provider, Instrumentation and Scheduling]</li><li>API priority and fairness metrics use snake_case in label names (<a href=https://github.com/kubernetes/kubernetes/pull/96236>#96236</a>, <a href=https://github.com/adtac>@adtac</a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Testing]</li><li>Applies translations on all command descriptions (<a href=https://github.com/kubernetes/kubernetes/pull/95439>#95439</a>, <a href=https://github.com/HerrNaN>@HerrNaN</a>) [SIG CLI]</li><li>Changed: default "Accept-Encoding" header removed from HTTP probes. See <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes>https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes</a> (<a href=https://github.com/kubernetes/kubernetes/pull/96127>#96127</a>, <a href=https://github.com/fonsecas72>@fonsecas72</a>) [SIG Network and Node]</li><li>Generators for services are removed from kubectl (<a href=https://github.com/kubernetes/kubernetes/pull/95256>#95256</a>, <a href=https://github.com/Git-Jiro>@Git-Jiro</a>) [SIG CLI]</li><li>Introduce kubectl-convert plugin. (<a href=https://github.com/kubernetes/kubernetes/pull/96190>#96190</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG CLI and Testing]</li><li>Kube-scheduler now logs processed component config at startup (<a href=https://github.com/kubernetes/kubernetes/pull/96426>#96426</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Scheduling]</li><li>NONE (<a href=https://github.com/kubernetes/kubernetes/pull/96179>#96179</a>, <a href=https://github.com/bbyrne5>@bbyrne5</a>) [SIG Network]</li><li>Users will now be able to configure all supported values for AWS NLB health check interval and thresholds for new resources. (<a href=https://github.com/kubernetes/kubernetes/pull/96312>#96312</a>, <a href=https://github.com/kishorj>@kishorj</a>) [SIG Cloud Provider]</li></ul><h2 id=dependencies-1>Dependencies</h2><h3 id=added-1>Added</h3><ul><li>cloud.google.com/go/firestore: v1.1.0</li><li>github.com/armon/go-metrics: <a href=https://github.com/armon/go-metrics/tree/f0300d1>f0300d1</a></li><li>github.com/armon/go-radix: <a href=https://github.com/armon/go-radix/tree/7fddfc3>7fddfc3</a></li><li>github.com/bketelsen/crypt: <a href=https://github.com/bketelsen/crypt/tree/5cbc8cc>5cbc8cc</a></li><li>github.com/hashicorp/consul/api: <a href=https://github.com/hashicorp/consul/api/tree/v1.1.0>v1.1.0</a></li><li>github.com/hashicorp/consul/sdk: <a href=https://github.com/hashicorp/consul/sdk/tree/v0.1.1>v0.1.1</a></li><li>github.com/hashicorp/errwrap: <a href=https://github.com/hashicorp/errwrap/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-cleanhttp: <a href=https://github.com/hashicorp/go-cleanhttp/tree/v0.5.1>v0.5.1</a></li><li>github.com/hashicorp/go-immutable-radix: <a href=https://github.com/hashicorp/go-immutable-radix/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-msgpack: <a href=https://github.com/hashicorp/go-msgpack/tree/v0.5.3>v0.5.3</a></li><li>github.com/hashicorp/go-multierror: <a href=https://github.com/hashicorp/go-multierror/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-rootcerts: <a href=https://github.com/hashicorp/go-rootcerts/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-sockaddr: <a href=https://github.com/hashicorp/go-sockaddr/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/go-uuid: <a href=https://github.com/hashicorp/go-uuid/tree/v1.0.1>v1.0.1</a></li><li>github.com/hashicorp/go.net: <a href=https://github.com/hashicorp/go.net/tree/v0.0.1>v0.0.1</a></li><li>github.com/hashicorp/logutils: <a href=https://github.com/hashicorp/logutils/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/mdns: <a href=https://github.com/hashicorp/mdns/tree/v1.0.0>v1.0.0</a></li><li>github.com/hashicorp/memberlist: <a href=https://github.com/hashicorp/memberlist/tree/v0.1.3>v0.1.3</a></li><li>github.com/hashicorp/serf: <a href=https://github.com/hashicorp/serf/tree/v0.8.2>v0.8.2</a></li><li>github.com/mitchellh/cli: <a href=https://github.com/mitchellh/cli/tree/v1.0.0>v1.0.0</a></li><li>github.com/mitchellh/go-testing-interface: <a href=https://github.com/mitchellh/go-testing-interface/tree/v1.0.0>v1.0.0</a></li><li>github.com/mitchellh/gox: <a href=https://github.com/mitchellh/gox/tree/v0.4.0>v0.4.0</a></li><li>github.com/mitchellh/iochan: <a href=https://github.com/mitchellh/iochan/tree/v1.0.0>v1.0.0</a></li><li>github.com/pascaldekloe/goe: <a href=https://github.com/pascaldekloe/goe/tree/57f6aae>57f6aae</a></li><li>github.com/posener/complete: <a href=https://github.com/posener/complete/tree/v1.1.1>v1.1.1</a></li><li>github.com/ryanuber/columnize: <a href=https://github.com/ryanuber/columnize/tree/9b3edd6>9b3edd6</a></li><li>github.com/sean-/seed: <a href=https://github.com/sean-/seed/tree/e2103e2>e2103e2</a></li><li>github.com/subosito/gotenv: <a href=https://github.com/subosito/gotenv/tree/v1.2.0>v1.2.0</a></li><li>github.com/willf/bitset: <a href=https://github.com/willf/bitset/tree/d5bec33>d5bec33</a></li><li>gopkg.in/ini.v1: v1.51.0</li><li>gopkg.in/yaml.v3: 9f266ea</li><li>rsc.io/quote/v3: v3.1.0</li><li>rsc.io/sampler: v1.3.0</li></ul><h3 id=changed-1>Changed</h3><ul><li>cloud.google.com/go/bigquery: v1.0.1 → v1.4.0</li><li>cloud.google.com/go/datastore: v1.0.0 → v1.1.0</li><li>cloud.google.com/go/pubsub: v1.0.1 → v1.2.0</li><li>cloud.google.com/go/storage: v1.0.0 → v1.6.0</li><li>cloud.google.com/go: v0.51.0 → v0.54.0</li><li>github.com/Microsoft/go-winio: <a href=https://github.com/Microsoft/go-winio/compare/fc70bd9...v0.4.15>fc70bd9 → v0.4.15</a></li><li>github.com/aws/aws-sdk-go: <a href=https://github.com/aws/aws-sdk-go/compare/v1.35.5...v1.35.24>v1.35.5 → v1.35.24</a></li><li>github.com/blang/semver: <a href=https://github.com/blang/semver/compare/v3.5.0...v3.5.1>v3.5.0+incompatible → v3.5.1+incompatible</a></li><li>github.com/checkpoint-restore/go-criu/v4: <a href=https://github.com/checkpoint-restore/go-criu/v4/compare/v4.0.2...v4.1.0>v4.0.2 → v4.1.0</a></li><li>github.com/containerd/containerd: <a href=https://github.com/containerd/containerd/compare/v1.3.3...v1.4.1>v1.3.3 → v1.4.1</a></li><li>github.com/containerd/ttrpc: <a href=https://github.com/containerd/ttrpc/compare/v1.0.0...v1.0.2>v1.0.0 → v1.0.2</a></li><li>github.com/containerd/typeurl: <a href=https://github.com/containerd/typeurl/compare/v1.0.0...v1.0.1>v1.0.0 → v1.0.1</a></li><li>github.com/coreos/etcd: <a href=https://github.com/coreos/etcd/compare/v3.3.10...v3.3.13>v3.3.10+incompatible → v3.3.13+incompatible</a></li><li>github.com/docker/docker: <a href=https://github.com/docker/docker/compare/aa6a989...bd33bbf>aa6a989 → bd33bbf</a></li><li>github.com/go-gl/glfw/v3.3/glfw: <a href=https://github.com/go-gl/glfw/v3.3/glfw/compare/12ad95a...6f7a984>12ad95a → 6f7a984</a></li><li>github.com/golang/groupcache: <a href=https://github.com/golang/groupcache/compare/215e871...8c9f03a>215e871 → 8c9f03a</a></li><li>github.com/golang/mock: <a href=https://github.com/golang/mock/compare/v1.3.1...v1.4.1>v1.3.1 → v1.4.1</a></li><li>github.com/golang/protobuf: <a href=https://github.com/golang/protobuf/compare/v1.4.2...v1.4.3>v1.4.2 → v1.4.3</a></li><li>github.com/google/cadvisor: <a href=https://github.com/google/cadvisor/compare/v0.37.0...v0.38.4>v0.37.0 → v0.38.4</a></li><li>github.com/google/go-cmp: <a href=https://github.com/google/go-cmp/compare/v0.4.0...v0.5.2>v0.4.0 → v0.5.2</a></li><li>github.com/google/pprof: <a href=https://github.com/google/pprof/compare/d4f498a...1ebb73c>d4f498a → 1ebb73c</a></li><li>github.com/google/uuid: <a href=https://github.com/google/uuid/compare/v1.1.1...v1.1.2>v1.1.1 → v1.1.2</a></li><li>github.com/gorilla/mux: <a href=https://github.com/gorilla/mux/compare/v1.7.3...v1.8.0>v1.7.3 → v1.8.0</a></li><li>github.com/gorilla/websocket: <a href=https://github.com/gorilla/websocket/compare/v1.4.0...v1.4.2>v1.4.0 → v1.4.2</a></li><li>github.com/karrick/godirwalk: <a href=https://github.com/karrick/godirwalk/compare/v1.7.5...v1.16.1>v1.7.5 → v1.16.1</a></li><li>github.com/opencontainers/runc: <a href=https://github.com/opencontainers/runc/compare/819fcc6...v1.0.0-rc92>819fcc6 → v1.0.0-rc92</a></li><li>github.com/opencontainers/runtime-spec: <a href=https://github.com/opencontainers/runtime-spec/compare/237cc4f...4d89ac9>237cc4f → 4d89ac9</a></li><li>github.com/opencontainers/selinux: <a href=https://github.com/opencontainers/selinux/compare/v1.5.2...v1.6.0>v1.5.2 → v1.6.0</a></li><li>github.com/prometheus/procfs: <a href=https://github.com/prometheus/procfs/compare/v0.1.3...v0.2.0>v0.1.3 → v0.2.0</a></li><li>github.com/quobyte/api: <a href=https://github.com/quobyte/api/compare/v0.1.2...v0.1.8>v0.1.2 → v0.1.8</a></li><li>github.com/spf13/cobra: <a href=https://github.com/spf13/cobra/compare/v1.0.0...v1.1.1>v1.0.0 → v1.1.1</a></li><li>github.com/spf13/viper: <a href=https://github.com/spf13/viper/compare/v1.4.0...v1.7.0>v1.4.0 → v1.7.0</a></li><li>github.com/stretchr/testify: <a href=https://github.com/stretchr/testify/compare/v1.4.0...v1.6.1>v1.4.0 → v1.6.1</a></li><li>github.com/vishvananda/netns: <a href=https://github.com/vishvananda/netns/compare/52d707b...db3c7e5>52d707b → db3c7e5</a></li><li>go.opencensus.io: v0.22.2 → v0.22.3</li><li>golang.org/x/exp: da58074 → 6cc2880</li><li>golang.org/x/lint: fdd1cda → 738671d</li><li>golang.org/x/net: ab34263 → 69a7880</li><li>golang.org/x/oauth2: 858c2ad → bf48bf1</li><li>golang.org/x/sys: ed371f2 → 5cba982</li><li>golang.org/x/text: v0.3.3 → v0.3.4</li><li>golang.org/x/time: 555d28b → 3af7569</li><li>golang.org/x/xerrors: 9bdfabe → 5ec99f8</li><li>google.golang.org/api: v0.15.1 → v0.20.0</li><li>google.golang.org/genproto: cb27e3a → 8816d57</li><li>google.golang.org/grpc: v1.27.0 → v1.27.1</li><li>google.golang.org/protobuf: v1.24.0 → v1.25.0</li><li>honnef.co/go/tools: v0.0.1-2019.2.3 → v0.0.1-2020.1.3</li><li>k8s.io/gengo: 8167cfd → 83324d8</li><li>k8s.io/klog/v2: v2.2.0 → v2.4.0</li><li>k8s.io/kube-openapi: 8b50664 → d219536</li><li>k8s.io/utils: d5654de → 67b214c</li><li>sigs.k8s.io/apiserver-network-proxy/konnectivity-client: v0.0.12 → v0.0.14</li><li>sigs.k8s.io/structured-merge-diff/v4: b3cf1e8 → v4.0.2</li></ul><h3 id=removed-1>Removed</h3><ul><li>github.com/armon/consul-api: <a href=https://github.com/armon/consul-api/tree/eb2c6b5>eb2c6b5</a></li><li>github.com/go-ini/ini: <a href=https://github.com/go-ini/ini/tree/v1.9.0>v1.9.0</a></li><li>github.com/ugorji/go: <a href=https://github.com/ugorji/go/tree/v1.1.4>v1.1.4</a></li><li>github.com/xordataexchange/crypt: <a href=https://github.com/xordataexchange/crypt/tree/b2862e3>b2862e3</a></li></ul><h1 id=v1-20-0-beta-1>v1.20.0-beta.1</h1><h2 id=downloads-for-v1-20-0-beta-1>Downloads for v1.20.0-beta.1</h2><h3 id=source-code-2>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>4eddf4850c2d57751696f352d0667309339090aeb30ff93e8db8a22c6cdebf74cb2d5dc78d4ae384c4e25491efc39413e2e420a804b76b421a9ad934e56b0667</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>59de5221162e9b6d88f5abbdb99765cb2b2e501498ea853fb65f2abe390211e28d9f21e0d87be3ade550a5ea6395d04552cf093d2ce2f99fd45ad46545dd13cb</td></tr></tbody></table><h3 id=client-binaries-2>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>d69ffed19b034a4221fc084e43ac293cf392e98febf5bf580f8d92307a8421d8b3aab18f9ca70608937e836b42c7a34e829f88eba6e040218a4486986e2fca21</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>1b542e165860c4adcd4550adc19b86c3db8cd75d2a1b8db17becc752da78b730ee48f1b0aaf8068d7bfbb1d8e023741ec293543bc3dd0f4037172a6917db8169</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>90ad52785eecb43a6f9035b92b6ba39fc84e67f8bc91cf098e70f8cfdd405c4b9d5c02dccb21022f21bb5b6ce92fdef304def1da0a7255c308e2c5fb3a9cdaab</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>d0cb3322b056e1821679afa70728ffc0d3375e8f3326dabbe8185be2e60f665ab8985b13a1a432e10281b84a929e0f036960253ac0dd6e0b44677d539e98e61b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>3aecc8197e0aa368408624add28a2dd5e73f0d8a48e5e33c19edf91d5323071d16a27353a6f3e22df4f66ed7bfbae8e56e0a9050f7bbdf927ce6aeb29bba6374</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>6ff145058f62d478b98f1e418e272555bfb5c7861834fbbf10a8fb334cc7ff09b32f2666a54b230932ba71d2fc7d3b1c1f5e99e6fe6d6ec83926a9b931cd2474</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>ff7b8bb894076e05a3524f6327a4a6353b990466f3292e84c92826cb64b5c82b3855f48b8e297ccadc8bcc15552bc056419ff6ff8725fc4e640828af9cc1331b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>6c6dcac9c725605763a130b5a975f2b560aa976a5c809d4e0887900701b707baccb9ca1aebc10a03cfa7338a6f42922bbf838ccf6800fc2a3e231686a72568b6</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>d12e3a29c960f0ddd1b9aabf5426ac1259863ac6c8f2be1736ebeb57ddca6b1c747ee2c363be19e059e38cf71488c5ea3509ad4d0e67fd5087282a5ad0ae9a48</td></tr></tbody></table><h3 id=server-binaries-2>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>904e8c049179e071c6caa65f525f465260bb4d4318a6dd9cc05be2172f39f7cfc69d1672736e01d926045764fe8872e806444e3af77ffef823ede769537b7d20</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>5934959374868aed8d4294de84411972660bca7b2e952201a9403f37e40c60a5c53eaea8001344d0bf4a00c8cd27de6324d88161388de27f263a5761357cb82b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>4c884585970f80dc5462d9a734d7d5be9558b36c6e326a8a3139423efbd7284fa9f53fb077983647e17e19f03f5cb9bf26201450c78daecf10afa5a1ab5f9efc</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>235b78b08440350dcb9f13b63f7722bd090c672d8e724ca5d409256e5a5d4f46d431652a1aa908c3affc5b1e162318471de443d38b93286113e79e7f90501a9b</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>220fc9351702b3ecdcf79089892ceb26753a8a1deaf46922ffb3d3b62b999c93fef89440e779ca6043372b963081891b3a966d1a5df0cf261bdd44395fd28dce</td></tr></tbody></table><h3 id=node-binaries-2>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>fe59d3a1f21c47bab126f689687657f77fbcb46a2caeef48eecd073b2b22879f997a466911b5c5c829e9cf27e68a36ecdf18686d42714839d4b97d6c7281578d</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>93e545aa963cfd11e0b2c6d47669b5ef70c5a86ef80c3353c1a074396bff1e8e7371dda25c39d78c7a9e761f2607b8b5ab843fa0c10b8ff9663098fae8d25725</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>5e0f177f9bec406a668d4b37e69b191208551fdf289c82b5ec898959da4f8a00a2b0695cbf1d2de5acb809321c6e5604f5483d33556543d92b96dcf80e814dd3</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>574412059e4d257eb904cd4892a075b6a2cde27adfa4976ee64c46d6768facece338475f1b652ad94c8df7cfcbb70ebdf0113be109c7099ab76ffdb6f023eefd</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>b1ffaa6d7f77d89885c642663cb14a86f3e2ec2afd223e3bb2000962758cf0f15320969ffc4be93b5826ff22d54fdbae0dbea09f9d8228eda6da50b6fdc88758</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.1/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>388983765213cf3bdc1f8b27103ed79e39028767e5f1571e35ed1f91ed100e49f3027f7b7ff19b53fab7fbb6d723c0439f21fc6ed62be64532c25f5bfa7ee265</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-beta-0>Changelog since v1.20.0-beta.0</h2><h2 id=changes-by-kind-2>Changes by Kind</h2><h3 id=deprecation-1>Deprecation</h3><ul><li>ACTION REQUIRED: The kube-apiserver ability to serve on an insecure port, deprecated since v1.10, has been removed. The insecure address flags <code>--address</code> and <code>--insecure-bind-address</code> have no effect in kube-apiserver and will be removed in v1.24. The insecure port flags <code>--port</code> and <code>--insecure-port</code> may only be set to 0 and will be removed in v1.24. (<a href=https://github.com/kubernetes/kubernetes/pull/95856>#95856</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG API Machinery, Node and Testing]</li></ul><h3 id=api-change-1>API Change</h3><ul><li><ul><li><code>TokenRequest</code> and <code>TokenRequestProjection</code> features have been promoted to GA. This feature allows generating service account tokens that are not visible in Secret objects and are tied to the lifetime of a Pod object. See <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection>https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection</a> for details on configuring and using this feature. The <code>TokenRequest</code> and <code>TokenRequestProjection</code> feature gates will be removed in v1.21.</li><li>kubeadm's kube-apiserver Pod manifest now includes the following flags by default "--service-account-key-file", "--service-account-signing-key-file", "--service-account-issuer". (<a href=https://github.com/kubernetes/kubernetes/pull/93258>#93258</a>, <a href=https://github.com/zshihang>@zshihang</a>) [SIG API Machinery, Auth, Cluster Lifecycle, Storage and Testing]</li></ul></li><li>Certain fields on Service objects will be automatically cleared when changing the service's <code>type</code> to a mode that does not need those fields. For example, changing from type=LoadBalancer to type=ClusterIP will clear the NodePort assignments, rather than forcing the user to clear them. (<a href=https://github.com/kubernetes/kubernetes/pull/95196>#95196</a>, <a href=https://github.com/thockin>@thockin</a>) [SIG API Machinery, Apps, Network and Testing]</li><li>Services will now have a <code>clusterIPs</code> field to go with <code>clusterIP</code>. <code>clusterIPs[0]</code> is a synonym for <code>clusterIP</code> and will be syncronized on create and update operations. (<a href=https://github.com/kubernetes/kubernetes/pull/95894>#95894</a>, <a href=https://github.com/thockin>@thockin</a>) [SIG Network]</li></ul><h3 id=feature-2>Feature</h3><ul><li>A new metric <code>apiserver_request_filter_duration_seconds</code> has been introduced that
measures request filter latency in seconds. (<a href=https://github.com/kubernetes/kubernetes/pull/95207>#95207</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery and Instrumentation]</li><li>Add a new flag to set priority for the kubelet on Windows nodes so that workloads cannot overwhelm the node there by disrupting kubelet process. (<a href=https://github.com/kubernetes/kubernetes/pull/96051>#96051</a>, <a href=https://github.com/ravisantoshgudimetla>@ravisantoshgudimetla</a>) [SIG Node and Windows]</li><li>Changed: default "Accept: <em>/</em>" header added to HTTP probes. See <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes>https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#http-probes</a> (<a href=https://github.com/kubernetes/website/pull/24756>https://github.com/kubernetes/website/pull/24756</a>) (<a href=https://github.com/kubernetes/kubernetes/pull/95641>#95641</a>, <a href=https://github.com/fonsecas72>@fonsecas72</a>) [SIG Network and Node]</li><li>Client-go credential plugins can now be passed in the current cluster information via the KUBERNETES_EXEC_INFO environment variable. (<a href=https://github.com/kubernetes/kubernetes/pull/95489>#95489</a>, <a href=https://github.com/ankeesler>@ankeesler</a>) [SIG API Machinery and Auth]</li><li>Kube-apiserver: added support for compressing rotated audit log files with <code>--audit-log-compress</code> (<a href=https://github.com/kubernetes/kubernetes/pull/94066>#94066</a>, <a href=https://github.com/lojies>@lojies</a>) [SIG API Machinery and Auth]</li></ul><h3 id=documentation-1>Documentation</h3><ul><li>Fake dynamic client: document that List does not preserve TypeMeta in UnstructuredList (<a href=https://github.com/kubernetes/kubernetes/pull/95117>#95117</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG API Machinery]</li></ul><h3 id=bug-or-regression-2>Bug or Regression</h3><ul><li>Added support to kube-proxy for externalTrafficPolicy=Local setting via Direct Server Return (DSR) load balancers on Windows. (<a href=https://github.com/kubernetes/kubernetes/pull/93166>#93166</a>, <a href=https://github.com/elweb9858>@elweb9858</a>) [SIG Network]</li><li>Disable watchcache for events (<a href=https://github.com/kubernetes/kubernetes/pull/96052>#96052</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery]</li><li>Disabled <code>LocalStorageCapacityIsolation</code> feature gate is honored during scheduling. (<a href=https://github.com/kubernetes/kubernetes/pull/96092>#96092</a>, <a href=https://github.com/Huang-Wei>@Huang-Wei</a>) [SIG Scheduling]</li><li>Fix bug in JSON path parser where an error occurs when a range is empty (<a href=https://github.com/kubernetes/kubernetes/pull/95933>#95933</a>, <a href=https://github.com/brianpursley>@brianpursley</a>) [SIG API Machinery]</li><li>Fix k8s.io/apimachinery/pkg/api/meta.SetStatusCondition to update ObservedGeneration (<a href=https://github.com/kubernetes/kubernetes/pull/95961>#95961</a>, <a href=https://github.com/KnicKnic>@KnicKnic</a>) [SIG API Machinery]</li><li>Fixed a regression which prevented pods with <code>docker/default</code> seccomp annotations from being created in 1.19 if a PodSecurityPolicy was in place which did not allow <code>runtime/default</code> seccomp profiles. (<a href=https://github.com/kubernetes/kubernetes/pull/95985>#95985</a>, <a href=https://github.com/saschagrunert>@saschagrunert</a>) [SIG Auth]</li><li>Kubectl: print error if users place flags before plugin name (<a href=https://github.com/kubernetes/kubernetes/pull/92343>#92343</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG CLI]</li><li>When creating a PVC with the volume.beta.kubernetes.io/storage-provisioner annotation already set, the PV controller might have incorrectly deleted the newly provisioned PV instead of binding it to the PVC, depending on timing and system load. (<a href=https://github.com/kubernetes/kubernetes/pull/95909>#95909</a>, <a href=https://github.com/pohly>@pohly</a>) [SIG Apps and Storage]</li></ul><h3 id=other-cleanup-or-flake-1>Other (Cleanup or Flake)</h3><ul><li>Kubectl: the <code>generator</code> flag of <code>kubectl autoscale</code> has been deprecated and has no effect, it will be removed in a feature release (<a href=https://github.com/kubernetes/kubernetes/pull/92998>#92998</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG CLI]</li><li>V1helpers.MatchNodeSelectorTerms now accepts just a Node and a list of Terms (<a href=https://github.com/kubernetes/kubernetes/pull/95871>#95871</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Apps, Scheduling and Storage]</li><li><code>MatchNodeSelectorTerms</code> function moved to <code>k8s.io/component-helpers</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95531>#95531</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Apps, Scheduling and Storage]</li></ul><h2 id=dependencies-2>Dependencies</h2><h3 id=added-2>Added</h3><p><em>Nothing has changed.</em></p><h3 id=changed-2>Changed</h3><p><em>Nothing has changed.</em></p><h3 id=removed-2>Removed</h3><p><em>Nothing has changed.</em></p><h1 id=v1-20-0-beta-0>v1.20.0-beta.0</h1><h2 id=downloads-for-v1-20-0-beta-0>Downloads for v1.20.0-beta.0</h2><h3 id=source-code-3>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>385e49e32bbd6996f07bcadbf42285755b8a8ef9826ee1ba42bd82c65827cf13f63e5634b834451b263a93b708299cbb4b4b0b8ddbc688433deaf6bec240aa67</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>842e80f6dcad461426fb699de8a55fde8621d76a94e54288fe9939cc1a3bbd0f4799abadac2c59bcf3f91d743726dbd17e1755312ae7fec482ef560f336dbcbb</td></tr></tbody></table><h3 id=client-binaries-3>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>bde5e7d9ee3e79d1e69465a3ddb4bb36819a4f281b5c01a7976816d7c784410812dde133cdf941c47e5434e9520701b9c5e8b94d61dca77c172f87488dfaeb26</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>721bb8444c9e0d7a9f8461e3f5428882d76fcb3def6eb11b8e8e08fae7f7383630699248660d69d4f6a774124d6437888666e1fa81298d5b5518bc4a6a6b2c92</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>71e4edc41afbd65f813e7ecbc22b27c95f248446f005e288d758138dc4cc708735be7218af51bcf15e8b9893a3598c45d6a685f605b46f50af3762b02c32ed76</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>bbefc749156f63898973f2f7c7a6f1467481329fb430d641fe659b497e64d679886482d557ebdddb95932b93de8d1e3e365c91d4bf9f110b68bd94b0ba702ded</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>9803190685058b4b64d002c2fbfb313308bcea4734ed53a8c340cfdae4894d8cb13b3e819ae64051bafe0fbf8b6ecab53a6c1dcf661c57640c75b0eb60041113</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>bcdceea64cba1ae38ea2bab50d8fd77c53f6d673de12566050b0e3c204334610e6c19e4ace763e68b5e48ab9e811521208b852b1741627be30a2b17324fc1daf</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>41e36d00867e90012d5d5adfabfaae8d9f5a9fd32f290811e3c368e11822916b973afaaf43961081197f2cbab234090d97d89774e674aeadc1da61f7a64708a9</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>c50fec5aec2d0e742f851f25c236cb73e76f8fc73b0908049a10ae736c0205b8fff83eb3d29b1748412edd942da00dd738195d9003f25b577d6af8359d84fb2f</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>0fd6777c349908b6d627e849ea2d34c048b8de41f7df8a19898623f597e6debd35b7bcbf8e1d43a1be3a9abb45e4810bc498a0963cf780b109e93211659e9c7e</td></tr></tbody></table><h3 id=server-binaries-3>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>30d982424ca64bf0923503ae8195b2e2a59497096b2d9e58dfd491cd6639633027acfa9750bc7bccf34e1dc116d29d2f87cbd7ae713db4210ce9ac16182f0576</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>f08b62be9bc6f0745f820b0083c7a31eedb2ce370a037c768459a59192107b944c8f4345d0bb88fc975f2e7a803ac692c9ac3e16d4a659249d4600e84ff75d9e</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>e3472b5b3dfae0a56e5363d52062b1e4a9fc227a05e0cf5ece38233b2c442f427970aab94a52377fb87e583663c120760d154bc1c4ac22dca1f4d0d1ebb96088</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>06c254e0a62f755d31bc40093d86c44974f0a60308716cc3214a6b3c249a4d74534d909b82f8a3dd3a3c9720e61465b45d2bb3a327ef85d3caba865750020dfb</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>2edeb4411c26a0de057a66787091ab1044f71774a464aed898ffee26634a40127181c2edddb38e786b6757cca878fd0c3a885880eec6c3448b93c645770abb12</td></tr></tbody></table><h3 id=node-binaries-3>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>cc1d5b94b86070b5e7746d7aaeaeac3b3a5e5ebbff1ec33885f7eeab270a6177d593cb1975b2e56f4430b7859ad42da76f266629f9313e0f688571691ac448ed</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>75e82c7c9122add3b24695b94dcb0723c52420c3956abf47511e37785aa48a1fa8257db090c6601010c4475a325ccfff13eb3352b65e3aa1774f104b09b766b0</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>16ef27c40bf4d678a55fcd3d3f7d09f1597eec2cc58f9950946f0901e52b82287be397ad7f65e8d162d8a9cdb4a34a610b6db8b5d0462be8e27c4b6eb5d6e5e7</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>939865f2c4cb6a8934f22a06223e416dec5f768ffc1010314586149470420a1d62aef97527c34d8a636621c9669d6489908ce1caf96f109e8d073cee1c030b50</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>bbfdd844075fb816079af7b73d99bc1a78f41717cdbadb043f6f5872b4dc47bc619f7f95e2680d4b516146db492c630c17424e36879edb45e40c91bc2ae4493c</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-beta.0/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>a2b3ea40086fd71aed71a4858fd3fc79fd1907bc9ea8048ff3c82ec56477b0a791b724e5a52d79b3b36338c7fbd93dfd3d03b00ccea9042bda0d270fc891e4ec</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-alpha-3>Changelog since v1.20.0-alpha.3</h2><h2 id=urgent-upgrade-notes-1>Urgent Upgrade Notes</h2><h3 id=no-really-you-must-read-this-before-you-upgrade-1>(No, really, you MUST read this before you upgrade)</h3><ul><li>Kubeadm: improve the validation of serviceSubnet and podSubnet.
ServiceSubnet has to be limited in size, due to implementation details, and the mask can not allocate more than 20 bits.
PodSubnet validates against the corresponding cluster "--node-cidr-mask-size" of the kube-controller-manager, it fail if the values are not compatible.
kubeadm no longer sets the node-mask automatically on IPv6 deployments, you must check that your IPv6 service subnet mask is compatible with the default node mask /64 or set it accordenly.
Previously, for IPv6, if the podSubnet had a mask lower than /112, kubeadm calculated a node-mask to be multiple of eight and splitting the available bits to maximise the number used for nodes. (<a href=https://github.com/kubernetes/kubernetes/pull/95723>#95723</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Cluster Lifecycle]</li><li>Windows hyper-v container featuregate is deprecated in 1.20 and will be removed in 1.21 (<a href=https://github.com/kubernetes/kubernetes/pull/95505>#95505</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node and Windows]</li></ul><h2 id=changes-by-kind-3>Changes by Kind</h2><h3 id=deprecation-2>Deprecation</h3><ul><li>Support 'controlplane' as a valid EgressSelection type in the EgressSelectorConfiguration API. 'Master' is deprecated and will be removed in v1.22. (<a href=https://github.com/kubernetes/kubernetes/pull/95235>#95235</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG API Machinery]</li></ul><h3 id=api-change-2>API Change</h3><ul><li>Add dual-stack Services (alpha). This is a BREAKING CHANGE to an alpha API.
It changes the dual-stack API wrt Service from a single ipFamily field to 3
fields: ipFamilyPolicy (SingleStack, PreferDualStack, RequireDualStack),
ipFamilies (a list of families assigned), and clusterIPs (inclusive of
clusterIP). Most users do not need to set anything at all, defaulting will
handle it for them. Services are single-stack unless the user asks for
dual-stack. This is all gated by the "IPv6DualStack" feature gate. (<a href=https://github.com/kubernetes/kubernetes/pull/91824>#91824</a>, <a href=https://github.com/khenidak>@khenidak</a>) [SIG API Machinery, Apps, CLI, Network, Node, Scheduling and Testing]</li><li>Introduces a metric source for HPAs which allows scaling based on container resource usage. (<a href=https://github.com/kubernetes/kubernetes/pull/90691>#90691</a>, <a href=https://github.com/arjunrn>@arjunrn</a>) [SIG API Machinery, Apps, Autoscaling and CLI]</li></ul><h3 id=feature-3>Feature</h3><ul><li>Add a metric for time taken to perform recursive permission change (<a href=https://github.com/kubernetes/kubernetes/pull/95866>#95866</a>, <a href=https://github.com/JornShen>@JornShen</a>) [SIG Instrumentation and Storage]</li><li>Allow cross compilation of kubernetes on different platforms. (<a href=https://github.com/kubernetes/kubernetes/pull/94403>#94403</a>, <a href=https://github.com/bnrjee>@bnrjee</a>) [SIG Release]</li><li>Command to start network proxy changes from 'KUBE_ENABLE_EGRESS_VIA_KONNECTIVITY_SERVICE ./cluster/kube-up.sh' to 'KUBE_ENABLE_KONNECTIVITY_SERVICE=true ./hack/kube-up.sh' (<a href=https://github.com/kubernetes/kubernetes/pull/92669>#92669</a>, <a href=https://github.com/Jefftree>@Jefftree</a>) [SIG Cloud Provider]</li><li>DefaultPodTopologySpread graduated to Beta. The feature gate is enabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/95631>#95631</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling and Testing]</li><li>Kubernetes E2E test image manifest lists now contain Windows images. (<a href=https://github.com/kubernetes/kubernetes/pull/77398>#77398</a>, <a href=https://github.com/claudiubelu>@claudiubelu</a>) [SIG Testing and Windows]</li><li>Support for Windows container images (OS Versions: 1809, 1903, 1909, 2004) was added the pause:3.4 image. (<a href=https://github.com/kubernetes/kubernetes/pull/91452>#91452</a>, <a href=https://github.com/claudiubelu>@claudiubelu</a>) [SIG Node, Release and Windows]</li></ul><h3 id=documentation-2>Documentation</h3><ul><li>Fake dynamic client: document that List does not preserve TypeMeta in UnstructuredList (<a href=https://github.com/kubernetes/kubernetes/pull/95117>#95117</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG API Machinery]</li></ul><h3 id=bug-or-regression-3>Bug or Regression</h3><ul><li>Exposes and sets a default timeout for the SubjectAccessReview client for DelegatingAuthorizationOptions. (<a href=https://github.com/kubernetes/kubernetes/pull/95725>#95725</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery and Cloud Provider]</li><li>Alter wording to describe pods using a pvc (<a href=https://github.com/kubernetes/kubernetes/pull/95635>#95635</a>, <a href=https://github.com/RaunakShah>@RaunakShah</a>) [SIG CLI]</li><li>If we set SelectPolicy MinPolicySelect on scaleUp behavior or scaleDown behavior,Horizontal Pod Autoscaler doesn`t automatically scale the number of pods correctly (<a href=https://github.com/kubernetes/kubernetes/pull/95647>#95647</a>, <a href=https://github.com/JoshuaAndrew>@JoshuaAndrew</a>) [SIG Apps and Autoscaling]</li><li>Ignore apparmor for non-linux operating systems (<a href=https://github.com/kubernetes/kubernetes/pull/93220>#93220</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node and Windows]</li><li>Ipvs: ensure selected scheduler kernel modules are loaded (<a href=https://github.com/kubernetes/kubernetes/pull/93040>#93040</a>, <a href=https://github.com/cmluciano>@cmluciano</a>) [SIG Network]</li><li>Kubeadm: add missing "--experimental-patches" flag to "kubeadm init phase control-plane" (<a href=https://github.com/kubernetes/kubernetes/pull/95786>#95786</a>, <a href=https://github.com/Sh4d1>@Sh4d1</a>) [SIG Cluster Lifecycle]</li><li>Reorganized iptables rules to fix a performance issue (<a href=https://github.com/kubernetes/kubernetes/pull/95252>#95252</a>, <a href=https://github.com/tssurya>@tssurya</a>) [SIG Network]</li><li>Unhealthy pods covered by PDBs can be successfully evicted if enough healthy pods are available. (<a href=https://github.com/kubernetes/kubernetes/pull/94381>#94381</a>, <a href=https://github.com/michaelgugino>@michaelgugino</a>) [SIG Apps]</li><li>Update the PIP when it is not in the Succeeded provisioning state during the LB update. (<a href=https://github.com/kubernetes/kubernetes/pull/95748>#95748</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li><li>Update the frontend IP config when the service's <code>pipName</code> annotation is changed (<a href=https://github.com/kubernetes/kubernetes/pull/95813>#95813</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li></ul><h3 id=other-cleanup-or-flake-2>Other (Cleanup or Flake)</h3><ul><li>NO (<a href=https://github.com/kubernetes/kubernetes/pull/95690>#95690</a>, <a href=https://github.com/nikhita>@nikhita</a>) [SIG Release]</li></ul><h2 id=dependencies-3>Dependencies</h2><h3 id=added-3>Added</h3><ul><li>github.com/form3tech-oss/jwt-go: <a href=https://github.com/form3tech-oss/jwt-go/tree/v3.2.2>v3.2.2+incompatible</a></li></ul><h3 id=changed-3>Changed</h3><ul><li>github.com/Azure/go-autorest/autorest/adal: <a href=https://github.com/Azure/go-autorest/autorest/adal/compare/v0.9.0...v0.9.5>v0.9.0 → v0.9.5</a></li><li>github.com/Azure/go-autorest/autorest/mocks: <a href=https://github.com/Azure/go-autorest/autorest/mocks/compare/v0.4.0...v0.4.1>v0.4.0 → v0.4.1</a></li><li>golang.org/x/crypto: 75b2880 → 7f63de1</li></ul><h3 id=removed-3>Removed</h3><p><em>Nothing has changed.</em></p><h1 id=v1-20-0-alpha-3>v1.20.0-alpha.3</h1><h2 id=downloads-for-v1-20-0-alpha-3>Downloads for v1.20.0-alpha.3</h2><h3 id=source-code-4>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>542cc9e0cd97732020491456402b6e2b4f54f2714007ee1374a7d363663a1b41e82b50886176a5313aaccfbfd4df2bc611d6b32d19961cdc98b5821b75d6b17c</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>5e5d725294e552fd1d14fd6716d013222827ac2d4e2d11a7a1fdefb77b3459bbeb69931f38e1597de205dd32a1c9763ab524c2af1551faef4f502ef0890f7fbf</td></tr></tbody></table><h3 id=client-binaries-4>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>60004939727c75d0f06adc4449e16b43303941937c0e9ea9aca7d947e93a5aed5d11e53d1fc94caeb988be66d39acab118d406dc2d6cead61181e1ced6d2be1a</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>7edba9c4f1bf38fdf1fa5bff2856c05c0e127333ce19b17edf3119dc9b80462c027404a1f58a5eabf1de73a8f2f20aced043dda1fafd893619db1a188cda550c</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>db1818aa82d072cb3e32a2a988e66d76ecf7cebc6b8a29845fa2d6ec27f14a36e4b9839b1b7ed8c43d2da9cde00215eb672a7e8ee235d2e3107bc93c22e58d38</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>d2922e70d22364b1f5a1e94a0c115f849fe2575b231b1ba268f73a9d86fc0a9fbb78dc713446839a2593acf1341cb5a115992f350870f13c1a472bb107b75af7</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>2e3ae20e554c7d4fc3a8afdfcafe6bbc81d4c5e9aea036357baac7a3fdc2e8098aa8a8c3dded3951667d57f667ce3fbf37ec5ae5ceb2009a569dc9002d3a92f9</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>b54a34e572e6a86221577de376e6f7f9fcd82327f7fe94f2fc8d21f35d302db8a0f3d51e60dc89693999f5df37c96d0c3649a29f07f095efcdd59923ae285c95</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>5be1b70dc437d3ba88cb0b89cd1bc555f79896c3f5b5f4fa0fb046a0d09d758b994d622ebe5cef8e65bba938c5ae945b81dc297f9dfa0d98f82ea75f344a3a0d</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>88cf3f66168ef3bf9a5d3d2275b7f33799406e8205f2c202997ebec23d449aa4bb48b010356ab1cf52ff7b527b8df7c8b9947a43a82ebe060df83c3d21b7223a</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>87d2d4ea1829da8cfa1a705a03ea26c759a03bd1c4d8b96f2c93264c4d172bb63a91d9ddda65cdc5478b627c30ae8993db5baf8be262c157d83bffcebe85474e</td></tr></tbody></table><h3 id=server-binaries-4>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>7af691fc0b13a937797912374e3b3eeb88d5262e4eb7d4ebe92a3b64b3c226cb049aedfd7e39f639f6990444f7bcf2fe58699cf0c29039daebe100d7eebf60de</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>557c47870ecf5c2090b2694c8f0c8e3b4ca23df5455a37945bd037bc6fb5b8f417bf737bb66e6336b285112cb52de0345240fdb2f3ce1c4fb335ca7ef1197f99</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>981de6cf7679d743cdeef1e894314357b68090133814801870504ef30564e32b5675e270db20961e9a731e35241ad9b037bdaf749da87b6c4ce8889eeb1c5855</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>506578a21601ccff609ae757a55e68634c15cbfecbf13de972c96b32a155ded29bd71aee069c77f5f721416672c7a7ac0b8274de22bfd28e1ecae306313d96c5</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>af0cdcd4a77a7cc8060a076641615730a802f1f02dab084e41926023489efec6102d37681c70ab0dbe7440cd3e72ea0443719a365467985360152b9aae657375</td></tr></tbody></table><h3 id=node-binaries-4>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>2d92c61596296279de1efae23b2b707415565d9d50cd61a7231b8d10325732b059bcb90f3afb36bef2575d203938c265572721e38df408e8792d3949523bd5d9</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>c298de9b5ac1b8778729a2d8e2793ff86743033254fbc27014333880b03c519de81691caf03aa418c729297ee8942ce9ec89d11b0e34a80576b9936015dc1519</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>daa3c65afda6d7aff206c1494390bbcc205c2c6f8db04c10ca967a690578a01c49d49c6902b85e7158f79fd4d2a87c5d397d56524a75991c9d7db85ac53059a7</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>05661908bb73bfcaf9c2eae96e9a6a793db5a7a100bce6df9e057985dd53a7a5248d72e81b6d13496bd38b9326c17cdb2edaf0e982b6437507245fb846e1efc6</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>845e518e2c4ef0cef2c3b58f0b9ea5b5fe9b8a249717f789607752484c424c26ae854b263b7c0a004a8426feb9aa3683c177a9ed2567e6c3521f4835ea08c24a</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.3/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>530e536574ed2c3e5973d3c0f0fdd2b4d48ef681a7a7c02db13e605001669eeb4f4b8a856fc08fc21436658c27b377f5d04dbcb3aae438098abc953b6eaf5712</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-alpha-2>Changelog since v1.20.0-alpha.2</h2><h2 id=changes-by-kind-4>Changes by Kind</h2><h3 id=api-change-3>API Change</h3><ul><li>New parameter <code>defaultingType</code> for <code>PodTopologySpread</code> plugin allows to use k8s defined or user provided default constraints (<a href=https://github.com/kubernetes/kubernetes/pull/95048>#95048</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</li></ul><h3 id=feature-4>Feature</h3><ul><li>Added new k8s.io/component-helpers repository providing shared helper code for (core) components. (<a href=https://github.com/kubernetes/kubernetes/pull/92507>#92507</a>, <a href=https://github.com/ingvagabund>@ingvagabund</a>) [SIG Apps, Node, Release and Scheduling]</li><li>Adds <code>create ingress</code> command to <code>kubectl</code> (<a href=https://github.com/kubernetes/kubernetes/pull/78153>#78153</a>, <a href=https://github.com/amimof>@amimof</a>) [SIG CLI and Network]</li><li>Kubectl create now supports creating ingress objects. (<a href=https://github.com/kubernetes/kubernetes/pull/94327>#94327</a>, <a href=https://github.com/rikatz>@rikatz</a>) [SIG CLI and Network]</li><li>New default scheduling plugins order reduces scheduling and preemption latency when taints and node affinity are used (<a href=https://github.com/kubernetes/kubernetes/pull/95539>#95539</a>, <a href=https://github.com/soulxu>@soulxu</a>) [SIG Scheduling]</li><li>SCTP support in API objects (Pod, Service, NetworkPolicy) is now GA.
Note that this has no effect on whether SCTP is enabled on nodes at the kernel level,
and note that some cloud platforms and network plugins do not support SCTP traffic. (<a href=https://github.com/kubernetes/kubernetes/pull/95566>#95566</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Apps and Network]</li><li>Scheduling Framework: expose Run[Pre]ScorePlugins functions to PreemptionHandle which can be used in PostFilter extention point. (<a href=https://github.com/kubernetes/kubernetes/pull/93534>#93534</a>, <a href=https://github.com/everpeace>@everpeace</a>) [SIG Scheduling and Testing]</li><li>SelectorSpreadPriority maps to PodTopologySpread plugin when DefaultPodTopologySpread feature is enabled (<a href=https://github.com/kubernetes/kubernetes/pull/95448>#95448</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</li><li>SetHostnameAsFQDN has been graduated to Beta and therefore it is enabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/95267>#95267</a>, <a href=https://github.com/javidiaz>@javidiaz</a>) [SIG Node]</li></ul><h3 id=bug-or-regression-4>Bug or Regression</h3><ul><li>An issues preventing volume expand controller to annotate the PVC with <code>volume.kubernetes.io/storage-resizer</code> when the PVC StorageClass is already updated to the out-of-tree provisioner is now fixed. (<a href=https://github.com/kubernetes/kubernetes/pull/94489>#94489</a>, <a href=https://github.com/ialidzhikov>@ialidzhikov</a>) [SIG API Machinery, Apps and Storage]</li><li>Change the mount way from systemd to normal mount except ceph and glusterfs intree-volume. (<a href=https://github.com/kubernetes/kubernetes/pull/94916>#94916</a>, <a href=https://github.com/smileusd>@smileusd</a>) [SIG Apps, Cloud Provider, Network, Node, Storage and Testing]</li><li>Fix azure disk attach failure for disk size bigger than 4TB (<a href=https://github.com/kubernetes/kubernetes/pull/95463>#95463</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</li><li>Fix azure disk data loss issue on Windows when unmount disk (<a href=https://github.com/kubernetes/kubernetes/pull/95456>#95456</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</li><li>Fix verb & scope reporting for kube-apiserver metrics (LIST reported instead of GET) (<a href=https://github.com/kubernetes/kubernetes/pull/95562>#95562</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Testing]</li><li>Fix vsphere detach failure for static PVs (<a href=https://github.com/kubernetes/kubernetes/pull/95447>#95447</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Cloud Provider and Storage]</li><li>Fix: smb valid path error (<a href=https://github.com/kubernetes/kubernetes/pull/95583>#95583</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Storage]</li><li>Fixed a bug causing incorrect formatting of <code>kubectl describe ingress</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/94985>#94985</a>, <a href=https://github.com/howardjohn>@howardjohn</a>) [SIG CLI and Network]</li><li>Fixed a bug in client-go where new clients with customized <code>Dial</code>, <code>Proxy</code>, <code>GetCert</code> config may get stale HTTP transports. (<a href=https://github.com/kubernetes/kubernetes/pull/95427>#95427</a>, <a href=https://github.com/roycaihw>@roycaihw</a>) [SIG API Machinery]</li><li>Fixes high CPU usage in kubectl drain (<a href=https://github.com/kubernetes/kubernetes/pull/95260>#95260</a>, <a href=https://github.com/amandahla>@amandahla</a>) [SIG CLI]</li><li>Support the node label <code>node.kubernetes.io/exclude-from-external-load-balancers</code> (<a href=https://github.com/kubernetes/kubernetes/pull/95542>#95542</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</li></ul><h3 id=other-cleanup-or-flake-3>Other (Cleanup or Flake)</h3><ul><li>Fix func name NewCreateCreateDeploymentOptions (<a href=https://github.com/kubernetes/kubernetes/pull/91931>#91931</a>, <a href=https://github.com/lixiaobing1>@lixiaobing1</a>) [SIG CLI]</li><li>Kubeadm: update the default pause image version to 1.4.0 on Windows. With this update the image supports Windows versions 1809 (2019LTS), 1903, 1909, 2004 (<a href=https://github.com/kubernetes/kubernetes/pull/95419>#95419</a>, <a href=https://github.com/jsturtevant>@jsturtevant</a>) [SIG Cluster Lifecycle and Windows]</li><li>Upgrade snapshot controller to 3.0.0 (<a href=https://github.com/kubernetes/kubernetes/pull/95412>#95412</a>, <a href=https://github.com/saikat-royc>@saikat-royc</a>) [SIG Cloud Provider]</li><li>Remove the dependency of csi-translation-lib module on apiserver/cloud-provider/controller-manager (<a href=https://github.com/kubernetes/kubernetes/pull/95543>#95543</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Release]</li><li>Scheduler framework interface moved from pkg/scheduler/framework/v1alpha to pkg/scheduler/framework (<a href=https://github.com/kubernetes/kubernetes/pull/95069>#95069</a>, <a href=https://github.com/farah>@farah</a>) [SIG Scheduling, Storage and Testing]</li><li>UDP and SCTP protocols can left stale connections that need to be cleared to avoid services disruption, but they can cause problems that are hard to debug.
Kubernetes components using a loglevel greater or equal than 4 will log the conntrack operations and its output, to show the entries that were deleted. (<a href=https://github.com/kubernetes/kubernetes/pull/95694>#95694</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Network]</li></ul><h2 id=dependencies-4>Dependencies</h2><h3 id=added-4>Added</h3><p><em>Nothing has changed.</em></p><h3 id=changed-4>Changed</h3><p><em>Nothing has changed.</em></p><h3 id=removed-4>Removed</h3><p><em>Nothing has changed.</em></p><h1 id=v1-20-0-alpha-2>v1.20.0-alpha.2</h1><h2 id=downloads-for-v1-20-0-alpha-2>Downloads for v1.20.0-alpha.2</h2><h3 id=source-code-5>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>45089a4d26d56a5d613ecbea64e356869ac738eca3cc71d16b74ea8ae1b4527bcc32f1dc35ff7aa8927e138083c7936603faf063121d965a2f0f8ba28fa128d8</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>646edd890d6df5858b90aaf68cc6e1b4589b8db09396ae921b5c400f2188234999e6c9633906692add08c6e8b4b09f12b2099132b0a7533443fb2a01cfc2bf81</td></tr></tbody></table><h3 id=client-binaries-5>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>c136273883e24a2a50b5093b9654f01cdfe57b97461d34885af4a68c2c4d108c07583c02b1cdf7f57f82e91306e542ce8f3bddb12fcce72b744458bc4796f8eb</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>6ec59f1ed30569fa64ddb2d0de32b1ae04cda4ffe13f339050a7c9d7c63d425ee6f6d963dcf82c17281c4474da3eaf32c08117669052872a8c81bdce2c8a5415</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>7b40a4c087e2ea7f8d055f297fcd39a3f1cb6c866e7a3981a9408c3c3eb5363c648613491aad11bc7d44d5530b20832f8f96f6ceff43deede911fb74aafad35f</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>cda9955feebea5acb8f2b5b87895d24894bbbbde47041453b1f926ebdf47a258ce0496aa27d06bcbf365b5615ce68a20d659b64410c54227216726e2ee432fca</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>f65bd9241c7eb88a4886a285330f732448570aea4ededaebeabcf70d17ea185f51bf8a7218f146ee09fb1adceca7ee71fb3c3683834f2c415163add820fba96e</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>1e377599af100a81d027d9199365fb8208d443a8e0a97affff1a79dc18796e14b78cb53d6e245c1c1e8defd0e050e37bf5f2a23c8a3ff45a6d18d03619709bf5</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>1cdee81478246aa7e7b80ae4efc7f070a5b058083ae278f59fad088b75a8052761b0e15ab261a6e667ddafd6a69fb424fc307072ed47941cad89a85af7aee93d</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>d8774167c87b6844c348aa15e92d5033c528d6ab9e95d08a7cb22da68bafd8e46d442cf57a5f6affad62f674c10ae6947d524b94108b5e450ca78f92656d63c0</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>f664b47d8daa6036f8154c1dc1f881bfe683bf57c39d9b491de3848c03d051c50c6644d681baf7f9685eae45f9ce62e4c6dfea2853763cfe8256a61bdd59d894</td></tr></tbody></table><h3 id=server-binaries-5>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>d6fcb4600be0beb9de222a8da64c35fe22798a0da82d41401d34d0f0fc7e2817512169524c281423d8f4a007cd77452d966317d5a1b67d2717a05ff346e8aa7d</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>022a76cf10801f8afbabb509572479b68fdb4e683526fa0799cdbd9bab4d3f6ecb76d1d63d0eafee93e3edf6c12892d84b9c771ef2325663b95347728fa3d6c0</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>0679aadd60bbf6f607e5befad74b5267eb2d4c1b55985cc25a97e0f4c5efb7acbb3ede91bfa6a5a5713dae4d7a302f6faaf678fd6b359284c33d9a6aca2a08bb</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>9f2cfeed543b515eafb60d9765a3afff4f3d323c0a5c8a0d75e3de25985b2627817bfcbe59a9a61d969e026e2b861adb974a09eae75b58372ed736ceaaed2a82</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>937258704d7b9dcd91f35f2d34ee9dd38c18d9d4e867408c05281bfbbb919ad012c95880bee84d2674761aa44cc617fb2fae1124cf63b689289286d6eac1c407</td></tr></tbody></table><h3 id=node-binaries-5>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>076165d745d47879de68f4404eaf432920884be48277eb409e84bf2c61759633bf3575f46b0995f1fc693023d76c0921ed22a01432e756d7f8d9e246a243b126</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>1ff2e2e3e43af41118cdfb70c778e15035bbb1aca833ffd2db83c4bcd44f55693e956deb9e65017ebf3c553f2820ad5cd05f5baa33f3d63f3e00ed980ea4dfed</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>b232c7359b8c635126899beee76998078eec7a1ef6758d92bcdebe8013b0b1e4d7b33ecbf35e3f82824fe29493400845257e70ed63c1635bfa36c8b3b4969f6f</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>51d415a068f554840f4c78d11a4fedebd7cb03c686b0ec864509b24f7a8667ebf54bb0a25debcf2b70f38be1e345e743f520695b11806539a55a3620ce21946f</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>b51c082d8af358233a088b632cf2f6c8cfe5421471c27f5dc9ba4839ae6ea75df25d84298f2042770097554c01742bb7686694b331ad9bafc93c86317b867728</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.2/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>91b9d26620a2dde67a0edead0039814efccbdfd54594dda3597aaced6d89140dc92612ed0727bc21d63468efeef77c845e640153b09e39d8b736062e6eee0c76</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-alpha-1>Changelog since v1.20.0-alpha.1</h2><h2 id=changes-by-kind-5>Changes by Kind</h2><h3 id=deprecation-3>Deprecation</h3><ul><li>Action-required: kubeadm: graduate the "kubeadm alpha certs" command to a parent command "kubeadm certs". The command "kubeadm alpha certs" is deprecated and will be removed in a future release. Please migrate. (<a href=https://github.com/kubernetes/kubernetes/pull/94938>#94938</a>, <a href=https://github.com/yagonobre>@yagonobre</a>) [SIG Cluster Lifecycle]</li><li>Action-required: kubeadm: remove the deprecated feature --experimental-kustomize from kubeadm commands. The feature was replaced with --experimental-patches in 1.19. To migrate see the --help description for the --experimental-patches flag. (<a href=https://github.com/kubernetes/kubernetes/pull/94871>#94871</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: deprecate self-hosting support. The experimental command "kubeadm alpha self-hosting" is now deprecated and will be removed in a future release. (<a href=https://github.com/kubernetes/kubernetes/pull/95125>#95125</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Removes deprecated scheduler metrics DeprecatedSchedulingDuration, DeprecatedSchedulingAlgorithmPredicateEvaluationSecondsDuration, DeprecatedSchedulingAlgorithmPriorityEvaluationSecondsDuration (<a href=https://github.com/kubernetes/kubernetes/pull/94884>#94884</a>, <a href=https://github.com/arghya88>@arghya88</a>) [SIG Instrumentation and Scheduling]</li><li>Scheduler alpha metrics binding_duration_seconds and scheduling_algorithm_preemption_evaluation_seconds are deprecated, Both of those metrics are now covered as part of framework_extension_point_duration_seconds, the former as a PostFilter the latter and a Bind plugin. The plan is to remove both in 1.21 (<a href=https://github.com/kubernetes/kubernetes/pull/95001>#95001</a>, <a href=https://github.com/arghya88>@arghya88</a>) [SIG Instrumentation and Scheduling]</li></ul><h3 id=api-change-4>API Change</h3><ul><li>GPU metrics provided by kubelet are now disabled by default (<a href=https://github.com/kubernetes/kubernetes/pull/95184>#95184</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>) [SIG Node]</li><li>New parameter <code>defaultingType</code> for <code>PodTopologySpread</code> plugin allows to use k8s defined or user provided default constraints (<a href=https://github.com/kubernetes/kubernetes/pull/95048>#95048</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</li><li>Server Side Apply now treats LabelSelector fields as atomic (meaning the entire selector is managed by a single writer and updated together), since they contain interrelated and inseparable fields that do not merge in intuitive ways. (<a href=https://github.com/kubernetes/kubernetes/pull/93901>#93901</a>, <a href=https://github.com/jpbetz>@jpbetz</a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Storage and Testing]</li><li>Status of v1beta1 CRDs without "preserveUnknownFields:false" will show violation "spec.preserveUnknownFields: Invalid value: true: must be false" (<a href=https://github.com/kubernetes/kubernetes/pull/93078>#93078</a>, <a href=https://github.com/vareti>@vareti</a>) [SIG API Machinery]</li></ul><h3 id=feature-5>Feature</h3><ul><li><p>Added <code>get-users</code> and <code>delete-user</code> to the <code>kubectl config</code> subcommand (<a href=https://github.com/kubernetes/kubernetes/pull/89840>#89840</a>, <a href=https://github.com/eddiezane>@eddiezane</a>) [SIG CLI]</p></li><li><p>Added counter metric "apiserver_request_self" to count API server self-requests with labels for verb, resource, and subresource. (<a href=https://github.com/kubernetes/kubernetes/pull/94288>#94288</a>, <a href=https://github.com/LogicalShark>@LogicalShark</a>) [SIG API Machinery, Auth, Instrumentation and Scheduling]</p></li><li><p>Added new k8s.io/component-helpers repository providing shared helper code for (core) components. (<a href=https://github.com/kubernetes/kubernetes/pull/92507>#92507</a>, <a href=https://github.com/ingvagabund>@ingvagabund</a>) [SIG Apps, Node, Release and Scheduling]</p></li><li><p>Adds <code>create ingress</code> command to <code>kubectl</code> (<a href=https://github.com/kubernetes/kubernetes/pull/78153>#78153</a>, <a href=https://github.com/amimof>@amimof</a>) [SIG CLI and Network]</p></li><li><p>Allow configuring AWS LoadBalancer health check protocol via service annotations (<a href=https://github.com/kubernetes/kubernetes/pull/94546>#94546</a>, <a href=https://github.com/kishorj>@kishorj</a>) [SIG Cloud Provider]</p></li><li><p>Azure: Support multiple services sharing one IP address (<a href=https://github.com/kubernetes/kubernetes/pull/94991>#94991</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider]</p></li><li><p>Ephemeral containers now apply the same API defaults as initContainers and containers (<a href=https://github.com/kubernetes/kubernetes/pull/94896>#94896</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Apps and CLI]</p></li><li><p>In dual-stack bare-metal clusters, you can now pass dual-stack IPs to <code>kubelet --node-ip</code>.
eg: <code>kubelet --node-ip 10.1.0.5,fd01::0005</code>. This is not yet supported for non-bare-metal
clusters.</p><p>In dual-stack clusters where nodes have dual-stack addresses, hostNetwork pods
will now get dual-stack PodIPs. (<a href=https://github.com/kubernetes/kubernetes/pull/95239>#95239</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Network and Node]</p></li><li><p>Introduces a new GCE specific cluster creation variable KUBE_PROXY_DISABLE. When set to true, this will skip over the creation of kube-proxy (whether the daemonset or static pod). This can be used to control the lifecycle of kube-proxy separately from the lifecycle of the nodes. (<a href=https://github.com/kubernetes/kubernetes/pull/91977>#91977</a>, <a href=https://github.com/varunmar>@varunmar</a>) [SIG Cloud Provider]</p></li><li><p>Kubeadm: do not throw errors if the current system time is outside of the NotBefore and NotAfter bounds of a loaded certificate. Print warnings instead. (<a href=https://github.com/kubernetes/kubernetes/pull/94504>#94504</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: make the command "kubeadm alpha kubeconfig user" accept a "--config" flag and remove the following flags:</p><ul><li>apiserver-advertise-address / apiserver-bind-port: use either localAPIEndpoint from InitConfiguration or controlPlaneEndpoint from ClusterConfiguration.</li><li>cluster-name: use clusterName from ClusterConfiguration</li><li>cert-dir: use certificatesDir from ClusterConfiguration (<a href=https://github.com/kubernetes/kubernetes/pull/94879>#94879</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cluster Lifecycle]</li></ul></li><li><p>Kubectl rollout history sts/sts-name --revision=some-revision will start showing the detailed view of the sts on that specified revision (<a href=https://github.com/kubernetes/kubernetes/pull/86506>#86506</a>, <a href=https://github.com/dineshba>@dineshba</a>) [SIG CLI]</p></li><li><p>Scheduling Framework: expose Run[Pre]ScorePlugins functions to PreemptionHandle which can be used in PostFilter extention point. (<a href=https://github.com/kubernetes/kubernetes/pull/93534>#93534</a>, <a href=https://github.com/everpeace>@everpeace</a>) [SIG Scheduling and Testing]</p></li><li><p>Send gce node startup scripts logs to console and journal (<a href=https://github.com/kubernetes/kubernetes/pull/95311>#95311</a>, <a href=https://github.com/karan>@karan</a>) [SIG Cloud Provider and Node]</p></li><li><p>Support kubectl delete orphan/foreground/background options (<a href=https://github.com/kubernetes/kubernetes/pull/93384>#93384</a>, <a href=https://github.com/zhouya0>@zhouya0</a>) [SIG CLI and Testing]</p></li></ul><h3 id=bug-or-regression-5>Bug or Regression</h3><ul><li>Change the mount way from systemd to normal mount except ceph and glusterfs intree-volume. (<a href=https://github.com/kubernetes/kubernetes/pull/94916>#94916</a>, <a href=https://github.com/smileusd>@smileusd</a>) [SIG Apps, Cloud Provider, Network, Node, Storage and Testing]</li><li>Cloud node controller: handle empty providerID from getProviderID (<a href=https://github.com/kubernetes/kubernetes/pull/95342>#95342</a>, <a href=https://github.com/nicolehanjing>@nicolehanjing</a>) [SIG Cloud Provider]</li><li>Fix a bug where the endpoint slice controller was not mirroring the parent service labels to its corresponding endpoint slices (<a href=https://github.com/kubernetes/kubernetes/pull/94443>#94443</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Apps and Network]</li><li>Fix azure disk attach failure for disk size bigger than 4TB (<a href=https://github.com/kubernetes/kubernetes/pull/95463>#95463</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</li><li>Fix azure disk data loss issue on Windows when unmount disk (<a href=https://github.com/kubernetes/kubernetes/pull/95456>#95456</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</li><li>Fix detach azure disk issue when vm not exist (<a href=https://github.com/kubernetes/kubernetes/pull/95177>#95177</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</li><li>Fix network_programming_latency metric reporting for Endpoints/EndpointSlice deletions, where we don't have correct timestamp (<a href=https://github.com/kubernetes/kubernetes/pull/95363>#95363</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG Network and Scalability]</li><li>Fix scheduler cache snapshot when a Node is deleted before its Pods (<a href=https://github.com/kubernetes/kubernetes/pull/95130>#95130</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scheduling]</li><li>Fix vsphere detach failure for static PVs (<a href=https://github.com/kubernetes/kubernetes/pull/95447>#95447</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Cloud Provider and Storage]</li><li>Fixed a bug that prevents the use of ephemeral containers in the presence of a validating admission webhook. (<a href=https://github.com/kubernetes/kubernetes/pull/94685>#94685</a>, <a href=https://github.com/verb>@verb</a>) [SIG Node and Testing]</li><li>Gracefully delete nodes when their parent scale set went missing (<a href=https://github.com/kubernetes/kubernetes/pull/95289>#95289</a>, <a href=https://github.com/bpineau>@bpineau</a>) [SIG Cloud Provider]</li><li>In dual-stack clusters, kubelet will now set up both IPv4 and IPv6 iptables rules, which may
fix some problems, eg with HostPorts. (<a href=https://github.com/kubernetes/kubernetes/pull/94474>#94474</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Network and Node]</li><li>Kubeadm: for Docker as the container runtime, make the "kubeadm reset" command stop containers before removing them (<a href=https://github.com/kubernetes/kubernetes/pull/94586>#94586</a>, <a href=https://github.com/BedivereZero>@BedivereZero</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: warn but do not error out on missing "ca.key" files for root CA, front-proxy CA and etcd CA, during "kubeadm join --control-plane" if the user has provided all certificates, keys and kubeconfig files which require signing with the given CA keys. (<a href=https://github.com/kubernetes/kubernetes/pull/94988>#94988</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Port mapping allows to map the same <code>containerPort</code> to multiple <code>hostPort</code> without naming the mapping explicitly. (<a href=https://github.com/kubernetes/kubernetes/pull/94494>#94494</a>, <a href=https://github.com/SergeyKanzhelev>@SergeyKanzhelev</a>) [SIG Network and Node]</li><li>Warn instead of fail when creating Roles and ClusterRoles with custom verbs via kubectl (<a href=https://github.com/kubernetes/kubernetes/pull/92492>#92492</a>, <a href=https://github.com/eddiezane>@eddiezane</a>) [SIG CLI]</li></ul><h3 id=other-cleanup-or-flake-4>Other (Cleanup or Flake)</h3><ul><li>Added fine grained debugging to the intra-pod conformance test for helping easily resolve networking issues for nodes that might be unhealthy when running conformance or sonobuoy tests. (<a href=https://github.com/kubernetes/kubernetes/pull/93837>#93837</a>, <a href=https://github.com/jayunit100>@jayunit100</a>) [SIG Network and Testing]</li><li>AdmissionReview objects sent for the creation of Namespace API objects now populate the <code>namespace</code> attribute consistently (previously the <code>namespace</code> attribute was empty for Namespace creation via POST requests, and populated for Namespace creation via server-side-apply PATCH requests) (<a href=https://github.com/kubernetes/kubernetes/pull/95012>#95012</a>, <a href=https://github.com/nodo>@nodo</a>) [SIG API Machinery and Testing]</li><li>Client-go header logging (at verbosity levels >= 9) now masks <code>Authorization</code> header contents (<a href=https://github.com/kubernetes/kubernetes/pull/95316>#95316</a>, <a href=https://github.com/sfowl>@sfowl</a>) [SIG API Machinery]</li><li>Enhance log information of verifyRunAsNonRoot, add pod, container information (<a href=https://github.com/kubernetes/kubernetes/pull/94911>#94911</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node]</li><li>Errors from staticcheck:<br>vendor/k8s.io/client-go/discovery/cached/memory/memcache_test.go:94:2: this value of g is never used (SA4006) (<a href=https://github.com/kubernetes/kubernetes/pull/95098>#95098</a>, <a href=https://github.com/phunziker>@phunziker</a>) [SIG API Machinery]</li><li>Kubeadm: update the default pause image version to 1.4.0 on Windows. With this update the image supports Windows versions 1809 (2019LTS), 1903, 1909, 2004 (<a href=https://github.com/kubernetes/kubernetes/pull/95419>#95419</a>, <a href=https://github.com/jsturtevant>@jsturtevant</a>) [SIG Cluster Lifecycle and Windows]</li><li>Masks ceph RBD adminSecrets in logs when logLevel >= 4 (<a href=https://github.com/kubernetes/kubernetes/pull/95245>#95245</a>, <a href=https://github.com/sfowl>@sfowl</a>) [SIG Storage]</li><li>Upgrade snapshot controller to 3.0.0 (<a href=https://github.com/kubernetes/kubernetes/pull/95412>#95412</a>, <a href=https://github.com/saikat-royc>@saikat-royc</a>) [SIG Cloud Provider]</li><li>Remove offensive words from kubectl cluster-info command (<a href=https://github.com/kubernetes/kubernetes/pull/95202>#95202</a>, <a href=https://github.com/rikatz>@rikatz</a>) [SIG Architecture, CLI and Testing]</li><li>The following new metrics are available.<ul><li>network_plugin_operations_total</li><li>network_plugin_operations_errors_total (<a href=https://github.com/kubernetes/kubernetes/pull/93066>#93066</a>, <a href=https://github.com/AnishShah>@AnishShah</a>) [SIG Instrumentation, Network and Node]</li></ul></li><li>Vsphere: improve logging message on node cache refresh event (<a href=https://github.com/kubernetes/kubernetes/pull/95236>#95236</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Cloud Provider]</li><li><code>kubectl api-resources</code> now prints the API version (as 'API group/version', same as output of <code>kubectl api-versions</code>). The column APIGROUP is now APIVERSION (<a href=https://github.com/kubernetes/kubernetes/pull/95253>#95253</a>, <a href=https://github.com/sallyom>@sallyom</a>) [SIG CLI]</li></ul><h2 id=dependencies-5>Dependencies</h2><h3 id=added-5>Added</h3><ul><li>github.com/jmespath/go-jmespath/internal/testify: <a href=https://github.com/jmespath/go-jmespath/internal/testify/tree/v1.5.1>v1.5.1</a></li></ul><h3 id=changed-5>Changed</h3><ul><li>github.com/aws/aws-sdk-go: <a href=https://github.com/aws/aws-sdk-go/compare/v1.28.2...v1.35.5>v1.28.2 → v1.35.5</a></li><li>github.com/jmespath/go-jmespath: <a href=https://github.com/jmespath/go-jmespath/compare/c2b33e8...v0.4.0>c2b33e8 → v0.4.0</a></li><li>k8s.io/kube-openapi: 6aeccd4 → 8b50664</li><li>sigs.k8s.io/apiserver-network-proxy/konnectivity-client: v0.0.9 → v0.0.12</li><li>sigs.k8s.io/structured-merge-diff/v4: v4.0.1 → b3cf1e8</li></ul><h3 id=removed-5>Removed</h3><p><em>Nothing has changed.</em></p><h1 id=v1-20-0-alpha-1>v1.20.0-alpha.1</h1><h2 id=downloads-for-v1-20-0-alpha-1>Downloads for v1.20.0-alpha.1</h2><h3 id=source-code-6>Source Code</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes.tar.gz>kubernetes.tar.gz</a></td><td>e7daed6502ea07816274f2371f96fe1a446d0d7917df4454b722d9eb3b5ff6163bfbbd5b92dfe7a0c1d07328b8c09c4ae966e482310d6b36de8813aaf87380b5</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-src.tar.gz>kubernetes-src.tar.gz</a></td><td>e91213a0919647a1215d4691a63b12d89a3e74055463a8ebd71dc1a4cabf4006b3660881067af0189960c8dab74f4a7faf86f594df69021901213ee5b56550ea</td></tr></tbody></table><h3 id=client-binaries-6>Client binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-darwin-amd64.tar.gz>kubernetes-client-darwin-amd64.tar.gz</a></td><td>1f3add5f826fa989820d715ca38e8864b66f30b59c1abeacbb4bfb96b4e9c694eac6b3f4c1c81e0ee3451082d44828cb7515315d91ad68116959a5efbdaef1e1</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-linux-386.tar.gz>kubernetes-client-linux-386.tar.gz</a></td><td>c62acdc8993b0a950d4b0ce0b45473bf96373d501ce61c88adf4007afb15c1d53da8d53b778a7eccac6c1624f7fdda322be9f3a8bc2d80aaad7b4237c39f5eaf</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-linux-amd64.tar.gz>kubernetes-client-linux-amd64.tar.gz</a></td><td>1203ababfe00f9bc5be5c059324c17160a96530c1379a152db33564bbe644ccdb94b30eea15a0655bd652efb17895a46c31bbba19d4f5f473c2a0ff62f6e551f</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-linux-arm.tar.gz>kubernetes-client-linux-arm.tar.gz</a></td><td>31860088596e12d739c7aed94556c2d1e217971699b950c8417a3cea1bed4e78c9ff1717b9f3943354b75b4641d4b906cd910890dbf4278287c0d224837d9a7d</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-linux-arm64.tar.gz>kubernetes-client-linux-arm64.tar.gz</a></td><td>8d469f37fe20d6e15b5debc13cce4c22e8b7a4f6a4ac787006b96507a85ce761f63b28140d692c54b5f7deb08697f8d5ddb9bbfa8f5ac0d9241fc7de3a3fe3cd</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-linux-ppc64le.tar.gz>kubernetes-client-linux-ppc64le.tar.gz</a></td><td>0d62ee1729cd5884946b6c73701ad3a570fa4d642190ca0fe5c1db0fb0cba9da3ac86a948788d915b9432d28ab8cc499e28aadc64530b7d549ee752a6ed93ec1</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-linux-s390x.tar.gz>kubernetes-client-linux-s390x.tar.gz</a></td><td>0fc0420e134ec0b8e0ab2654e1e102cebec47b48179703f1e1b79d51ee0d6da55a4e7304d8773d3cf830341ac2fe3cede1e6b0460fd88f7595534e0730422d5a</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-windows-386.tar.gz>kubernetes-client-windows-386.tar.gz</a></td><td>3fb53b5260f4888c77c0e4ff602bbcf6bf38c364d2769850afe2b8d8e8b95f7024807c15e2b0d5603e787c46af8ac53492be9e88c530f578b8a389e3bd50c099</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-client-windows-amd64.tar.gz>kubernetes-client-windows-amd64.tar.gz</a></td><td>2f44c93463d6b5244ce0c82f147e7f32ec2233d0e29c64c3c5759e23533aebd12671bf63e986c0861e9736f9b5259bb8d138574a7c8c8efc822e35cd637416c0</td></tr></tbody></table><h3 id=server-binaries-6>Server binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-server-linux-amd64.tar.gz>kubernetes-server-linux-amd64.tar.gz</a></td><td>ae82d14b1214e4100f0cc2c988308b3e1edd040a65267d0eddb9082409f79644e55387889e3c0904a12c710f91206e9383edf510990bee8c9ea2e297b6472551</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-server-linux-arm.tar.gz>kubernetes-server-linux-arm.tar.gz</a></td><td>9a2a5828b7d1ddb16cc19d573e99a4af642f84129408e6203eeeb0558e7b8db77f3269593b5770b6a976fe9df4a64240ed27ad05a4bd43719e55fce1db0abf58</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-server-linux-arm64.tar.gz>kubernetes-server-linux-arm64.tar.gz</a></td><td>ed700dd226c999354ce05b73927388d36d08474c15333ae689427de15de27c84feb6b23c463afd9dd81993315f31eb8265938cfc7ecf6f750247aa42b9b33fa9</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-server-linux-ppc64le.tar.gz>kubernetes-server-linux-ppc64le.tar.gz</a></td><td>abb7a9d726538be3ccf5057a0c63ff9732b616e213c6ebb81363f0c49f1e168ce8068b870061ad7cba7ba1d49252f94cf00a5f68cec0f38dc8fce4e24edc5ca6</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-server-linux-s390x.tar.gz>kubernetes-server-linux-s390x.tar.gz</a></td><td>3a51888af1bfdd2d5b0101d173ee589c1f39240e4428165f5f85c610344db219625faa42f00a49a83ce943fb079be873b1a114a62003fae2f328f9bf9d1227a4</td></tr></tbody></table><h3 id=node-binaries-6>Node binaries</h3><table><thead><tr><th>filename</th><th>sha512 hash</th></tr></thead><tbody><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-node-linux-amd64.tar.gz>kubernetes-node-linux-amd64.tar.gz</a></td><td>d0f28e3c38ca59a7ff1bfecb48a1ce97116520355d9286afdca1200d346c10018f5bbdf890f130a388654635a2e83e908b263ed45f8a88defca52a7c1d0a7984</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-node-linux-arm.tar.gz>kubernetes-node-linux-arm.tar.gz</a></td><td>ed9d3f13028beb3be39bce980c966f82c4b39dc73beaae38cc075fea5be30b0309e555cb2af8196014f2cc9f0df823354213c314b4d6545ff6e30dd2d00ec90e</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-node-linux-arm64.tar.gz>kubernetes-node-linux-arm64.tar.gz</a></td><td>ad5b3268db365dcdded9a9a4bffc90c7df0f844000349accdf2b8fb5f1081e553de9b9e9fb25d5e8a4ef7252d51fa94ef94d36d2ab31d157854e164136f662c2</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-node-linux-ppc64le.tar.gz>kubernetes-node-linux-ppc64le.tar.gz</a></td><td>c4de2524e513996def5eeba7b83f7b406f17eaf89d4d557833a93bd035348c81fa9375dcd5c27cfcc55d73995449fc8ee504be1b3bd7b9f108b0b2f153cb05ae</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-node-linux-s390x.tar.gz>kubernetes-node-linux-s390x.tar.gz</a></td><td>9157b44e3e7bd5478af9f72014e54d1afa5cd19b984b4cd8b348b312c385016bb77f29db47f44aea08b58abf47d8a396b92a2d0e03f2fe8acdd30f4f9466cbdb</td></tr><tr><td><a href=https://dl.k8s.io/v1.20.0-alpha.1/kubernetes-node-windows-amd64.tar.gz>kubernetes-node-windows-amd64.tar.gz</a></td><td>8b40a43c5e6447379ad2ee8aac06e8028555e1b370a995f6001018a62411abe5fbbca6060b3d1682c5cadc07a27d49edd3204e797af46368800d55f4ca8aa1de</td></tr></tbody></table><h2 id=changelog-since-v1-20-0-alpha-0>Changelog since v1.20.0-alpha.0</h2><h2 id=urgent-upgrade-notes-2>Urgent Upgrade Notes</h2><h3 id=no-really-you-must-read-this-before-you-upgrade-2>(No, really, you MUST read this before you upgrade)</h3><ul><li>Azure blob disk feature(<code>kind</code>: <code>Shared</code>, <code>Dedicated</code>) has been deprecated, you should use <code>kind</code>: <code>Managed</code> in <code>kubernetes.io/azure-disk</code> storage class. (<a href=https://github.com/kubernetes/kubernetes/pull/92905>#92905</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</li><li>CVE-2020-8559 (Medium): Privilege escalation from compromised node to cluster. See <a href=https://github.com/kubernetes/kubernetes/issues/92914>https://github.com/kubernetes/kubernetes/issues/92914</a> for more details.
The API Server will no longer proxy non-101 responses for upgrade requests. This could break proxied backends (such as an extension API server) that respond to upgrade requests with a non-101 response code. (<a href=https://github.com/kubernetes/kubernetes/pull/92941>#92941</a>, <a href=https://github.com/tallclair>@tallclair</a>) [SIG API Machinery]</li></ul><h2 id=changes-by-kind-6>Changes by Kind</h2><h3 id=deprecation-4>Deprecation</h3><ul><li>Kube-apiserver: the componentstatus API is deprecated. This API provided status of etcd, kube-scheduler, and kube-controller-manager components, but only worked when those components were local to the API server, and when kube-scheduler and kube-controller-manager exposed unsecured health endpoints. Instead of this API, etcd health is included in the kube-apiserver health check and kube-scheduler/kube-controller-manager health checks can be made directly against those components' health endpoints. (<a href=https://github.com/kubernetes/kubernetes/pull/93570>#93570</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery, Apps and Cluster Lifecycle]</li><li>Kubeadm: deprecate the "kubeadm alpha kubelet config enable-dynamic" command. To continue using the feature please defer to the guide for "Dynamic Kubelet Configuration" at k8s.io. (<a href=https://github.com/kubernetes/kubernetes/pull/92881>#92881</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: remove the deprecated "kubeadm alpha kubelet config enable-dynamic" command. To continue using the feature please defer to the guide for "Dynamic Kubelet Configuration" at k8s.io. This change also removes the parent command "kubeadm alpha kubelet" as there are no more sub-commands under it for the time being. (<a href=https://github.com/kubernetes/kubernetes/pull/94668>#94668</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: remove the deprecated --kubelet-config flag for the command "kubeadm upgrade node" (<a href=https://github.com/kubernetes/kubernetes/pull/94869>#94869</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubelet's deprecated endpoint <code>metrics/resource/v1alpha1</code> has been removed, please adopt to <code>metrics/resource</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/94272>#94272</a>, <a href=https://github.com/RainbowMango>@RainbowMango</a>) [SIG Instrumentation and Node]</li><li>The v1alpha1 PodPreset API and admission plugin has been removed with no built-in replacement. Admission webhooks can be used to modify pods on creation. (<a href=https://github.com/kubernetes/kubernetes/pull/94090>#94090</a>, <a href=https://github.com/deads2k>@deads2k</a>) [SIG API Machinery, Apps, CLI, Cloud Provider, Scalability and Testing]</li></ul><h3 id=api-change-5>API Change</h3><ul><li>A new <code>nofuzz</code> go build tag now disables gofuzz support. Release binaries enable this. (<a href=https://github.com/kubernetes/kubernetes/pull/92491>#92491</a>, <a href=https://github.com/BenTheElder>@BenTheElder</a>) [SIG API Machinery]</li><li>A new alpha-level field, <code>SupportsFsGroup</code>, has been introduced for CSIDrivers to allow them to specify whether they support volume ownership and permission modifications. The <code>CSIVolumeSupportFSGroup</code> feature gate must be enabled to allow this field to be used. (<a href=https://github.com/kubernetes/kubernetes/pull/92001>#92001</a>, <a href=https://github.com/huffmanca>@huffmanca</a>) [SIG API Machinery, CLI and Storage]</li><li>Added pod version skew strategy for seccomp profile to synchronize the deprecated annotations with the new API Server fields. Please see the corresponding section <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/20190717-seccomp-ga.md#version-skew-strategy>in the KEP</a> for more detailed explanations. (<a href=https://github.com/kubernetes/kubernetes/pull/91408>#91408</a>, <a href=https://github.com/saschagrunert>@saschagrunert</a>) [SIG Apps, Auth, CLI and Node]</li><li>Adds the ability to disable Accelerator/GPU metrics collected by Kubelet (<a href=https://github.com/kubernetes/kubernetes/pull/91930>#91930</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>) [SIG Node]</li><li>Custom Endpoints are now mirrored to EndpointSlices by a new EndpointSliceMirroring controller. (<a href=https://github.com/kubernetes/kubernetes/pull/91637>#91637</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li><li>External facing API podresources is now available under k8s.io/kubelet/pkg/apis/ (<a href=https://github.com/kubernetes/kubernetes/pull/92632>#92632</a>, <a href=https://github.com/RenaudWasTaken>@RenaudWasTaken</a>) [SIG Node and Testing]</li><li>Fix conversions for custom metrics. (<a href=https://github.com/kubernetes/kubernetes/pull/94481>#94481</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Instrumentation]</li><li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and all of the usual volume features work. Volumes don't need to be empt; for example, restoring from snapshot is supported. (<a href=https://github.com/kubernetes/kubernetes/pull/92784>#92784</a>, <a href=https://github.com/pohly>@pohly</a>) [SIG API Machinery, Apps, Auth, CLI, Instrumentation, Node, Scheduling, Storage and Testing]</li><li>Kube-controller-manager: volume plugins can be restricted from contacting local and loopback addresses by setting <code>--volume-host-allow-local-loopback=false</code>, or from contacting specific CIDR ranges by setting <code>--volume-host-cidr-denylist</code> (for example, <code>--volume-host-cidr-denylist=127.0.0.1/28,feed::/16</code>) (<a href=https://github.com/kubernetes/kubernetes/pull/91785>#91785</a>, <a href=https://github.com/mattcary>@mattcary</a>) [SIG API Machinery, Apps, Auth, CLI, Network, Node, Storage and Testing]</li><li>Kubernetes is now built with golang 1.15.0-rc.1.<ul><li>The deprecated, legacy behavior of treating the CommonName field on X.509 serving certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable. (<a href=https://github.com/kubernetes/kubernetes/pull/93264>#93264</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Scalability, Storage and Testing]</li></ul></li><li>Migrate scheduler, controller-manager and cloud-controller-manager to use LeaseLock (<a href=https://github.com/kubernetes/kubernetes/pull/94603>#94603</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery, Apps, Cloud Provider and Scheduling]</li><li>Modify DNS-1123 error messages to indicate that RFC 1123 is not followed exactly (<a href=https://github.com/kubernetes/kubernetes/pull/94182>#94182</a>, <a href=https://github.com/mattfenwick>@mattfenwick</a>) [SIG API Machinery, Apps, Auth, Network and Node]</li><li>The ServiceAccountIssuerDiscovery feature gate is now Beta and enabled by default. (<a href=https://github.com/kubernetes/kubernetes/pull/91921>#91921</a>, <a href=https://github.com/mtaufen>@mtaufen</a>) [SIG Auth]</li><li>The kube-controller-manager managed signers can now have distinct signing certificates and keys. See the help about <code>--cluster-signing-[signer-name]-{cert,key}-file</code>. <code>--cluster-signing-{cert,key}-file</code> is still the default. (<a href=https://github.com/kubernetes/kubernetes/pull/90822>#90822</a>, <a href=https://github.com/deads2k>@deads2k</a>) [SIG API Machinery, Apps and Auth]</li><li>When creating a networking.k8s.io/v1 Ingress API object, <code>spec.tls[*].secretName</code> values are required to pass validation rules for Secret API object names. (<a href=https://github.com/kubernetes/kubernetes/pull/93929>#93929</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG Network]</li><li>WinOverlay feature graduated to beta (<a href=https://github.com/kubernetes/kubernetes/pull/94807>#94807</a>, <a href=https://github.com/ksubrmnn>@ksubrmnn</a>) [SIG Windows]</li></ul><h3 id=feature-6>Feature</h3><ul><li><p>ACTION REQUIRED : In CoreDNS v1.7.0, <a href=https://github.com/coredns/coredns/blob/master/notes/coredns-1.7.0.md#metric-changes>metrics names have been changed</a> which will be backward incompatible with existing reporting formulas that use the old metrics' names. Adjust your formulas to the new names before upgrading.</p><p>Kubeadm now includes CoreDNS version v1.7.0. Some of the major changes include:</p><ul><li>Fixed a bug that could cause CoreDNS to stop updating service records.</li><li>Fixed a bug in the forward plugin where only the first upstream server is always selected no matter which policy is set.</li><li>Remove already deprecated options <code>resyncperiod</code> and <code>upstream</code> in the Kubernetes plugin.</li><li>Includes Prometheus metrics name changes (to bring them in line with standard Prometheus metrics naming convention). They will be backward incompatible with existing reporting formulas that use the old metrics' names.</li><li>The federation plugin (allows for v1 Kubernetes federation) has been removed.
More details are available in <a href=https://coredns.io/2020/06/15/coredns-1.7.0-release/>https://coredns.io/2020/06/15/coredns-1.7.0-release/</a> (<a href=https://github.com/kubernetes/kubernetes/pull/92651>#92651</a>, <a href=https://github.com/rajansandeep>@rajansandeep</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle and Instrumentation]</li></ul></li><li><p>Add metrics for azure service operations (route and loadbalancer). (<a href=https://github.com/kubernetes/kubernetes/pull/94124>#94124</a>, <a href=https://github.com/nilo19>@nilo19</a>) [SIG Cloud Provider and Instrumentation]</p></li><li><p>Add network rule support in Azure account creation (<a href=https://github.com/kubernetes/kubernetes/pull/94239>#94239</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Add tags support for Azure File Driver (<a href=https://github.com/kubernetes/kubernetes/pull/92825>#92825</a>, <a href=https://github.com/ZeroMagic>@ZeroMagic</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Added kube-apiserver metrics: apiserver_current_inflight_request_measures and, when API Priority and Fairness is enable, windowed_request_stats. (<a href=https://github.com/kubernetes/kubernetes/pull/91177>#91177</a>, <a href=https://github.com/MikeSpreitzer>@MikeSpreitzer</a>) [SIG API Machinery, Instrumentation and Testing]</p></li><li><p>Audit events for API requests to deprecated API versions now include a <code>"k8s.io/deprecated": "true"</code> audit annotation. If a target removal release is identified, the audit event includes a <code>"k8s.io/removal-release": "&lt;majorVersion>.&lt;minorVersion>"</code> audit annotation as well. (<a href=https://github.com/kubernetes/kubernetes/pull/92842>#92842</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and Instrumentation]</p></li><li><p>Cloud node-controller use InstancesV2 (<a href=https://github.com/kubernetes/kubernetes/pull/91319>#91319</a>, <a href=https://github.com/gongguan>@gongguan</a>) [SIG Apps, Cloud Provider, Scalability and Storage]</p></li><li><p>Kubeadm: Add a preflight check that the control-plane node has at least 1700MB of RAM (<a href=https://github.com/kubernetes/kubernetes/pull/93275>#93275</a>, <a href=https://github.com/xlgao-zju>@xlgao-zju</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: add the "--cluster-name" flag to the "kubeadm alpha kubeconfig user" to allow configuring the cluster name in the generated kubeconfig file (<a href=https://github.com/kubernetes/kubernetes/pull/93992>#93992</a>, <a href=https://github.com/prabhu43>@prabhu43</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: add the "--kubeconfig" flag to the "kubeadm init phase upload-certs" command to allow users to pass a custom location for a kubeconfig file. (<a href=https://github.com/kubernetes/kubernetes/pull/94765>#94765</a>, <a href=https://github.com/zhanw15>@zhanw15</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: deprecate the "--csr-only" and "--csr-dir" flags of the "kubeadm init phase certs" subcommands. Please use "kubeadm alpha certs generate-csr" instead. This new command allows you to generate new private keys and certificate signing requests for all the control-plane components, so that the certificates can be signed by an external CA. (<a href=https://github.com/kubernetes/kubernetes/pull/92183>#92183</a>, <a href=https://github.com/wallrj>@wallrj</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: make etcd pod request 100m CPU, 100Mi memory and 100Mi ephemeral_storage by default (<a href=https://github.com/kubernetes/kubernetes/pull/94479>#94479</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubemark now supports both real and hollow nodes in a single cluster. (<a href=https://github.com/kubernetes/kubernetes/pull/93201>#93201</a>, <a href=https://github.com/ellistarn>@ellistarn</a>) [SIG Scalability]</p></li><li><p>Kubernetes is now built using go1.15.2</p><ul><li><p>build: Update to <a href=mailto:k/repo-infra@v0.1.1>k/repo-infra@v0.1.1</a> (supports go1.15.2)</p></li><li><p>build: Use go-runner:buster-v2.0.1 (built using go1.15.1)</p></li><li><p>bazel: Replace --features with Starlark build settings flag</p></li><li><p>hack/lib/util.sh: some bash cleanups</p><ul><li>switched one spot to use kube::logging</li><li>make kube::util::find-binary return an error when it doesn't find
anything so that hack scripts fail fast instead of with '' binary not
found errors.</li><li>this required deleting some genfeddoc stuff. the binary no longer
exists in k/k repo since we removed federation/, and I don't see it
in <a href=https://github.com/kubernetes-sigs/kubefed/>https://github.com/kubernetes-sigs/kubefed/</a> either. I'm assuming
that it's gone for good now.</li></ul></li><li><p>bazel: output go_binary rule directly from go_binary_conditional_pure</p><p>From: @mikedanese:
Instead of aliasing. Aliases are annoying in a number of ways. This is
specifically bugging me now because they make the action graph harder to
analyze programmatically. By using aliases here, we would need to handle
potentially aliased go_binary targets and dereference to the effective
target.</p><p>The comment references an issue with <code>pure = select(...)</code> which appears
to be resolved considering this now builds.</p></li><li><p>make kube::util::find-binary not dependent on bazel-out/ structure</p><p>Implement an aspect that outputs go_build_mode metadata for go binaries,
and use that during binary selection. (<a href=https://github.com/kubernetes/kubernetes/pull/94449>#94449</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Architecture, CLI, Cluster Lifecycle, Node, Release and Testing]</p></li></ul></li><li><p>Only update Azure data disks when attach/detach (<a href=https://github.com/kubernetes/kubernetes/pull/94265>#94265</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Promote SupportNodePidsLimit to GA to provide node to pod pid isolation
Promote SupportPodPidsLimit to GA to provide ability to limit pids per pod (<a href=https://github.com/kubernetes/kubernetes/pull/94140>#94140</a>, <a href=https://github.com/derekwaynecarr>@derekwaynecarr</a>) [SIG Node and Testing]</p></li><li><p>Rename pod_preemption_metrics to preemption_metrics. (<a href=https://github.com/kubernetes/kubernetes/pull/93256>#93256</a>, <a href=https://github.com/ahg-g>@ahg-g</a>) [SIG Instrumentation and Scheduling]</p></li><li><p>Server-side apply behavior has been regularized in the case where a field is removed from the applied configuration. Removed fields which have no other owners are deleted from the live object, or reset to their default value if they have one. Safe ownership transfers, such as the transfer of a <code>replicas</code> field from a user to an HPA without resetting to the default value are documented in <a href=/docs/reference/using-api/server-side-apply/#transferring-ownership>Transferring Ownership</a> (<a href=https://github.com/kubernetes/kubernetes/pull/92661>#92661</a>, <a href=https://github.com/jpbetz>@jpbetz</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation and Testing]</p></li><li><p>Set CSIMigrationvSphere feature gates to beta.
Users should enable CSIMigration + CSIMigrationvSphere features and install the vSphere CSI Driver (<a href=https://github.com/kubernetes-sigs/vsphere-csi-driver>https://github.com/kubernetes-sigs/vsphere-csi-driver</a>) to move workload from the in-tree vSphere plugin "kubernetes.io/vsphere-volume" to vSphere CSI Driver.</p><p>Requires: vSphere vCenter/ESXi Version: 7.0u1, HW Version: VM version 15 (<a href=https://github.com/kubernetes/kubernetes/pull/92816>#92816</a>, <a href=https://github.com/divyenpatel>@divyenpatel</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Support [service.beta.kubernetes.io/azure-pip-ip-tags] annotations to allow customers to specify ip-tags to influence public-ip creation in Azure [Tag1=Value1, Tag2=Value2, etc.] (<a href=https://github.com/kubernetes/kubernetes/pull/94114>#94114</a>, <a href=https://github.com/MarcPow>@MarcPow</a>) [SIG Cloud Provider]</p></li><li><p>Support a smooth upgrade from client-side apply to server-side apply without conflicts, as well as support the corresponding downgrade. (<a href=https://github.com/kubernetes/kubernetes/pull/90187>#90187</a>, <a href=https://github.com/julianvmodesto>@julianvmodesto</a>) [SIG API Machinery and Testing]</p></li><li><p>Trace output in apiserver logs is more organized and comprehensive. Traces are nested, and for all non-long running request endpoints, the entire filter chain is instrumented (e.g. authentication check is included). (<a href=https://github.com/kubernetes/kubernetes/pull/88936>#88936</a>, <a href=https://github.com/jpbetz>@jpbetz</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation and Scheduling]</p></li><li><p><code>kubectl alpha debug</code> now supports debugging nodes by creating a debugging container running in the node's host namespaces. (<a href=https://github.com/kubernetes/kubernetes/pull/92310>#92310</a>, <a href=https://github.com/verb>@verb</a>) [SIG CLI]</p></li></ul><h3 id=documentation-3>Documentation</h3><ul><li>Kubelet: remove alpha warnings for CNI flags. (<a href=https://github.com/kubernetes/kubernetes/pull/94508>#94508</a>, <a href=https://github.com/andrewsykim>@andrewsykim</a>) [SIG Network and Node]</li></ul><h3 id=failing-test-1>Failing Test</h3><ul><li>Kube-proxy iptables min-sync-period defaults to 1 sec. Previously, it was 0. (<a href=https://github.com/kubernetes/kubernetes/pull/92836>#92836</a>, <a href=https://github.com/aojea>@aojea</a>) [SIG Network]</li></ul><h3 id=bug-or-regression-6>Bug or Regression</h3><ul><li><p>A panic in the apiserver caused by the <code>informer-sync</code> health checker is now fixed. (<a href=https://github.com/kubernetes/kubernetes/pull/93600>#93600</a>, <a href=https://github.com/ialidzhikov>@ialidzhikov</a>) [SIG API Machinery]</p></li><li><p>Add kubectl wait --ignore-not-found flag (<a href=https://github.com/kubernetes/kubernetes/pull/90969>#90969</a>, <a href=https://github.com/zhouya0>@zhouya0</a>) [SIG CLI]</p></li><li><p>Adding fix to the statefulset controller to wait for pvc deletion before creating pods. (<a href=https://github.com/kubernetes/kubernetes/pull/93457>#93457</a>, <a href=https://github.com/ymmt2005>@ymmt2005</a>) [SIG Apps]</p></li><li><p>Azure ARM client: don't segfault on empty response and http error (<a href=https://github.com/kubernetes/kubernetes/pull/94078>#94078</a>, <a href=https://github.com/bpineau>@bpineau</a>) [SIG Cloud Provider]</p></li><li><p>Azure: fix a bug that kube-controller-manager would panic if wrong Azure VMSS name is configured (<a href=https://github.com/kubernetes/kubernetes/pull/94306>#94306</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Cloud Provider]</p></li><li><p>Azure: per VMSS VMSS VMs cache to prevent throttling on clusters having many attached VMSS (<a href=https://github.com/kubernetes/kubernetes/pull/93107>#93107</a>, <a href=https://github.com/bpineau>@bpineau</a>) [SIG Cloud Provider]</p></li><li><p>Both apiserver_request_duration_seconds metrics and RequestReceivedTimestamp field of an audit event take
into account the time a request spends in the apiserver request filters. (<a href=https://github.com/kubernetes/kubernetes/pull/94903>#94903</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery, Auth and Instrumentation]</p></li><li><p>Build/lib/release: Explicitly use '--platform' in building server images</p><p>When we switched to go-runner for building the apiserver,
controller-manager, and scheduler server components, we no longer
reference the individual architectures in the image names, specifically
in the 'FROM' directive of the server image Dockerfiles.</p><p>As a result, server images for non-amd64 images copy in the go-runner
amd64 binary instead of the go-runner that matches that architecture.</p><p>This commit explicitly sets the '--platform=linux/${arch}' to ensure
we're pulling the correct go-runner arch from the manifest list.</p><p>Before:
<code>FROM ${base_image}</code></p><p>After:
<code>FROM --platform=linux/${arch} ${base_image}</code> (<a href=https://github.com/kubernetes/kubernetes/pull/94552>#94552</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Release]</p></li><li><p>CSIDriver object can be deployed during volume attachment. (<a href=https://github.com/kubernetes/kubernetes/pull/93710>#93710</a>, <a href=https://github.com/Jiawei0227>@Jiawei0227</a>) [SIG Apps, Node, Storage and Testing]</p></li><li><p>CVE-2020-8557 (Medium): Node-local denial of service via container /etc/hosts file. See <a href=https://github.com/kubernetes/kubernetes/issues/93032>https://github.com/kubernetes/kubernetes/issues/93032</a> for more details. (<a href=https://github.com/kubernetes/kubernetes/pull/92916>#92916</a>, <a href=https://github.com/joelsmith>@joelsmith</a>) [SIG Node]</p></li><li><p>Do not add nodes labeled with kubernetes.azure.com/managed=false to backend pool of load balancer. (<a href=https://github.com/kubernetes/kubernetes/pull/93034>#93034</a>, <a href=https://github.com/matthias50>@matthias50</a>) [SIG Cloud Provider]</p></li><li><p>Do not fail sorting empty elements. (<a href=https://github.com/kubernetes/kubernetes/pull/94666>#94666</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG CLI]</p></li><li><p>Do not retry volume expansion if CSI driver returns FailedPrecondition error (<a href=https://github.com/kubernetes/kubernetes/pull/92986>#92986</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Node and Storage]</p></li><li><p>Dockershim security: pod sandbox now always run with <code>no-new-privileges</code> and <code>runtime/default</code> seccomp profile
dockershim seccomp: custom profiles can now have smaller seccomp profiles when set at pod level (<a href=https://github.com/kubernetes/kubernetes/pull/90948>#90948</a>, <a href=https://github.com/pjbgf>@pjbgf</a>) [SIG Node]</p></li><li><p>Dual-stack: make nodeipam compatible with existing single-stack clusters when dual-stack feature gate become enabled by default (<a href=https://github.com/kubernetes/kubernetes/pull/90439>#90439</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG API Machinery]</p></li><li><p>Endpoint controller requeues service after an endpoint deletion event occurs to confirm that deleted endpoints are undesired to mitigate the effects of an out of sync endpoint cache. (<a href=https://github.com/kubernetes/kubernetes/pull/93030>#93030</a>, <a href=https://github.com/swetharepakula>@swetharepakula</a>) [SIG Apps and Network]</p></li><li><p>EndpointSlice controllers now return immediately if they encounter an error creating, updating, or deleting resources. (<a href=https://github.com/kubernetes/kubernetes/pull/93908>#93908</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps and Network]</p></li><li><p>EndpointSliceMirroring controller now copies labels from Endpoints to EndpointSlices. (<a href=https://github.com/kubernetes/kubernetes/pull/93442>#93442</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps and Network]</p></li><li><p>EndpointSliceMirroring controller now mirrors Endpoints that do not have a Service associated with them. (<a href=https://github.com/kubernetes/kubernetes/pull/94171>#94171</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps, Network and Testing]</p></li><li><p>Ensure backoff step is set to 1 for Azure armclient. (<a href=https://github.com/kubernetes/kubernetes/pull/94180>#94180</a>, <a href=https://github.com/feiskyer>@feiskyer</a>) [SIG Cloud Provider]</p></li><li><p>Ensure getPrimaryInterfaceID not panic when network interfaces for Azure VMSS are null (<a href=https://github.com/kubernetes/kubernetes/pull/94355>#94355</a>, <a href=https://github.com/feiskyer>@feiskyer</a>) [SIG Cloud Provider]</p></li><li><p>Eviction requests for pods that have a non-zero DeletionTimestamp will always succeed (<a href=https://github.com/kubernetes/kubernetes/pull/91342>#91342</a>, <a href=https://github.com/michaelgugino>@michaelgugino</a>) [SIG Apps]</p></li><li><p>Extended DSR loadbalancer feature in winkernel kube-proxy to HNS versions 9.3-9.max, 10.2+ (<a href=https://github.com/kubernetes/kubernetes/pull/93080>#93080</a>, <a href=https://github.com/elweb9858>@elweb9858</a>) [SIG Network]</p></li><li><p>Fix HandleCrash order (<a href=https://github.com/kubernetes/kubernetes/pull/93108>#93108</a>, <a href=https://github.com/lixiaobing1>@lixiaobing1</a>) [SIG API Machinery]</p></li><li><p>Fix a concurrent map writes error in kubelet (<a href=https://github.com/kubernetes/kubernetes/pull/93773>#93773</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Node]</p></li><li><p>Fix a regression where kubeadm bails out with a fatal error when an optional version command line argument is supplied to the "kubeadm upgrade plan" command (<a href=https://github.com/kubernetes/kubernetes/pull/94421>#94421</a>, <a href=https://github.com/rosti>@rosti</a>) [SIG Cluster Lifecycle]</p></li><li><p>Fix azure file migration panic (<a href=https://github.com/kubernetes/kubernetes/pull/94853>#94853</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix bug where loadbalancer deletion gets stuck because of missing resource group #75198 (<a href=https://github.com/kubernetes/kubernetes/pull/93962>#93962</a>, <a href=https://github.com/phiphi282>@phiphi282</a>) [SIG Cloud Provider]</p></li><li><p>Fix calling AttachDisk on a previously attached EBS volume (<a href=https://github.com/kubernetes/kubernetes/pull/93567>#93567</a>, <a href=https://github.com/gnufied>@gnufied</a>) [SIG Cloud Provider, Storage and Testing]</p></li><li><p>Fix detection of image filesystem, disk metrics for devicemapper, detection of OOM Kills on 5.0+ linux kernels. (<a href=https://github.com/kubernetes/kubernetes/pull/92919>#92919</a>, <a href=https://github.com/dashpole>@dashpole</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation and Node]</p></li><li><p>Fix etcd_object_counts metric reported by kube-apiserver (<a href=https://github.com/kubernetes/kubernetes/pull/94773>#94773</a>, <a href=https://github.com/tkashem>@tkashem</a>) [SIG API Machinery]</p></li><li><p>Fix incorrectly reported verbs for kube-apiserver metrics for CRD objects (<a href=https://github.com/kubernetes/kubernetes/pull/93523>#93523</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Instrumentation]</p></li><li><p>Fix instance not found issues when an Azure Node is recreated in a short time (<a href=https://github.com/kubernetes/kubernetes/pull/93316>#93316</a>, <a href=https://github.com/feiskyer>@feiskyer</a>) [SIG Cloud Provider]</p></li><li><p>Fix kube-apiserver /readyz to contain "informer-sync" check ensuring that internal informers are synced. (<a href=https://github.com/kubernetes/kubernetes/pull/93670>#93670</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Testing]</p></li><li><p>Fix kubectl SchemaError on CRDs with schema using x-kubernetes-preserve-unknown-fields on array types. (<a href=https://github.com/kubernetes/kubernetes/pull/94888>#94888</a>, <a href=https://github.com/sttts>@sttts</a>) [SIG API Machinery]</p></li><li><p>Fix memory leak in EndpointSliceTracker for EndpointSliceMirroring controller. (<a href=https://github.com/kubernetes/kubernetes/pull/93441>#93441</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps and Network]</p></li><li><p>Fix missing csi annotations on node during parallel csinode update. (<a href=https://github.com/kubernetes/kubernetes/pull/94389>#94389</a>, <a href=https://github.com/pacoxu>@pacoxu</a>) [SIG Storage]</p></li><li><p>Fix the <code>cloudprovider_azure_api_request_duration_seconds</code> metric buckets to correctly capture the latency metrics. Previously, the majority of the calls would fall in the "+Inf" bucket. (<a href=https://github.com/kubernetes/kubernetes/pull/94873>#94873</a>, <a href=https://github.com/marwanad>@marwanad</a>) [SIG Cloud Provider and Instrumentation]</p></li><li><p>Fix: azure disk resize error if source does not exist (<a href=https://github.com/kubernetes/kubernetes/pull/93011>#93011</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix: detach azure disk broken on Azure Stack (<a href=https://github.com/kubernetes/kubernetes/pull/94885>#94885</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</p></li><li><p>Fix: determine the correct ip config based on ip family (<a href=https://github.com/kubernetes/kubernetes/pull/93043>#93043</a>, <a href=https://github.com/aramase>@aramase</a>) [SIG Cloud Provider]</p></li><li><p>Fix: initial delay in mounting azure disk & file (<a href=https://github.com/kubernetes/kubernetes/pull/93052>#93052</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Fix: use sensitiveOptions on Windows mount (<a href=https://github.com/kubernetes/kubernetes/pull/94126>#94126</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Fixed Ceph RBD volume expansion when no ceph.conf exists (<a href=https://github.com/kubernetes/kubernetes/pull/92027>#92027</a>, <a href=https://github.com/juliantaylor>@juliantaylor</a>) [SIG Storage]</p></li><li><p>Fixed a bug where improper storage and comparison of endpoints led to excessive API traffic from the endpoints controller (<a href=https://github.com/kubernetes/kubernetes/pull/94112>#94112</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Apps, Network and Testing]</p></li><li><p>Fixed a bug whereby the allocation of reusable CPUs and devices was not being honored when the TopologyManager was enabled (<a href=https://github.com/kubernetes/kubernetes/pull/93189>#93189</a>, <a href=https://github.com/klueska>@klueska</a>) [SIG Node]</p></li><li><p>Fixed a panic in kubectl debug when pod has multiple init containers or ephemeral containers (<a href=https://github.com/kubernetes/kubernetes/pull/94580>#94580</a>, <a href=https://github.com/kiyoshim55>@kiyoshim55</a>) [SIG CLI]</p></li><li><p>Fixed a regression that sometimes prevented <code>kubectl portforward</code> to work when TCP and UDP services were configured on the same port (<a href=https://github.com/kubernetes/kubernetes/pull/94728>#94728</a>, <a href=https://github.com/amorenoz>@amorenoz</a>) [SIG CLI]</p></li><li><p>Fixed bug in reflector that couldn't recover from "Too large resource version" errors with API servers 1.17.0-1.18.5 (<a href=https://github.com/kubernetes/kubernetes/pull/94316>#94316</a>, <a href=https://github.com/janeczku>@janeczku</a>) [SIG API Machinery]</p></li><li><p>Fixed bug where kubectl top pod output is not sorted when --sort-by and --containers flags are used together (<a href=https://github.com/kubernetes/kubernetes/pull/93692>#93692</a>, <a href=https://github.com/brianpursley>@brianpursley</a>) [SIG CLI]</p></li><li><p>Fixed kubelet creating extra sandbox for pods with RestartPolicyOnFailure after all containers succeeded (<a href=https://github.com/kubernetes/kubernetes/pull/92614>#92614</a>, <a href=https://github.com/tnqn>@tnqn</a>) [SIG Node and Testing]</p></li><li><p>Fixed memory leak in endpointSliceTracker (<a href=https://github.com/kubernetes/kubernetes/pull/92838>#92838</a>, <a href=https://github.com/tnqn>@tnqn</a>) [SIG Apps and Network]</p></li><li><p>Fixed node data lost in kube-scheduler for clusters with imbalance on number of nodes across zones (<a href=https://github.com/kubernetes/kubernetes/pull/93355>#93355</a>, <a href=https://github.com/maelk>@maelk</a>) [SIG Scheduling]</p></li><li><p>Fixed the EndpointSliceController to correctly create endpoints for IPv6-only pods.</p><p>Fixed the EndpointController to allow IPv6 headless services, if the IPv6DualStack
feature gate is enabled, by specifying <code>ipFamily: IPv6</code> on the service. (This already
worked with the EndpointSliceController.) (<a href=https://github.com/kubernetes/kubernetes/pull/91399>#91399</a>, <a href=https://github.com/danwinship>@danwinship</a>) [SIG Apps and Network]</p></li><li><p>Fixes a bug evicting pods after a taint with a limited tolerationSeconds toleration is removed from a node (<a href=https://github.com/kubernetes/kubernetes/pull/93722>#93722</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG Apps and Node]</p></li><li><p>Fixes a bug where EndpointSlices would not be recreated after rapid Service recreation. (<a href=https://github.com/kubernetes/kubernetes/pull/94730>#94730</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps, Network and Testing]</p></li><li><p>Fixes a race condition in kubelet pod handling (<a href=https://github.com/kubernetes/kubernetes/pull/94751>#94751</a>, <a href=https://github.com/auxten>@auxten</a>) [SIG Node]</p></li><li><p>Fixes an issue proxying to ipv6 pods without specifying a port (<a href=https://github.com/kubernetes/kubernetes/pull/94834>#94834</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and Network]</p></li><li><p>Fixes an issue that can result in namespaced custom resources being orphaned when their namespace is deleted, if the CRD defining the custom resource is removed concurrently with namespaces being deleted, then recreated. (<a href=https://github.com/kubernetes/kubernetes/pull/93790>#93790</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and Apps]</p></li><li><p>Ignore root user check when windows pod starts (<a href=https://github.com/kubernetes/kubernetes/pull/92355>#92355</a>, <a href=https://github.com/wawa0210>@wawa0210</a>) [SIG Node and Windows]</p></li><li><p>Increased maximum IOPS of AWS EBS io1 volumes to 64,000 (current AWS maximum). (<a href=https://github.com/kubernetes/kubernetes/pull/90014>#90014</a>, <a href=https://github.com/jacobmarble>@jacobmarble</a>) [SIG Cloud Provider and Storage]</p></li><li><p>K8s.io/apimachinery: runtime.DefaultUnstructuredConverter.FromUnstructured now handles converting integer fields to typed float values (<a href=https://github.com/kubernetes/kubernetes/pull/93250>#93250</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery]</p></li><li><p>Kube-aggregator certificates are dynamically loaded on change from disk (<a href=https://github.com/kubernetes/kubernetes/pull/92791>#92791</a>, <a href=https://github.com/p0lyn0mial>@p0lyn0mial</a>) [SIG API Machinery]</p></li><li><p>Kube-apiserver: fixed a bug returning inconsistent results from list requests which set a field or label selector and set a paging limit (<a href=https://github.com/kubernetes/kubernetes/pull/94002>#94002</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery]</p></li><li><p>Kube-apiserver: jsonpath expressions with consecutive recursive descent operators are no longer evaluated for custom resource printer columns (<a href=https://github.com/kubernetes/kubernetes/pull/93408>#93408</a>, <a href=https://github.com/joelsmith>@joelsmith</a>) [SIG API Machinery]</p></li><li><p>Kube-proxy now trims extra spaces found in loadBalancerSourceRanges to match Service validation. (<a href=https://github.com/kubernetes/kubernetes/pull/94107>#94107</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Network]</p></li><li><p>Kube-up now includes CoreDNS version v1.7.0. Some of the major changes include:</p><ul><li>Fixed a bug that could cause CoreDNS to stop updating service records.</li><li>Fixed a bug in the forward plugin where only the first upstream server is always selected no matter which policy is set.</li><li>Remove already deprecated options <code>resyncperiod</code> and <code>upstream</code> in the Kubernetes plugin.</li><li>Includes Prometheus metrics name changes (to bring them in line with standard Prometheus metrics naming convention). They will be backward incompatible with existing reporting formulas that use the old metrics' names.</li><li>The federation plugin (allows for v1 Kubernetes federation) has been removed.
More details are available in <a href=https://coredns.io/2020/06/15/coredns-1.7.0-release/>https://coredns.io/2020/06/15/coredns-1.7.0-release/</a> (<a href=https://github.com/kubernetes/kubernetes/pull/92718>#92718</a>, <a href=https://github.com/rajansandeep>@rajansandeep</a>) [SIG Cloud Provider]</li></ul></li><li><p>Kubeadm now makes sure the etcd manifest is regenerated upon upgrade even when no etcd version change takes place (<a href=https://github.com/kubernetes/kubernetes/pull/94395>#94395</a>, <a href=https://github.com/rosti>@rosti</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: avoid a panic when determining if the running version of CoreDNS is supported during upgrades (<a href=https://github.com/kubernetes/kubernetes/pull/94299>#94299</a>, <a href=https://github.com/zouyee>@zouyee</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: ensure "kubeadm reset" does not unmount the root "/var/lib/kubelet" directory if it is mounted by the user (<a href=https://github.com/kubernetes/kubernetes/pull/93702>#93702</a>, <a href=https://github.com/thtanaka>@thtanaka</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: ensure the etcd data directory is created with 0700 permissions during control-plane init and join (<a href=https://github.com/kubernetes/kubernetes/pull/94102>#94102</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: fix the bug that kubeadm tries to call 'docker info' even if the CRI socket was for another CR (<a href=https://github.com/kubernetes/kubernetes/pull/94555>#94555</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: make the kubeconfig files for the kube-controller-manager and kube-scheduler use the LocalAPIEndpoint instead of the ControlPlaneEndpoint. This makes kubeadm clusters more reseliant to version skew problems during immutable upgrades: <a href=https://kubernetes.io/docs/setup/release/version-skew-policy/#kube-controller-manager-kube-scheduler-and-cloud-controller-manager>https://kubernetes.io/docs/setup/release/version-skew-policy/#kube-controller-manager-kube-scheduler-and-cloud-controller-manager</a> (<a href=https://github.com/kubernetes/kubernetes/pull/94398>#94398</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: relax the validation of kubeconfig server URLs. Allow the user to define custom kubeconfig server URLs without erroring out during validation of existing kubeconfig files (e.g. when using external CA mode). (<a href=https://github.com/kubernetes/kubernetes/pull/94816>#94816</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubeadm: remove duplicate DNS names and IP addresses from generated certificates (<a href=https://github.com/kubernetes/kubernetes/pull/92753>#92753</a>, <a href=https://github.com/QianChenglong>@QianChenglong</a>) [SIG Cluster Lifecycle]</p></li><li><p>Kubelet: assume that swap is disabled when <code>/proc/swaps</code> does not exist (<a href=https://github.com/kubernetes/kubernetes/pull/93931>#93931</a>, <a href=https://github.com/SataQiu>@SataQiu</a>) [SIG Node]</p></li><li><p>Kubelet: fix race condition in pluginWatcher (<a href=https://github.com/kubernetes/kubernetes/pull/93622>#93622</a>, <a href=https://github.com/knight42>@knight42</a>) [SIG Node]</p></li><li><p>Kuberuntime security: pod sandbox now always runs with <code>runtime/default</code> seccomp profile
kuberuntime seccomp: custom profiles can now have smaller seccomp profiles when set at pod level (<a href=https://github.com/kubernetes/kubernetes/pull/90949>#90949</a>, <a href=https://github.com/pjbgf>@pjbgf</a>) [SIG Node]</p></li><li><p>NONE (<a href=https://github.com/kubernetes/kubernetes/pull/71269>#71269</a>, <a href=https://github.com/DeliangFan>@DeliangFan</a>) [SIG Node]</p></li><li><p>New Azure instance types do now have correct max data disk count information. (<a href=https://github.com/kubernetes/kubernetes/pull/94340>#94340</a>, <a href=https://github.com/ialidzhikov>@ialidzhikov</a>) [SIG Cloud Provider and Storage]</p></li><li><p>Pods with invalid Affinity/AntiAffinity LabelSelectors will now fail scheduling when these plugins are enabled (<a href=https://github.com/kubernetes/kubernetes/pull/93660>#93660</a>, <a href=https://github.com/damemi>@damemi</a>) [SIG Scheduling]</p></li><li><p>Require feature flag CustomCPUCFSQuotaPeriod if setting a non-default cpuCFSQuotaPeriod in kubelet config. (<a href=https://github.com/kubernetes/kubernetes/pull/94687>#94687</a>, <a href=https://github.com/karan>@karan</a>) [SIG Node]</p></li><li><p>Reverted devicemanager for Windows node added in 1.19rc1. (<a href=https://github.com/kubernetes/kubernetes/pull/93263>#93263</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG Node and Windows]</p></li><li><p>Scheduler bugfix: Scheduler doesn't lose pod information when nodes are quickly recreated. This could happen when nodes are restarted or quickly recreated reusing a nodename. (<a href=https://github.com/kubernetes/kubernetes/pull/93938>#93938</a>, <a href=https://github.com/alculquicondor>@alculquicondor</a>) [SIG Scalability, Scheduling and Testing]</p></li><li><p>The EndpointSlice controller now waits for EndpointSlice and Node caches to be synced before starting. (<a href=https://github.com/kubernetes/kubernetes/pull/94086>#94086</a>, <a href=https://github.com/robscott>@robscott</a>) [SIG Apps and Network]</p></li><li><p>The <code>/debug/api_priority_and_fairness/dump_requests</code> path at an apiserver will no longer return a phantom line for each exempt priority level. (<a href=https://github.com/kubernetes/kubernetes/pull/93406>#93406</a>, <a href=https://github.com/MikeSpreitzer>@MikeSpreitzer</a>) [SIG API Machinery]</p></li><li><p>The kubelet recognizes the --containerd-namespace flag to configure the namespace used by cadvisor. (<a href=https://github.com/kubernetes/kubernetes/pull/87054>#87054</a>, <a href=https://github.com/changyaowei>@changyaowei</a>) [SIG Node]</p></li><li><p>The terminationGracePeriodSeconds from pod spec is respected for the mirror pod. (<a href=https://github.com/kubernetes/kubernetes/pull/92442>#92442</a>, <a href=https://github.com/tedyu>@tedyu</a>) [SIG Node and Testing]</p></li><li><p>Update Calico to v3.15.2 (<a href=https://github.com/kubernetes/kubernetes/pull/94241>#94241</a>, <a href=https://github.com/lmm>@lmm</a>) [SIG Cloud Provider]</p></li><li><p>Update default etcd server version to 3.4.13 (<a href=https://github.com/kubernetes/kubernetes/pull/94287>#94287</a>, <a href=https://github.com/jingyih>@jingyih</a>) [SIG API Machinery, Cloud Provider, Cluster Lifecycle and Testing]</p></li><li><p>Updated Cluster Autoscaler to 1.19.0; (<a href=https://github.com/kubernetes/kubernetes/pull/93577>#93577</a>, <a href=https://github.com/vivekbagade>@vivekbagade</a>) [SIG Autoscaling and Cloud Provider]</p></li><li><p>Use NLB Subnet CIDRs instead of VPC CIDRs in Health Check SG Rules (<a href=https://github.com/kubernetes/kubernetes/pull/93515>#93515</a>, <a href=https://github.com/t0rr3sp3dr0>@t0rr3sp3dr0</a>) [SIG Cloud Provider]</p></li><li><p>Users will see increase in time for deletion of pods and also guarantee that removal of pod from api server would mean deletion of all the resources from container runtime. (<a href=https://github.com/kubernetes/kubernetes/pull/92817>#92817</a>, <a href=https://github.com/kmala>@kmala</a>) [SIG Node]</p></li><li><p>Very large patches may now be specified to <code>kubectl patch</code> with the <code>--patch-file</code> flag instead of including them directly on the command line. The <code>--patch</code> and <code>--patch-file</code> flags are mutually exclusive. (<a href=https://github.com/kubernetes/kubernetes/pull/93548>#93548</a>, <a href=https://github.com/smarterclayton>@smarterclayton</a>) [SIG CLI]</p></li><li><p>When creating a networking.k8s.io/v1 Ingress API object, <code>spec.rules[*].http</code> values are now validated consistently when the <code>host</code> field contains a wildcard. (<a href=https://github.com/kubernetes/kubernetes/pull/93954>#93954</a>, <a href=https://github.com/Miciah>@Miciah</a>) [SIG CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Storage and Testing]</p></li></ul><h3 id=other-cleanup-or-flake-5>Other (Cleanup or Flake)</h3><ul><li>--cache-dir sets cache directory for both http and discovery, defaults to $HOME/.kube/cache (<a href=https://github.com/kubernetes/kubernetes/pull/92910>#92910</a>, <a href=https://github.com/soltysh>@soltysh</a>) [SIG API Machinery and CLI]</li><li>Adds a bootstrapping ClusterRole, ClusterRoleBinding and group for /metrics, /livez/<em>, /readyz/</em>, & /healthz/- endpoints. (<a href=https://github.com/kubernetes/kubernetes/pull/93311>#93311</a>, <a href=https://github.com/logicalhan>@logicalhan</a>) [SIG API Machinery, Auth, Cloud Provider and Instrumentation]</li><li>Base-images: Update to debian-iptables:buster-v1.3.0<ul><li>Uses iptables 1.8.5</li><li>base-images: Update to debian-base:buster-v1.2.0</li><li>cluster/images/etcd: Build etcd:3.4.13-1 image<ul><li>Uses debian-base:buster-v1.2.0 (<a href=https://github.com/kubernetes/kubernetes/pull/94733>#94733</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG API Machinery, Release and Testing]</li></ul></li></ul></li><li>Build: Update to <a href=mailto:debian-base@v2.1.2>debian-base@v2.1.2</a> and <a href=mailto:debian-iptables@v12.1.1>debian-iptables@v12.1.1</a> (<a href=https://github.com/kubernetes/kubernetes/pull/93667>#93667</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG API Machinery, Release and Testing]</li><li>Build: Update to <a href=mailto:debian-base@v2.1.3>debian-base@v2.1.3</a> and <a href=mailto:debian-iptables@v12.1.2>debian-iptables@v12.1.2</a> (<a href=https://github.com/kubernetes/kubernetes/pull/93916>#93916</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG API Machinery, Release and Testing]</li><li>Build: Update to go-runner:buster-v2.0.0 (<a href=https://github.com/kubernetes/kubernetes/pull/94167>#94167</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Release]</li><li>Fix kubelet to properly log when a container is started. Before, sometimes the log said that a container is dead and was restarted when it was started for the first time. This only happened when using pods with initContainers and regular containers. (<a href=https://github.com/kubernetes/kubernetes/pull/91469>#91469</a>, <a href=https://github.com/rata>@rata</a>) [SIG Node]</li><li>Fix: license issue in blob disk feature (<a href=https://github.com/kubernetes/kubernetes/pull/92824>#92824</a>, <a href=https://github.com/andyzhangx>@andyzhangx</a>) [SIG Cloud Provider]</li><li>Fixes the flooding warning messages about setting volume ownership for configmap/secret volumes (<a href=https://github.com/kubernetes/kubernetes/pull/92878>#92878</a>, <a href=https://github.com/jvanz>@jvanz</a>) [SIG Instrumentation, Node and Storage]</li><li>Fixes the message about no auth for metrics in scheduler. (<a href=https://github.com/kubernetes/kubernetes/pull/94035>#94035</a>, <a href=https://github.com/zhouya0>@zhouya0</a>) [SIG Scheduling]</li><li>Kube-up: defaults to limiting critical pods to the kube-system namespace to match behavior prior to 1.17 (<a href=https://github.com/kubernetes/kubernetes/pull/93121>#93121</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG Cloud Provider and Scheduling]</li><li>Kubeadm: Separate argument key/value in log msg (<a href=https://github.com/kubernetes/kubernetes/pull/94016>#94016</a>, <a href=https://github.com/mrueg>@mrueg</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: remove support for the "ci/k8s-master" version label. This label has been removed in the Kubernetes CI release process and would no longer work in kubeadm. You can use the "ci/latest" version label instead. See kubernetes/test-infra#18517 (<a href=https://github.com/kubernetes/kubernetes/pull/93626>#93626</a>, <a href=https://github.com/vikkyomkar>@vikkyomkar</a>) [SIG Cluster Lifecycle]</li><li>Kubeadm: remove the CoreDNS check for known image digests when applying the addon (<a href=https://github.com/kubernetes/kubernetes/pull/94506>#94506</a>, <a href=https://github.com/neolit123>@neolit123</a>) [SIG Cluster Lifecycle]</li><li>Kubernetes is now built with go1.15.0 (<a href=https://github.com/kubernetes/kubernetes/pull/93939>#93939</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Release and Testing]</li><li>Kubernetes is now built with go1.15.0-rc.2 (<a href=https://github.com/kubernetes/kubernetes/pull/93827>#93827</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG API Machinery, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Node, Release and Testing]</li><li>Lock ExternalPolicyForExternalIP to default, this feature gate will be removed in 1.22. (<a href=https://github.com/kubernetes/kubernetes/pull/94581>#94581</a>, <a href=https://github.com/knabben>@knabben</a>) [SIG Network]</li><li>Service.beta.kubernetes.io/azure-load-balancer-disable-tcp-reset is removed. All Standard load balancers will always enable tcp resets. (<a href=https://github.com/kubernetes/kubernetes/pull/94297>#94297</a>, <a href=https://github.com/MarcPow>@MarcPow</a>) [SIG Cloud Provider]</li><li>Stop propagating SelfLink (deprecated in 1.16) in kube-apiserver (<a href=https://github.com/kubernetes/kubernetes/pull/94397>#94397</a>, <a href=https://github.com/wojtek-t>@wojtek-t</a>) [SIG API Machinery and Testing]</li><li>Strip unnecessary security contexts on Windows (<a href=https://github.com/kubernetes/kubernetes/pull/93475>#93475</a>, <a href=https://github.com/ravisantoshgudimetla>@ravisantoshgudimetla</a>) [SIG Node, Testing and Windows]</li><li>To ensure the code be strong, add unit test for GetAddressAndDialer (<a href=https://github.com/kubernetes/kubernetes/pull/93180>#93180</a>, <a href=https://github.com/FreeZhang61>@FreeZhang61</a>) [SIG Node]</li><li>Update CNI plugins to v0.8.7 (<a href=https://github.com/kubernetes/kubernetes/pull/94367>#94367</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Cloud Provider, Network, Node, Release and Testing]</li><li>Update Golang to v1.14.5<ul><li>Update repo-infra to 0.0.7 (to support go1.14.5 and go1.13.13)<ul><li>Includes:<ul><li><a href=mailto:bazelbuild/bazel-toolchains@3.3.2>bazelbuild/bazel-toolchains@3.3.2</a></li><li><a href=mailto:bazelbuild/rules_go@v0.22.7>bazelbuild/rules_go@v0.22.7</a> (<a href=https://github.com/kubernetes/kubernetes/pull/93088>#93088</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Release and Testing]</li></ul></li></ul></li></ul></li><li>Update Golang to v1.14.6<ul><li>Update repo-infra to 0.0.8 (to support go1.14.6 and go1.13.14)<ul><li>Includes:<ul><li><a href=mailto:bazelbuild/bazel-toolchains@3.4.0>bazelbuild/bazel-toolchains@3.4.0</a></li><li><a href=mailto:bazelbuild/rules_go@v0.22.8>bazelbuild/rules_go@v0.22.8</a> (<a href=https://github.com/kubernetes/kubernetes/pull/93198>#93198</a>, <a href=https://github.com/justaugustus>@justaugustus</a>) [SIG Release and Testing]</li></ul></li></ul></li></ul></li><li>Update cri-tools to <a href=https://github.com/kubernetes-sigs/cri-tools/releases/tag/v1.19.0>v1.19.0</a> (<a href=https://github.com/kubernetes/kubernetes/pull/94307>#94307</a>, <a href=https://github.com/xmudrii>@xmudrii</a>) [SIG Cloud Provider]</li><li>Update default etcd server version to 3.4.9 (<a href=https://github.com/kubernetes/kubernetes/pull/92349>#92349</a>, <a href=https://github.com/jingyih>@jingyih</a>) [SIG API Machinery, Cloud Provider, Cluster Lifecycle and Testing]</li><li>Update etcd client side to v3.4.13 (<a href=https://github.com/kubernetes/kubernetes/pull/94259>#94259</a>, <a href=https://github.com/jingyih>@jingyih</a>) [SIG API Machinery and Cloud Provider]</li><li><code>kubectl get ingress</code> now prefers the <code>networking.k8s.io/v1</code> over <code>extensions/v1beta1</code> (deprecated since v1.14). To explicitly request the deprecated version, use <code>kubectl get ingress.v1beta1.extensions</code>. (<a href=https://github.com/kubernetes/kubernetes/pull/94309>#94309</a>, <a href=https://github.com/liggitt>@liggitt</a>) [SIG API Machinery and CLI]</li></ul><h2 id=dependencies-6>Dependencies</h2><h3 id=added-6>Added</h3><ul><li>github.com/Azure/go-autorest: <a href=https://github.com/Azure/go-autorest/tree/v14.2.0>v14.2.0+incompatible</a></li><li>github.com/fvbommel/sortorder: <a href=https://github.com/fvbommel/sortorder/tree/v1.0.1>v1.0.1</a></li><li>github.com/yuin/goldmark: <a href=https://github.com/yuin/goldmark/tree/v1.1.27>v1.1.27</a></li><li>sigs.k8s.io/structured-merge-diff/v4: v4.0.1</li></ul><h3 id=changed-6>Changed</h3><ul><li>github.com/Azure/go-autorest/autorest/adal: <a href=https://github.com/Azure/go-autorest/autorest/adal/compare/v0.8.2...v0.9.0>v0.8.2 → v0.9.0</a></li><li>github.com/Azure/go-autorest/autorest/date: <a href=https://github.com/Azure/go-autorest/autorest/date/compare/v0.2.0...v0.3.0>v0.2.0 → v0.3.0</a></li><li>github.com/Azure/go-autorest/autorest/mocks: <a href=https://github.com/Azure/go-autorest/autorest/mocks/compare/v0.3.0...v0.4.0>v0.3.0 → v0.4.0</a></li><li>github.com/Azure/go-autorest/autorest: <a href=https://github.com/Azure/go-autorest/autorest/compare/v0.9.6...v0.11.1>v0.9.6 → v0.11.1</a></li><li>github.com/Azure/go-autorest/logger: <a href=https://github.com/Azure/go-autorest/logger/compare/v0.1.0...v0.2.0>v0.1.0 → v0.2.0</a></li><li>github.com/Azure/go-autorest/tracing: <a href=https://github.com/Azure/go-autorest/tracing/compare/v0.5.0...v0.6.0>v0.5.0 → v0.6.0</a></li><li>github.com/Microsoft/hcsshim: <a href=https://github.com/Microsoft/hcsshim/compare/v0.8.9...5eafd15>v0.8.9 → 5eafd15</a></li><li>github.com/cilium/ebpf: <a href=https://github.com/cilium/ebpf/compare/9f1617e...1c8d4c9>9f1617e → 1c8d4c9</a></li><li>github.com/containerd/cgroups: <a href=https://github.com/containerd/cgroups/compare/bf292b2...0dbf7f0>bf292b2 → 0dbf7f0</a></li><li>github.com/coredns/corefile-migration: <a href=https://github.com/coredns/corefile-migration/compare/v1.0.8...v1.0.10>v1.0.8 → v1.0.10</a></li><li>github.com/evanphx/json-patch: <a href=https://github.com/evanphx/json-patch/compare/e83c0a1...v4.9.0>e83c0a1 → v4.9.0+incompatible</a></li><li>github.com/google/cadvisor: <a href=https://github.com/google/cadvisor/compare/8450c56...v0.37.0>8450c56 → v0.37.0</a></li><li>github.com/json-iterator/go: <a href=https://github.com/json-iterator/go/compare/v1.1.9...v1.1.10>v1.1.9 → v1.1.10</a></li><li>github.com/opencontainers/go-digest: <a href=https://github.com/opencontainers/go-digest/compare/v1.0.0-rc1...v1.0.0>v1.0.0-rc1 → v1.0.0</a></li><li>github.com/opencontainers/runc: <a href=https://github.com/opencontainers/runc/compare/1b94395...819fcc6>1b94395 → 819fcc6</a></li><li>github.com/prometheus/client_golang: <a href=https://github.com/prometheus/client_golang/compare/v1.6.0...v1.7.1>v1.6.0 → v1.7.1</a></li><li>github.com/prometheus/common: <a href=https://github.com/prometheus/common/compare/v0.9.1...v0.10.0>v0.9.1 → v0.10.0</a></li><li>github.com/prometheus/procfs: <a href=https://github.com/prometheus/procfs/compare/v0.0.11...v0.1.3>v0.0.11 → v0.1.3</a></li><li>github.com/rubiojr/go-vhd: <a href=https://github.com/rubiojr/go-vhd/compare/0bfd3b3...02e2102>0bfd3b3 → 02e2102</a></li><li>github.com/storageos/go-api: <a href=https://github.com/storageos/go-api/compare/343b3ef...v2.2.0>343b3ef → v2.2.0+incompatible</a></li><li>github.com/urfave/cli: <a href=https://github.com/urfave/cli/compare/v1.22.1...v1.22.2>v1.22.1 → v1.22.2</a></li><li>go.etcd.io/etcd: 54ba958 → dd1b699</li><li>golang.org/x/crypto: bac4c82 → 75b2880</li><li>golang.org/x/mod: v0.1.0 → v0.3.0</li><li>golang.org/x/net: d3edc99 → ab34263</li><li>golang.org/x/tools: c00d67e → c1934b7</li><li>k8s.io/kube-openapi: 656914f → 6aeccd4</li><li>k8s.io/system-validators: v1.1.2 → v1.2.0</li><li>k8s.io/utils: 6e3d28b → d5654de</li></ul><h3 id=removed-6>Removed</h3><ul><li>github.com/godbus/dbus: <a href=https://github.com/godbus/dbus/tree/ade71ed>ade71ed</a></li><li>github.com/xlab/handysort: <a href=https://github.com/xlab/handysort/tree/fb3537e>fb3537e</a></li><li>sigs.k8s.io/structured-merge-diff/v3: v3.0.0</li><li>vbom.ml/util: db5cfe1</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-85b7e96ac42e5e28ec570ad43f0ef5cd>1.2 - 쿠버네티스 버전 및 버전 차이(skew) 지원 정책</h1><p>이 문서는 다양한 쿠버네티스 구성 요소 간에 지원되는 최대 버전 차이를 설명한다.
특정 클러스터 배포 도구는 버전 차이에 대한 추가적인 제한을 설정할 수 있다.</p><h2 id=지원되는-버전>지원되는 버전</h2><p>쿠버네티스 버전은 <strong>x.y.z</strong>로 표현되는데,
여기서 <strong>x</strong>는 메이저 버전, <strong>y</strong>는 마이너 버전, <strong>z</strong>는 <a href=https://semver.org/>시맨틱 버전</a> 용어에 따른 패치 버전이다.
자세한 내용은 <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/release/versioning.md#kubernetes-release-versioning>쿠버네티스 릴리스 버전</a>을 참조한다.</p><p>쿠버네티스 프로젝트는 최근 세 개의 마이너 릴리스 (1.24, 1.23, 1.22) 에 대한 릴리스 분기를 유지한다. 쿠버네티스 1.19 이상은 약 1년간의 패치 지원을 받는다. 쿠버네티스 1.18 이상은 약 9개월의 패치 지원을 받는다.</p><p>보안 수정사항을 포함한 해당 수정사항은 심각도와 타당성에 따라 세 개의 릴리스 브랜치로 백포트(backport) 될 수 있다.
패치 릴리스는 각 브랜치별로 <a href=https://git.k8s.io/sig-release/releases/patch-releases.md#cadence>정기적인 주기</a>로 제공하며, 필요한 경우 추가 긴급 릴리스도 추가한다.</p><p><a href=https://git.k8s.io/sig-release/release-managers.md>릴리스 관리자</a> 그룹이 이러한 결정 권한을 가진다.</p><p>자세한 내용은 쿠버네티스 <a href=https://git.k8s.io/sig-release/releases/patch-releases.md>패치 릴리스</a> 페이지를 참조한다.</p><h2 id=지원되는-버전-차이>지원되는 버전 차이</h2><h3 id=kube-apiserver>kube-apiserver</h3><p><a href=/docs/setup/production-environment/tools/kubeadm/high-availability/>고가용성(HA) 클러스터</a>에서 최신 및 가장 오래된 <code>kube-apiserver</code> 인스턴스가 각각 한 단계 마이너 버전 내에 있어야 한다.</p><p>예:</p><ul><li>최신 <code>kube-apiserver</code>는 <strong>1.24</strong> 이다.</li><li>다른 <code>kube-apiserver</code> 인스턴스는 <strong>1.24</strong> 및 <strong>1.23</strong> 을 지원한다.</li></ul><h3 id=kubelet>kubelet</h3><p><code>kubelet</code>은 <code>kube-apiserver</code>보다 최신일 수 없으며, 2단계의 낮은 마이너 버전까지 지원한다.</p><p>예:</p><ul><li><code>kube-apiserver</code>가 <strong>1.24</strong> 이다.</li><li><code>kubelet</code>은 <strong>1.24</strong>, <strong>1.23</strong> 및 <strong>1.22</strong> 을 지원한다.</li></ul><blockquote class="note callout"><div><strong>참고:</strong> HA 클러스터의 <code>kube-apiserver</code> 인스턴스 사이에 버전 차이가 있으면 허용되는 <code>kubelet</code> 버전의 범위도 줄어든다.</div></blockquote><p>예:</p><ul><li><code>kube-apiserver</code> 인스턴스는 <strong>1.24</strong> 및 <strong>1.23</strong> 이다.</li><li><code>kubelet</code>은 <strong>1.23</strong> 및 <strong>1.22</strong> 을 지원한다(<strong>1.24</strong> 는 <code>kube-apiserver</code>의 <strong>1.23</strong> 인스턴스보다 최신 버전이기 때문에 지원하지 않는다).</li></ul><h3 id=kube-controller-manager-kube-scheduler-그리고-cloud-controller-manager>kube-controller-manager, kube-scheduler 그리고 cloud-controller-manager</h3><p><code>kube-controller-manager</code>, <code>kube-scheduler</code> 그리고 <code>cloud-controller-manager</code>는 그들과 통신하는 <code>kube-apiserver</code> 인스턴스보다 최신 버전이면 안 된다. <code>kube-apiserver</code> 마이너 버전과 일치할 것으로 예상하지만, 최대 한 단계 낮은 마이너 버전까지는 허용한다(실시간 업그레이드를 지원하기 위해서).</p><p>예:</p><ul><li><code>kube-apiserver</code>은 <strong>1.24</strong> 이다.</li><li><code>kube-controller-manager</code>, <code>kube-scheduler</code> 그리고 <code>cloud-controller-manager</code>는 <strong>1.24</strong> 과 <strong>1.23</strong> 을 지원한다.</li></ul><blockquote class="note callout"><div><strong>참고:</strong> HA 클러스터의 <code>kube-apiserver</code> 인스턴스 간에 버전 차이가 존재하고 이러한 구성 요소가 클러스터의 모든 <code>kube-apiserver</code> 인스턴스와 통신할 수 있는 경우(예를 들어, 로드 밸런서를 통해서)에는 구성 요소의 허용하는 버전의 범위도 줄어든다.</div></blockquote><p>예:</p><ul><li><code>kube-apiserver</code> 인스턴스는 <strong>1.24</strong> 및 <strong>1.23</strong> 이다.</li><li><code>kube-controller-manager</code>, <code>kube-scheduler</code> 그리고 <code>cloud-controller-manager</code>는 모든 <code>kube-apiserver</code> 인스턴스로 라우팅하는 로드 밸런서와 통신한다.</li><li><code>kube-controller-manager</code>, <code>kube-scheduler</code> 그리고 <code>cloud-controller-manager</code>는 <strong>1.23</strong> 에서 지원한다(<strong>1.24</strong> 는 <code>kube-apiserver</code> 인스턴스의 <strong>1.23</strong> 버전보다 최신이기 때문에 지원하지 않는다).</li></ul><h3 id=kubectl>kubectl</h3><p><code>kubectl</code>은 <code>kube-apiserver</code>의 한 단계 마이너 버전(이전 또는 최신) 내에서 지원한다.</p><p>예:</p><ul><li><code>kube-apiserver</code>은 <strong>1.24</strong> 이다.</li><li><code>kubectl</code>은 <strong>1.25</strong>, <strong>1.24</strong> 및 <strong>1.23</strong> 을 지원한다.</li></ul><blockquote class="note callout"><div><strong>참고:</strong> HA 클러스터의 <code>kube-apiserver</code> 인스턴스 간에 버전 차이가 있으면 지원되는 <code>kubectl</code> 버전의 범위도 줄어든다.</div></blockquote><p>예:</p><ul><li><code>kube-apiserver</code> 인스턴스는 <strong>1.24</strong> 및 <strong>1.23</strong> 이다.</li><li><code>kubectl</code>은 <strong>1.24</strong> 및 <strong>1.23</strong> 에서 지원한다(다른 버전은 <code>kube-apiserver</code> 인스턴스 중에 한 단계 이상의 마이너 버전 차이가 난다).</li></ul><h2 id=지원되는-구성-요소-업그레이드-순서>지원되는 구성 요소 업그레이드 순서</h2><p>구성요소 간 지원되는 버전 차이는 구성요소를 업그레이드하는 순서에 영향을 준다.
이 섹션에서는 기존 클러스터를 버전 <strong>1.23</strong> 에서 버전 <strong>1.24</strong> 로 전환하기 위해 구성 요소를 업그레이드하는 순서를 설명한다.</p><h3 id=kube-apiserver-1>kube-apiserver</h3><p>사전 요구 사항:</p><ul><li>단일 인스턴스 클러스터에서 기존 <code>kube-apiserver</code> 인스턴스는 <strong>1.23</strong> 이어야 한다.</li><li>HA 클러스터에서 모든 <code>kube-apiserver</code> 인스턴스는 <strong>1.23</strong> 또는 <strong>1.24</strong> 이어야 한다(이것은 <code>kube-apiserver</code> 인스턴스 간의 가장 최신과 오래된 버전의 차이를 최대 1개의 마이너 버전의 차이로 보장한다).</li><li>이 서버와 통신하는 <code>kube-controller-manager</code>, <code>kube-scheduler</code> 그리고 <code>cloud-controller-manager</code>의 버전은 <strong>1.23</strong> 이어야 한다(이것은 기존 API서버 버전보다 최신 버전이 아니고 새로운 API서버 버전의 마이너 1개의 버전 내에 있음을 보장한다).</li><li>모든 <code>kubelet</code> 인스턴스는 버전 <strong>1.23</strong> 또는 <strong>1.22</strong> 이어야 한다(이것은 기존 API서버 버전보다 최신 버전이 아니며, 새로운 API서버 버전의 2개의 마이너 버전 내에 있음을 보장한다).</li><li>등록된 어드미션 웹훅은 새로운 <code>kube-apiserver</code> 인스턴스가 전송하는 데이터를 처리할 수 있다:<ul><li><code>ValidatingWebhookConfiguration</code> 그리고 <code>MutatingWebhookConfiguration</code> 오브젝트는 <strong>1.24</strong> 에 추가된 REST 리소스의 새 버전을 포함하도록 업데이트한다(또는 v1.15 이상에서 사용 가능한 <a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-matchpolicy><code>matchPolicy: Equivalent</code> option</a> 설정을 사용).</li><li>웹훅은 자신에게 전송될 REST리소스의 새버전과 <strong>1.24</strong> 에서 기존 버전에 추가된 새로운 필드를 처리할 수 있다.</li></ul></li></ul><p><code>kube-apiserver</code>를 <strong>1.24</strong> 으로 업그레이드</p><blockquote class="note callout"><div><strong>참고:</strong> <a href=/docs/reference/using-api/deprecation-policy/>API 지원 중단</a> 및
<a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api_changes.md>API 변경 가이드라인</a>
에 대한 프로젝트 정책에서는 단일 클러스터일지라도 업그레이드할 때 <code>kube-apiserver</code>의 마이너 버전을 건너뛰지 않도록 요구한다.</div></blockquote><h3 id=kube-controller-manager-kube-scheduler-그리고-cloud-controller-manager-1>kube-controller-manager, kube-scheduler 그리고 cloud-controller-manager</h3><p>사전 요구 사항:</p><ul><li><code>kube-apiserver</code> 인스턴스는 <strong>1.24</strong> 이여야 한다(HA 클러스터에서 <code>kube-apiserver</code> 인스턴스와 통신할 수 있는 구성 요소를 업그레이드 전에 모든 <code>kube-apiserver</code> 인스턴스는 업그레이드되어야 한다).</li></ul><p><code>kube-controller-manager</code>, <code>kube-scheduler</code> 및 <code>cloud-controller-manager</code> 를 <strong>1.24</strong> 으로 업그레이드한다.</p><h3 id=kubelet-1>kubelet</h3><p>사전 요구 사항:</p><ul><li><code>kubelet</code>과 통신하는 <code>kube-apiserver</code> 인스턴스는 <strong>1.24</strong> 이어야 한다.</li></ul><p>필요에 따라서 <code>kubelet</code> 인스턴스를 <strong>1.24</strong> 으로 업그레이드할 수 있다(또는 <strong>1.23</strong> 아니면 <strong>1.22</strong> 으로 유지할 수 있음).</p><blockquote class="note callout"><div><strong>참고:</strong> <code>kubelet</code> 마이너 버전 업그레이드를 수행하기 전에, 해당 노드의 파드를 <a href=/docs/tasks/administer-cluster/safely-drain-node/>드레인(drain)</a>해야 한다.
인플레이스(In-place) 마이너 버전 <code>kubelet</code> 업그레이드는 지원되지 않는다.</div></blockquote><blockquote class="warning callout"><div><strong>경고:</strong><p>클러스터 안의 <code>kubelet</code> 인스턴스를 <code>kube-apiserver</code>의 버전보다 2단계 낮은 버전으로 실행하는 것을 권장하지 않는다:</p><ul><li><code>kube-apiserver</code>를 업그레이드한다면 한 단계 낮은 버전으로 업그레이드해야 한다.</li><li>이것은 관리되고 있는 3단계의 마이너 버전보다 낮은 <code>kubelet</code>을 실행할 가능성을 높인다.</li></ul></div></blockquote><h3 id=kube-proxy>kube-proxy</h3><ul><li><code>kube-proxy</code>는 반드시 <code>kubelet</code>과 동일한 마이너 버전이어야 한다.</li><li><code>kube-proxy</code>는 반드시 <code>kube-apiserver</code> 보다 최신 버전이면 안 된다.</li><li><code>kube-proxy</code>는 <code>kube-apiserver</code> 보다 2단계 낮은 마이너 버전 이내여야 한다.</li></ul><p>예:</p><p><code>kube-proxy</code> 버전이 <strong>1.22</strong> 인 경우:</p><ul><li><code>kubelet</code> 버전도 반드시 <strong>1.22</strong> 와 동일한 마이너 버전이어야 한다.</li><li><code>kube-apiserver</code> 버전은 반드시 <strong>1.22</strong> 에서 <strong>1.24</strong> 사이 이어야 한다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0b597086a9d1382f86abadcfeab657d6>2 - 학습 환경</h1><h2 id=kind>kind</h2><p><a href=https://kind.sigs.k8s.io/docs/><code>kind</code></a>를 사용하면 로컬 컴퓨터에서
쿠버네티스를 사용할 수 있다. 이 툴을 사용하려면
<a href=https://docs.docker.com/get-docker/>도커</a>를 설치 및 구성해야 한다.</p><p>kind <a href=https://kind.sigs.k8s.io/docs/user/quick-start/>빠른 시작</a> 페이지에는
kind를 시작하고 실행하기 위해 해야 할 일이 나와 있다.</p><h2 id=minikube>minikube</h2><p><code>kind</code>와 마찬가지로, <a href=https://minikube.sigs.k8s.io/><code>minikube</code></a>는 로컬에서 쿠버네티스를 실행할 수 있는 툴이다.
<code>minikube</code>는 개인용 컴퓨터(윈도우, 맥OS, 리눅스 포함)에서
단일 노드 쿠버네티스 클러스터를 실행하므로
쿠버네티스를 시험해 보거나 일상적인 개발 작업에 사용할 수 있다.</p><p>툴을 설치하고 싶으면
<a href=https://minikube.sigs.k8s.io/docs/start/>시작하기!</a> 공식 가이드를
참조하기 바란다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4e14853fdaa3bd273f31a60112b9b5ac>3 - 운영 환경</h1></div><div class=td-content><h1 id=pg-a77d3feb6e6d9978f32fa14622642e9a>3.1 - 컨테이너 런타임</h1><p>파드가 노드에서 실행될 수 있도록 클러스터의 각 노드에
<a class=glossary-tooltip title="컨테이너 런타임은 컨테이너 실행을 담당하는 소프트웨어이다." data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label="컨테이너 런타임">컨테이너 런타임</a>을
설치해야 한다. 이 페이지에서는 관련된 항목을 설명하고
노드 설정 관련 작업을 설명한다.</p><p>이 페이지에는 리눅스 환경의 쿠버네티스에서 여러 공통 컨테이너 런타임을 사용하는 방법에 대한
세부 정보가 있다.</p><ul><li><a href=#containerd>containerd</a></li><li><a href=#cri-o>CRI-O</a></li><li><a href=#%EB%8F%84%EC%BB%A4>도커</a></li></ul><blockquote class="note callout"><div><strong>참고:</strong> 다른 운영 체제의 경우, 해당 플랫폼과 관련된 문서를 찾아보자.</div></blockquote><h2 id=cgroup-드라이버>Cgroup 드라이버</h2><p>Control group은 프로세스에 할당된 리소스를 제한하는데 사용된다.</p><p>리눅스 배포판의 init 시스템이 <a href=https://www.freedesktop.org/wiki/Software/systemd/>systemd</a>인
경우, init 프로세스는 root control group(<code>cgroup</code>)을
생성 및 사용하는 cgroup 관리자로 작동한다.
Systemd는 cgroup과의 긴밀한 통합을 통해 프로세스당 cgroup을 할당한다.
컨테이너 런타임과 kubelet이 <code>cgroupfs</code>를 사용하도록 설정할 수 있다. systemd와 함께
<code>cgroupfs</code>를 사용하면 두 개의 서로 다른 cgroup 관리자가 존재하게 된다는 뜻이다.</p><p>단일 cgroup 관리자는 할당되는 리소스가 무엇인지를 단순화하고,
기본적으로 사용할 수 있는 리소스와 사용 중인 리소스를 일관성있게 볼 수 있다.
시스템에 두 개의 cgroup 관리자가 있으면, 이런 리소스도 두 개의 관점에서 보게 된다.
현장에서 사람들은 kubelet과 도커에 <code>cgroupfs</code>를 사용하고,
나머지 프로세스는 <code>systemd</code>를 사용하도록 노드가 설정된 경우, 리소스가 부족할 때
불안정해지는 사례를 보고했다.</p><p>컨테이너 런타임과 kubelet이 <code>systemd</code>를 cgroup 드라이버로 사용하도록 설정을 변경하면
시스템이 안정화된다. 도커에 대해 구성하려면, <code>native.cgroupdriver=systemd</code>를 설정한다.</p><blockquote class="caution callout"><div><strong>주의:</strong><p>클러스터에 결합되어 있는 노드의 cgroup 관리자를 변경하는 것은 강력하게 권장하지 <em>않는다</em>.
하나의 cgroup 드라이버의 의미를 사용하여 kubelet이 파드를 생성해왔다면,
컨테이너 런타임을 다른 cgroup 드라이버로 변경하는 것은 존재하는 기존 파드에 대해 파드 샌드박스 재생성을 시도할 때, 에러가 발생할 수 있다.
kubelet을 재시작하는 것은 에러를 해결할 수 없을 것이다.</p><p>자동화가 가능하다면, 업데이트된 구성을 사용하여 노드를 다른 노드로
교체하거나, 자동화를 사용하여 다시 설치한다.</p></div></blockquote><h2 id=컨테이너-런타임>컨테이너 런타임</h2><blockquote class="callout caution" role=alert><strong>주의:</strong>
이 섹션은 쿠버네티스에 필요한 기능을 제공하는 써드파티 프로젝트와 관련이 있다. 쿠버네티스 프로젝트 작성자는 써드파티 프로젝트에 책임이 없다. 이 페이지는 <a href=https://github.com/cncf/foundation/blob/master/website-guidelines.md target=_blank>CNCF 웹사이트 가이드라인</a>에 따라 프로젝트를 알파벳 순으로 나열한다. 이 목록에 프로젝트를 추가하려면 변경사항을 제출하기 전에 <a href=/contribute/style/content-guide/#third-party-content>콘텐츠 가이드</a>를 읽어본다.</blockquote><h3 id=containerd>containerd</h3><p>이 섹션에는 containerd 를 CRI 런타임으로 사용하는 데 필요한 단계가 포함되어 있다.</p><p>필수 구성 요소를 설치 및 구성한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span><span style=color:#b44>overlay
</span><span style=color:#b44>br_netfilter
</span><span style=color:#b44>EOF</span>

sudo modprobe overlay
sudo modprobe br_netfilter

<span style=color:#080;font-style:italic># 필요한 sysctl 파라미터를 설정하면 재부팅 후에도 유지된다.</span>
cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span><span style=color:#b44>net.bridge.bridge-nf-call-iptables  = 1
</span><span style=color:#b44>net.ipv4.ip_forward                 = 1
</span><span style=color:#b44>net.bridge.bridge-nf-call-ip6tables = 1
</span><span style=color:#b44>EOF</span>

<span style=color:#080;font-style:italic># 재부팅하지 않고 sysctl 파라미터 적용</span>
sudo sysctl --system
</code></pre></div><p>containerd를 설치한다.</p><ul class="nav nav-tabs" id=tab-cri-containerd-installation role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-cri-containerd-installation-0 role=tab aria-controls=tab-cri-containerd-installation-0 aria-selected=true>Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-cri-containerd-installation-1 role=tab aria-controls=tab-cri-containerd-installation-1>Windows (PowerShell)</a></li></ul><div class=tab-content id=tab-cri-containerd-installation><div id=tab-cri-containerd-installation-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-cri-containerd-installation-0><p><ol><li><p>공식 도커 리포지터리에서 <code>containerd.io</code> 패키지를 설치한다. 각 리눅스 배포한에 대한 도커 리포지터리를 설정하고 <code>containerd.io</code> 패키지를 설치하는 방법은 <a href=https://docs.docker.com/engine/install/#server>도커 엔진 설치</a>에서 찾을 수 있다.</p></li><li><p>containerd 설정</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
</code></pre></div></li><li><p>containerd 재시작</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo systemctl restart containerd
</code></pre></div></li></ol></div><div id=tab-cri-containerd-installation-1 class=tab-pane role=tabpanel aria-labelledby=tab-cri-containerd-installation-1><p><p>PowerShell 세션을 시작하고 <code>$Version</code>을 원하는 버전(예: <code>$Version:1.4.3</code>)으로 설정한 후 다음 명령을 실행한다.</p><ol><li><p>containerd 다운로드</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>curl.exe -L https<span>:</span>//github.com/containerd/containerd/releases/download/v<span style=color:#b8860b>$Version</span>/containerd-<span style=color:#b8860b>$Version</span>-windows-amd64.tar.gz -o containerd-windows-amd64.tar.
</code></pre></div></li></ol><p>gz
tar.exe xvf .\containerd-windows-amd64.tar.gz</p><pre><code>
2. 추출과 설정

```powershell
Copy-Item -Path &quot;.\bin\&quot; -Destination &quot;$Env:ProgramFiles\containerd&quot; -Recurse -Force
cd $Env:ProgramFiles\containerd\
.\containerd.exe config default | Out-File config.toml -Encoding ascii

# 설정을 검토한다. 설정에 따라 다음을 조정할 수 있다.
# - sandbox_image (쿠버네티스 일시중지 이미지)
# - cni bin 폴더와 conf 폴더 위치
Get-Content config.toml

# (선택사항 - 그러나 적극 권장함) Windows 디펜더 검사에서 containerd 제외
Add-MpPreference -ExclusionProcess &quot;$Env:ProgramFiles\containerd\containerd.exe&quot;
</code></pre><ol start=3><li><p>containerd 실행</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>.\containerd.exe --register-service
<span style=color:#a2f>Start-Service</span> containerd
</code></pre></div></li></ol></div></div><h4 id=containerd-systemd><code>systemd</code> cgroup 드라이버의 사용</h4><p><code>/etc/containerd/config.toml</code> 의 <code>systemd</code> cgroup 드라이버를 <code>runc</code> 에서 사용하려면, 다음과 같이 설정한다.</p><pre><code>[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc]
  ...
  [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]
    SystemdCgroup = true
</code></pre><p>이 변경 사항을 적용하는 경우 containerd를 재시작한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo systemctl restart containerd
</code></pre></div><p>kubeadm을 사용하는 경우,
<a href=/ko/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#%EC%BB%A8%ED%8A%B8%EB%A1%A4-%ED%94%8C%EB%A0%88%EC%9D%B8-%EB%85%B8%EB%93%9C%EC%97%90%EC%84%9C-kubelet%EC%9D%B4-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-cgroup-%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B2%84-%EA%B5%AC%EC%84%B1>kubelet용 cgroup 드라이버</a>를 수동으로 구성한다.</p><h3 id=cri-o>CRI-O</h3><p>이 섹션은 CRI-O를 컨테이너 런타임으로 설치하는 필수적인 단계를 담고 있다.</p><p>시스템에 CRI-O를 설치하기 위해서 다음의 커맨드를 사용한다.</p><blockquote class="note callout"><div><strong>참고:</strong> CRI-O 메이저와 마이너 버전은 쿠버네티스 메이저와 마이너 버전이 일치해야 한다.
더 자세한 정보는 <a href=https://github.com/cri-o/cri-o#compatibility-matrix-cri-o--kubernetes>CRI-O 호환 매트릭스</a>를 본다.</div></blockquote><p>필수 구성 요소를 설치하고 구성한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># .conf 파일을 만들어 부팅 시 모듈을 로드한다</span>
cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/modules-load.d/crio.conf
</span><span style=color:#b44>overlay
</span><span style=color:#b44>br_netfilter
</span><span style=color:#b44>EOF</span>

sudo modprobe overlay
sudo modprobe br_netfilter

<span style=color:#080;font-style:italic># 요구되는 sysctl 파라미터 설정, 이 설정은 재부팅 간에도 유지된다.</span>
cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span><span style=color:#b44>net.bridge.bridge-nf-call-iptables  = 1
</span><span style=color:#b44>net.ipv4.ip_forward                 = 1
</span><span style=color:#b44>net.bridge.bridge-nf-call-ip6tables = 1
</span><span style=color:#b44>EOF</span>

sudo sysctl --system
</code></pre></div><ul class="nav nav-tabs" id=tab-cri-cri-o-installation role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-cri-cri-o-installation-0 role=tab aria-controls=tab-cri-cri-o-installation-0 aria-selected=true>Debian</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-cri-cri-o-installation-1 role=tab aria-controls=tab-cri-cri-o-installation-1>Ubuntu</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-cri-cri-o-installation-2 role=tab aria-controls=tab-cri-cri-o-installation-2>CentOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-cri-cri-o-installation-3 role=tab aria-controls=tab-cri-cri-o-installation-3>openSUSE Tumbleweed</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-cri-cri-o-installation-4 role=tab aria-controls=tab-cri-cri-o-installation-4>Fedora</a></li></ul><div class=tab-content id=tab-cri-cri-o-installation><div id=tab-cri-cri-o-installation-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-cri-cri-o-installation-0><p><p>다음의 운영 체제에서 CRI-O를 설치하려면, 환경 변수 <code>OS</code> 를
아래의 표에서 적절한 필드로 설정한다.</p><table><thead><tr><th>운영 체제</th><th><code>$OS</code></th></tr></thead><tbody><tr><td>Debian Unstable</td><td><code>Debian_Unstable</code></td></tr><tr><td>Debian Testing</td><td><code>Debian_Testing</code></td></tr></tbody></table><p><br>그런 다음, <code>$VERSION</code> 을 사용자의 쿠버네티스 버전과 일치하는 CRI-O 버전으로 설정한다.
예를 들어, CRI-O 1.20을 설치하려면, <code>VERSION=1.20</code> 로 설정한다.
사용자의 설치를 특정 릴리스에 고정할 수 있다.
버전 1.20.0을 설치하려면, <code>VERSION=1.20:1.20.0</code> 을 설정한다.<br></p><p>그런 다음, 아래를 실행한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
</span><span style=color:#b44>deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /
</span><span style=color:#b44>EOF</span>
cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list
</span><span style=color:#b44>deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/$VERSION/$OS/ /
</span><span style=color:#b44>EOF</span>

curl -L https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$VERSION</span>/<span style=color:#b8860b>$OS</span>/Release.key | sudo apt-key --keyring /etc/apt/trusted.gpg.d/libcontainers.gpg add -
curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/<span style=color:#b8860b>$OS</span>/Release.key | sudo apt-key --keyring /etc/apt/trusted.gpg.d/libcontainers.gpg add -

sudo apt-get update
sudo apt-get install cri-o cri-o-runc
</code></pre></div></div><div id=tab-cri-cri-o-installation-1 class=tab-pane role=tabpanel aria-labelledby=tab-cri-cri-o-installation-1><p><p>다음의 운영 체제에서 CRI-O를 설치하려면, 환경 변수 <code>OS</code> 를 아래의 표에서 적절한 필드로 설정한다.</p><table><thead><tr><th>운영 체제</th><th><code>$OS</code></th></tr></thead><tbody><tr><td>Ubuntu 20.04</td><td><code>xUbuntu_20.04</code></td></tr><tr><td>Ubuntu 19.10</td><td><code>xUbuntu_19.10</code></td></tr><tr><td>Ubuntu 19.04</td><td><code>xUbuntu_19.04</code></td></tr><tr><td>Ubuntu 18.04</td><td><code>xUbuntu_18.04</code></td></tr></tbody></table><p><br>그런 다음, <code>$VERSION</code> 을 사용자의 쿠버네티스 버전과 일치하는 CRI-O 버전으로 설정한다.
예를 들어, CRI-O 1.20을 설치하려면, <code>VERSION=1.20</code> 로 설정한다.
사용자의 설치를 특정 릴리스에 고정할 수 있다.
버전 1.20.0을 설치하려면, <code>VERSION=1.20:1.20.0</code> 을 설정한다.<br></p><p>그런 다음, 아래를 실행한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
</span><span style=color:#b44>deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /
</span><span style=color:#b44>EOF</span>
cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list
</span><span style=color:#b44>deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/$VERSION/$OS/ /
</span><span style=color:#b44>EOF</span>

curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/<span style=color:#b8860b>$OS</span>/Release.key | sudo apt-key --keyring /etc/apt/trusted.gpg.d/libcontainers.gpg add -
curl -L https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$VERSION</span>/<span style=color:#b8860b>$OS</span>/Release.key | sudo apt-key --keyring /etc/apt/trusted.gpg.d/libcontainers-cri-o.gpg add -

apt-get update
apt-get install cri-o cri-o-runc
</code></pre></div></div><div id=tab-cri-cri-o-installation-2 class=tab-pane role=tabpanel aria-labelledby=tab-cri-cri-o-installation-2><p><p>다음의 운영 체제에서 CRI-O를 설치하려면, 환경 변수 <code>OS</code> 를 아래의 표에서 적절한 필드로 설정한다.</p><table><thead><tr><th>운영 체제</th><th><code>$OS</code></th></tr></thead><tbody><tr><td>Centos 8</td><td><code>CentOS_8</code></td></tr><tr><td>Centos 8 Stream</td><td><code>CentOS_8_Stream</code></td></tr><tr><td>Centos 7</td><td><code>CentOS_7</code></td></tr></tbody></table><p><br>그런 다음, <code>$VERSION</code> 을 사용자의 쿠버네티스 버전과 일치하는 CRI-O 버전으로 설정한다.
예를 들어, CRI-O 1.20을 설치하려면, <code>VERSION=1.20</code> 로 설정한다.
사용자의 설치를 특정 릴리스에 고정할 수 있다.
버전 1.20.0을 설치하려면, <code>VERSION=1.20:1.20.0</code> 을 설정한다.<br></p><p>그런 다음, 아래를 실행한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/<span style=color:#b8860b>$OS</span>/devel:kubic:libcontainers:stable.repo
sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$VERSION</span>.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$VERSION</span>/<span style=color:#b8860b>$OS</span>/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$VERSION</span>.repo
sudo yum install cri-o
</code></pre></div></div><div id=tab-cri-cri-o-installation-3 class=tab-pane role=tabpanel aria-labelledby=tab-cri-cri-o-installation-3><p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo zypper install cri-o
</code></pre></div></div><div id=tab-cri-cri-o-installation-4 class=tab-pane role=tabpanel aria-labelledby=tab-cri-cri-o-installation-4><p><p><code>$VERSION</code> 을 사용자의 쿠버네티스 버전과 일치하는 CRI-O 버전으로 설정한다.
예를 들어, CRI-O 1.20을 설치하려면, <code>VERSION=1.20</code> 로 설정한다.</p><p>사용할 수 있는 버전을 찾으려면 다음을 실행한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo dnf module list cri-o
</code></pre></div><p>CRI-O는 Fedora에서 특정 릴리스를 고정하여 설치하는 방법은 지원하지 않는다.</p><p>그런 다음, 아래를 실행한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo dnf module <span style=color:#a2f>enable</span> cri-o:<span style=color:#b8860b>$VERSION</span>
sudo dnf install cri-o
</code></pre></div></div></div><p>CRI-O를 시작한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo systemctl daemon-reload
sudo systemctl <span style=color:#a2f>enable</span> crio --now
</code></pre></div><p>자세한 사항은 <a href=https://github.com/cri-o/cri-o/blob/master/install.md>CRI-O 설치 가이드</a>를
참고한다.</p><h4 id=cgroup-드라이버-1>cgroup 드라이버</h4><p>CRI-O는 기본적으로 systemd cgroup 드라이버를 사용한다. <code>cgroupfs</code> cgroup 드라이버로
전환하려면, <code>/etc/crio/crio.conf</code> 를 수정하거나 <code>/etc/crio/crio.conf.d/02-cgroup-manager.conf</code> 에
드롭-인(drop-in) 구성을 배치한다. 예를 들면, 다음과 같다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml>[crio.runtime]
conmon_cgroup = <span style=color:#b44>&#34;pod&#34;</span>
cgroup_manager = <span style=color:#b44>&#34;cgroupfs&#34;</span>
</code></pre></div><p>또한 <code>cgroupfs</code> 와 함께 CRI-O를 사용할 때 <code>pod</code> 값으로 설정해야 하는
변경된 <code>conmon_cgroup</code> 에 유의한다. 일반적으로 kubelet(일반적으로 kubeadm을 통해 수행됨)과
CRI-O의 cgroup 드라이버 구성을 동기화 상태로
유지해야 한다.</p><h3 id=도커>도커</h3><ol><li><p>각 노드에서 <a href=https://docs.docker.com/engine/install/#server>도커 엔진 설치</a>에 따라 리눅스 배포판용 도커를 설치한다. 이 <a href=https://git.k8s.io/kubernetes/build/dependencies.yaml>의존성 파일</a>에서 검증된 최신 버전의 도커를 찾을 수 있다.</p></li><li><p>특히 컨테이너의 cgroup 관리에 systemd를 사용하도록 도커 데몬을 구성한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo mkdir /etc/docker
cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/docker/daemon.json
</span><span style=color:#b44>{
</span><span style=color:#b44>  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
</span><span style=color:#b44>  &#34;log-driver&#34;: &#34;json-file&#34;,
</span><span style=color:#b44>  &#34;log-opts&#34;: {
</span><span style=color:#b44>    &#34;max-size&#34;: &#34;100m&#34;
</span><span style=color:#b44>  },
</span><span style=color:#b44>  &#34;storage-driver&#34;: &#34;overlay2&#34;
</span><span style=color:#b44>}
</span><span style=color:#b44>EOF</span>
</code></pre></div><blockquote class="note callout"><div><strong>참고:</strong> <code>overlay2</code>는 리눅스 커널 4.0 이상 또는 3.10.0-514 버전 이상을 사용하는 RHEL 또는 CentOS를 구동하는 시스템에서 선호하는 스토리지 드라이버이다.</div></blockquote></li><li><p>도커 재시작과 부팅시 실행되게 설정</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo systemctl <span style=color:#a2f>enable</span> docker
sudo systemctl daemon-reload
sudo systemctl restart docker
</code></pre></div></li></ol><blockquote class="note callout"><div><strong>참고:</strong><p>더 자세한 내용은</p><ul><li><a href=https://docs.docker.com/config/daemon/>도커 데몬 설정</a></li><li><a href=https://docs.docker.com/config/daemon/systemd/>systemd로 도커 제어</a></li></ul></div></blockquote></div><div class=td-content style=page-break-before:always><h1 id=pg-00e1646f68aeb89f9722cf6f6cfcad94>3.2 - 배포 도구로 쿠버네티스 설치하기</h1></div><div class=td-content><h1 id=pg-a16f59f325a17cdeed324d5c889f7f73>3.2.1 - kubeadm으로 클러스터 구성하기</h1></div><div class=td-content><h1 id=pg-29e59491dd6118b23072dfe9ebb93323>3.2.1.1 - kubeadm 설치하기</h1><p><img src=https://raw.githubusercontent.com/kubernetes/kubeadm/master/logos/stacked/color/kubeadm-stacked-color.png align=right width=150px>이 페이지에서는 <code>kubeadm</code> 툴박스를 설치하는 방법을 보여준다.
이 설치 프로세스를 수행한 후 kubeadm으로 클러스터를 만드는 방법에 대한 자세한 내용은 <a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>kubeadm을 사용하여 클러스터 생성하기</a> 페이지를 참고한다.</p><h2 id=시작하기-전에>시작하기 전에</h2><ul><li>호환되는 리눅스 머신. 쿠버네티스 프로젝트는 데비안 기반 배포판, 레드햇 기반 배포판, 그리고 패키지 매니저를 사용하지 않는 경우에 대한 일반적인 가이드를 제공한다.</li><li>2 GB 이상의 램을 장착한 머신. (이 보다 작으면 사용자의 앱을 위한 공간이 거의 남지 않음)</li><li>2 이상의 CPU.</li><li>클러스터의 모든 머신에 걸친 전체 네트워크 연결. (공용 또는 사설 네트워크면 괜찮음)</li><li>모든 노드에 대해 고유한 호스트 이름, MAC 주소 및 product_uuid. 자세한 내용은 <a href=#verify-mac-address>여기</a>를 참고한다.</li><li>컴퓨터의 특정 포트들 개방. 자세한 내용은 <a href=#check-required-ports>여기</a>를 참고한다.</li><li>스왑의 비활성화. kubelet이 제대로 작동하게 하려면 <strong>반드시</strong> 스왑을 사용하지 않도록 설정한다.</li></ul><h2 id=verify-mac-address>MAC 주소 및 product_uuid가 모든 노드에 대해 고유한지 확인</h2><ul><li>사용자는 <code>ip link</code> 또는 <code>ifconfig -a</code> 명령을 사용하여 네트워크 인터페이스의 MAC 주소를 확인할 수 있다.</li><li>product_uuid는 <code>sudo cat /sys/class/dmi/id/product_uuid</code> 명령을 사용하여 확인할 수 있다.</li></ul><p>일부 가상 머신은 동일한 값을 가질 수 있지만 하드웨어 장치는 고유한 주소를 가질
가능성이 높다. 쿠버네티스는 이러한 값을 사용하여 클러스터의 노드를 고유하게 식별한다.
이러한 값이 각 노드에 고유하지 않으면 설치 프로세스가
<a href=https://github.com/kubernetes/kubeadm/issues/31>실패</a>할 수 있다.</p><h2 id=네트워크-어댑터-확인>네트워크 어댑터 확인</h2><p>네트워크 어댑터가 두 개 이상이고, 쿠버네티스 컴포넌트가 디폴트 라우트(default route)에서 도달할 수 없는
경우, 쿠버네티스 클러스터 주소가 적절한 어댑터를 통해 이동하도록 IP 경로를 추가하는 것이 좋다.</p><h2 id=iptables가-브리지된-트래픽을-보게-하기>iptables가 브리지된 트래픽을 보게 하기</h2><p><code>br_netfilter</code> 모듈이 로드되었는지 확인한다. <code>lsmod | grep br_netfilter</code> 를 실행하면 된다. 명시적으로 로드하려면 <code>sudo modprobe br_netfilter</code> 를 실행한다.</p><p>리눅스 노드의 iptables가 브리지된 트래픽을 올바르게 보기 위한 요구 사항으로, <code>sysctl</code> 구성에서 <code>net.bridge.bridge-nf-call-iptables</code> 가 1로 설정되어 있는지 확인해야 한다. 다음은 예시이다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span><span style=color:#b44>br_netfilter
</span><span style=color:#b44>EOF</span>

cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span><span style=color:#b44>net.bridge.bridge-nf-call-ip6tables = 1
</span><span style=color:#b44>net.bridge.bridge-nf-call-iptables = 1
</span><span style=color:#b44>EOF</span>
sudo sysctl --system
</code></pre></div><p>자세한 내용은 <a href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%ED%94%8C%EB%9F%AC%EA%B7%B8%EC%9D%B8-%EC%9A%94%EA%B5%AC-%EC%82%AC%ED%95%AD>네트워크 플러그인 요구 사항</a> 페이지를 참고한다.</p><h2 id=check-required-ports>필수 포트 확인</h2><h3 id=컨트롤-플레인-노드>컨트롤 플레인 노드</h3><table><thead><tr><th>프로토콜</th><th>방향</th><th>포트 범위</th><th>목적</th><th>사용자</th></tr></thead><tbody><tr><td>TCP</td><td>인바운드</td><td>6443*</td><td>쿠버네티스 API 서버</td><td>모두</td></tr><tr><td>TCP</td><td>인바운드</td><td>2379-2380</td><td>etcd 서버 클라이언트 API</td><td>kube-apiserver, etcd</td></tr><tr><td>TCP</td><td>인바운드</td><td>10250</td><td>kubelet API</td><td>자체, 컨트롤 플레인</td></tr><tr><td>TCP</td><td>인바운드</td><td>10251</td><td>kube-scheduler</td><td>자체</td></tr><tr><td>TCP</td><td>인바운드</td><td>10252</td><td>kube-controller-manager</td><td>자체</td></tr></tbody></table><h3 id=워커-노드>워커 노드</h3><table><thead><tr><th>프로토콜</th><th>방향</th><th>포트 범위</th><th>목적</th><th>사용자</th></tr></thead><tbody><tr><td>TCP</td><td>인바운드</td><td>10250</td><td>kubelet API</td><td>자체, 컨트롤 플레인</td></tr><tr><td>TCP</td><td>인바운드</td><td>30000-32767</td><td>NodePort 서비스†</td><td>모두</td></tr></tbody></table><p>† <a href=/ko/docs/concepts/services-networking/service/>NodePort 서비스</a>의 기본 포트 범위.</p><p>*로 표시된 모든 포트 번호는 재정의할 수 있으므로, 사용자 지정 포트도
열려 있는지 확인해야 한다.</p><p>etcd 포트가 컨트롤 플레인 노드에 포함되어 있지만, 외부 또는 사용자 지정 포트에서
자체 etcd 클러스터를 호스팅할 수도 있다.</p><p>사용자가 사용하는 파드 네트워크 플러그인(아래 참조)은 특정 포트를 열어야 할 수도
있다. 이것은 각 파드 네트워크 플러그인마다 다르므로, 필요한 포트에 대한
플러그인 문서를 참고한다.</p><h2 id=installing-runtime>런타임 설치</h2><p>파드에서 컨테이너를 실행하기 위해, 쿠버네티스는
<a class=glossary-tooltip title="컨테이너 런타임은 컨테이너 실행을 담당하는 소프트웨어이다." data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label="컨테이너 런타임">컨테이너 런타임</a>을 사용한다.</p><ul class="nav nav-tabs" id=container-runtime role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#container-runtime-0 role=tab aria-controls=container-runtime-0 aria-selected=true>리눅스 노드</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#container-runtime-1 role=tab aria-controls=container-runtime-1>다른 운영 체제</a></li></ul><div class=tab-content id=container-runtime><div id=container-runtime-0 class="tab-pane show active" role=tabpanel aria-labelledby=container-runtime-0><p><p>기본적으로, 쿠버네티스는
<a class=glossary-tooltip title="Kubelet과 컨테이너 런타임을 통합시키기 위한 API" data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#%ec%bb%a8%ed%85%8c%ec%9d%b4%eb%84%88-%eb%9f%b0%ed%83%80%ec%9e%84 target=_blank aria-label="컨테이너 런타임 인터페이스">컨테이너 런타임 인터페이스</a>(CRI)를
사용하여 사용자가 선택한 컨테이너 런타임과 인터페이스한다.</p><p>런타임을 지정하지 않으면, kubeadm은 잘 알려진 유닉스 도메인 소켓 목록을 검색하여
설치된 컨테이너 런타임을 자동으로 감지하려고 한다.
다음 표에는 컨테이너 런타임 및 관련 소켓 경로가 나열되어 있다.</p><table><caption style=display:none>컨테이너 런타임과 소켓 경로</caption><thead><tr><th>런타임</th><th>유닉스 도메인 소켓 경로</th></tr></thead><tbody><tr><td>도커</td><td><code>/var/run/dockershim.sock</code></td></tr><tr><td>containerd</td><td><code>/run/containerd/containerd.sock</code></td></tr><tr><td>CRI-O</td><td><code>/var/run/crio/crio.sock</code></td></tr></tbody></table><p><br>도커와 containerd가 모두 감지되면 도커가 우선시된다. 이것이 필요한 이유는 도커 18.09에서
도커만 설치한 경우에도 containerd와 함께 제공되므로 둘 다 감지될 수 있기
때문이다.
다른 두 개 이상의 런타임이 감지되면, kubeadm은 오류와 함께 종료된다.</p><p>kubelet은 빌트인 <code>dockershim</code> CRI 구현을 통해 도커와 통합된다.</p><p>자세한 내용은 <a href=/ko/docs/setup/production-environment/container-runtimes/>컨테이너 런타임</a>을
참고한다.</p></div><div id=container-runtime-1 class=tab-pane role=tabpanel aria-labelledby=container-runtime-1><p><p>기본적으로, kubeadm은 컨테이너 런타임으로 <a class=glossary-tooltip title="Docker는 운영 시스템 수준의 가상화를 제공하는 소프트웨어 기술이며, 컨테이너로도 알려져 있다." data-toggle=tooltip data-placement=top href=https://docs.docker.com/engine/ target=_blank aria-label=도커(Docker)>도커(Docker)</a>를 사용한다.
kubelet은 빌트인 <code>dockershim</code> CRI 구현을 통해 도커와 통합된다.</p><p>자세한 내용은 <a href=/ko/docs/setup/production-environment/container-runtimes/>컨테이너 런타임</a>을
참고한다.</p></div></div><h2 id=kubeadm-kubelet-및-kubectl-설치>kubeadm, kubelet 및 kubectl 설치</h2><p>모든 머신에 다음 패키지들을 설치한다.</p><ul><li><p><code>kubeadm</code>: 클러스터를 부트스트랩하는 명령이다.</p></li><li><p><code>kubelet</code>: 클러스터의 모든 머신에서 실행되는 파드와 컨테이너 시작과
같은 작업을 수행하는 컴포넌트이다.</p></li><li><p><code>kubectl</code>: 클러스터와 통신하기 위한 커맨드 라인 유틸리티이다.</p></li></ul><p>kubeadm은 <code>kubelet</code> 또는 <code>kubectl</code> 을 설치하거나 관리하지 <strong>않으므로</strong>, kubeadm이
설치하려는 쿠버네티스 컨트롤 플레인의 버전과 일치하는지
확인해야 한다. 그렇지 않으면, 예상치 못한 버그 동작으로 이어질 수 있는
버전 차이(skew)가 발생할 위험이 있다. 그러나, kubelet과 컨트롤 플레인 사이에 <em>하나의</em>
마이너 버전 차이가 지원되지만, kubelet 버전은 API 서버 버전 보다
높을 수 없다. 예를 들어, 1.7.0 버전의 kubelet은 1.8.0 API 서버와 완전히 호환되어야 하지만,
그 반대의 경우는 아니다.</p><p><code>kubectl</code> 설치에 대한 정보는 <a href=/ko/docs/tasks/tools/>kubectl 설치 및 설정</a>을 참고한다.</p><blockquote class="warning callout"><div><strong>경고:</strong> 이 지침은 모든 시스템 업그레이드에서 모든 쿠버네티스 패키지를 제외한다.
이는 kubeadm 및 쿠버네티스를
<a href=/ko/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>업그레이드 하는 데 특별한 주의</a>가 필요하기 때문이다.</div></blockquote><p>버전 차이에 대한 자세한 내용은 다음을 참고한다.</p><ul><li>쿠버네티스 <a href=/docs/setup/release/version-skew-policy/>버전 및 버전-차이 정책</a></li><li>Kubeadm 관련 <a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#version-skew-policy>버전 차이 정책</a></li></ul><ul class="nav nav-tabs" id=k8s-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-0 role=tab aria-controls=k8s-install-0 aria-selected=true>데비안 기반 배포판</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-1 role=tab aria-controls=k8s-install-1>레드햇 기반 배포판</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-2 role=tab aria-controls=k8s-install-2>패키지 매니저를 사용하지 않는 경우</a></li></ul><div class=tab-content id=k8s-install><div id=k8s-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-0><p><ol><li><p><code>apt</code> 패키지 색인을 업데이트하고, 쿠버네티스 <code>apt</code> 리포지터리를 사용하는 데 필요한 패키지를 설치한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
</code></pre></div></li><li><p>구글 클라우드의 공개 사이닝 키를 다운로드 한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
</code></pre></div></li><li><p>쿠버네티스 <code>apt</code> 리포지터리를 추가한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&#34;</span> | sudo tee /etc/apt/sources.list.d/kubernetes.list
</code></pre></div></li><li><p><code>apt</code> 패키지 색인을 업데이트하고, kubelet, kubeadm, kubectl을 설치하고 해당 버전을 고정한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div></li></ol></div><div id=k8s-install-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-1><p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span><span style=color:#b44>[kubernetes]
</span><span style=color:#b44>name=Kubernetes
</span><span style=color:#b44>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
</span><span style=color:#b44>enabled=1
</span><span style=color:#b44>gpgcheck=1
</span><span style=color:#b44>repo_gpgcheck=1
</span><span style=color:#b44>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span><span style=color:#b44>exclude=kubelet kubeadm kubectl
</span><span style=color:#b44>EOF</span>

<span style=color:#080;font-style:italic># permissive 모드로 SELinux 설정(효과적으로 비활성화)</span>
sudo setenforce <span style=color:#666>0</span>
sudo sed -i <span style=color:#b44>&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config

sudo yum install -y kubelet kubeadm kubectl --disableexcludes<span style=color:#666>=</span>kubernetes

sudo systemctl <span style=color:#a2f>enable</span> --now kubelet
</code></pre></div><p><strong>참고:</strong></p><ul><li><p><code>setenforce 0</code> 및 <code>sed ...</code> 를 실행하여 permissive 모드로 SELinux를 설정하면 효과적으로 비활성화된다.
컨테이너가 호스트 파일시스템(예를 들어, 파드 네트워크에 필요한)에 접근하도록 허용하는 데 필요하다.
kubelet에서 SELinux 지원이 개선될 때까지 이 작업을 수행해야 한다.</p></li><li><p>구성 방법을 알고 있는 경우 SELinux를 활성화된 상태로 둘 수 있지만 kubeadm에서 지원하지 않는 설정이 필요할 수 있다.</p></li></ul></div><div id=k8s-install-2 class=tab-pane role=tabpanel aria-labelledby=k8s-install-2><p><p>CNI 플러그인 설치(대부분의 파드 네트워크에 필요)</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#b8860b>CNI_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v0.8.2&#34;</span>
sudo mkdir -p /opt/cni/bin
curl -L <span style=color:#b44>&#34;https://github.com/containernetworking/plugins/releases/download/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CNI_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cni-plugins-linux-amd64-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CNI_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>.tgz&#34;</span> | sudo tar -C /opt/cni/bin -xz
</code></pre></div><p>명령어 파일을 다운로드할 디렉터리 정의</p><blockquote class="note callout"><div><strong>참고:</strong> <code>DOWNLOAD_DIR</code> 변수는 쓰기 가능한 디렉터리로 설정되어야 한다.
Flatcar Container Linux를 실행 중인 경우, <code>DOWNLOAD_DIR=/opt/bin</code> 을 설정한다.</div></blockquote><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#666>=</span>/usr/local/bin
sudo mkdir -p <span style=color:#b8860b>$DOWNLOAD_DIR</span>
</code></pre></div><p>crictl 설치(kubeadm / Kubelet 컨테이너 런타임 인터페이스(CRI)에 필요)</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v1.17.0&#34;</span>
curl -L <span style=color:#b44>&#34;https://github.com/kubernetes-sigs/cri-tools/releases/download/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/crictl-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>-linux-amd64.tar.gz&#34;</span> | sudo tar -C <span style=color:#b8860b>$DOWNLOAD_DIR</span> -xz
</code></pre></div><p><code>kubeadm</code>, <code>kubelet</code>, <code>kubectl</code> 설치 및 <code>kubelet</code> systemd 서비스 추가</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#b8860b>RELEASE</span><span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#a2f;font-weight:700>$(</span>curl -sSL https://dl.k8s.io/release/stable.txt<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
<span style=color:#a2f>cd</span> <span style=color:#b8860b>$DOWNLOAD_DIR</span>
sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE</span><span style=color:#b68;font-weight:700>}</span>/bin/linux/amd64/<span style=color:#666>{</span>kubeadm,kubelet,kubectl<span style=color:#666>}</span>
sudo chmod +x <span style=color:#666>{</span>kubeadm,kubelet,kubectl<span style=color:#666>}</span>

<span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v0.4.0&#34;</span>
curl -sSL <span style=color:#b44>&#34;https://raw.githubusercontent.com/kubernetes/release/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service&#34;</span> | sed <span style=color:#b44>&#34;s:/usr/bin:</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>:g&#34;</span> | sudo tee /etc/systemd/system/kubelet.service
sudo mkdir -p /etc/systemd/system/kubelet.service.d
curl -sSL <span style=color:#b44>&#34;https://raw.githubusercontent.com/kubernetes/release/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf&#34;</span> | sed <span style=color:#b44>&#34;s:/usr/bin:</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>:g&#34;</span> | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre></div><p><code>kubelet</code> 활성화 및 시작</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>systemctl <span style=color:#a2f>enable</span> --now kubelet
</code></pre></div><blockquote class="note callout"><div><strong>참고:</strong> Flatcar Container Linux 배포판은 <code>/usr</code> 디렉터리를 읽기 전용 파일시스템으로 마운트한다.
클러스터를 부트스트랩하기 전에, 쓰기 가능한 디렉터리를 구성하기 위한 추가 단계를 수행해야 한다.
쓰기 가능한 디렉터리를 설정하는 방법을 알아 보려면 <a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#usr-mounted-read-only/>Kubeadm 문제 해결 가이드</a>를 참고한다.</div></blockquote></div></div><p>kubelet은 이제 kubeadm이 수행할 작업을 알려 줄 때까지 크래시루프(crashloop) 상태로
기다려야 하므로 몇 초마다 다시 시작된다.</p><h2 id=컨트롤-플레인-노드에서-kubelet이-사용하는-cgroup-드라이버-구성>컨트롤 플레인 노드에서 kubelet이 사용하는 cgroup 드라이버 구성</h2><p>도커를 사용할 때, kubeadm은 kubelet 용 cgroup 드라이버를 자동으로 감지하여
런타임 중에 <code>/var/lib/kubelet/config.yaml</code> 파일에 설정한다.</p><p>다른 CRI를 사용하는 경우, 다음과 같이 <code>cgroupDriver</code> 값을 <code>kubeadm init</code> 에 전달해야 한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>cgroupDriver</span>:<span style=color:#bbb> </span>&lt;value&gt;<span style=color:#bbb>
</span></code></pre></div><p>자세한 내용은 <a href=/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file>구성 파일과 함께 kubeadm init 사용</a>과
<a href=/docs/reference/config-api/kubelet-config.v1beta1/><code>KubeletConfiguration</code> 레퍼런스</a>를 참고한다.</p><p><code>cgroupfs</code> 가 이미 kubelet의 기본값이기 때문에, 사용자의
CRI cgroup 드라이버가 <code>cgroupfs</code> 가 아닌 <strong>경우에만</strong> 위와 같이 설정해야 한다.</p><blockquote class="note callout"><div><strong>참고:</strong> <code>--cgroup-driver</code> 플래그가 kubelet에 의해 사용 중단되었으므로, <code>/var/lib/kubelet/kubeadm-flags.env</code>
또는 <code>/etc/default/kubelet</code>(RPM에 대해서는 <code>/etc/sysconfig/kubelet</code>)에 있는 경우, 그것을 제거하고 대신 KubeletConfiguration을
사용한다(기본적으로 <code>/var/lib/kubelet/config.yaml</code> 에 저장됨).</div></blockquote><p>CRI-O 및 containerd와 같은 다른 컨테이너 런타임에 대한 cgroup 드라이버의
자동 감지에 대한 작업이 진행 중이다.</p><h2 id=문제-해결>문제 해결</h2><p>kubeadm에 문제가 있는 경우, <a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/>문제 해결 문서</a>를 참고한다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>kubeadm을 사용하여 클러스터 생성</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4c656c5eda3e1c06ad1aedebdc04a211>3.2.1.2 - kubeadm으로 컨트롤 플레인 사용자 정의하기</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [stable]</code></div><p>kubeadm의 <code>ClusterConfiguration</code> 오브젝트는 API 서버, 컨트롤러매니저, 스케줄러와 같은 컨트롤 플레인 구성요소에 전달되는 기본 플래그 <code>extraArgs</code> 필드를 노출한다. 이 구성요소는 다음 필드를 사용하도록 정의되어 있다.</p><ul><li><code>apiServer</code></li><li><code>controllerManager</code></li><li><code>scheduler</code></li></ul><p><code>extraArgs</code> 필드는 <code>key: value</code> 쌍으로 구성되어 있다. 컨트롤 플레인 구성요소를 위한 플래그를 대체하려면 다음을 수행한다.</p><ol><li>사용자 구성에서 적절한 필드를 추가한다.</li><li>필드에 대체할 플래그를 추가한다.</li><li><code>kubeadm init</code>에 <code>--config &lt;YOUR CONFIG YAML></code> 파라미터를 추가해서 실행한다.</li></ol><p>각 필드의 구성에서 자세한 정보를 보려면,
<a href=https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#ClusterConfiguration>API 참고 문서</a>에서 확인해 볼 수 있다.</p><blockquote class="note callout"><div><strong>참고:</strong> <code>kubeadm config print init-defaults</code>를 실행하고 원하는 파일에 출력을 저장하여 기본값인 <code>ClusterConfiguration</code> 오브젝트를 생성할 수 있다.</div></blockquote><h2 id=apiserver-플래그>APIServer 플래그</h2><p>자세한 내용은 <a href=/docs/reference/command-line-tools-reference/kube-apiserver/>kube-apiserver에 대한 참고 문서</a>를 확인한다.</p><p>사용 예:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta2<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.16.0<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiServer</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>advertise-address</span>:<span style=color:#bbb> </span><span style=color:#666>192.168.0.103</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>anonymous-auth</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;false&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>enable-admission-plugins</span>:<span style=color:#bbb> </span>AlwaysPullImages,DefaultStorageClass<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>audit-log-path</span>:<span style=color:#bbb> </span>/home/johndoe/audit.log<span style=color:#bbb>
</span></code></pre></div><h2 id=컨트롤러매니저-플래그>컨트롤러매니저 플래그</h2><p>자세한 내용은 <a href=/docs/reference/command-line-tools-reference/kube-controller-manager/>kube-controller-manager에 대한 참고 문서</a>를 확인한다.</p><p>사용 예:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta2<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.16.0<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>controllerManager</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-key-file</span>:<span style=color:#bbb> </span>/home/johndoe/keys/ca.key<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>bind-address</span>:<span style=color:#bbb> </span><span style=color:#666>0.0.0.0</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>deployment-controller-sync-period</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;50&#34;</span><span style=color:#bbb>
</span></code></pre></div><h2 id=스케줄러-플래그>스케줄러 플래그</h2><p>자세한 내용은 <a href=/docs/reference/command-line-tools-reference/kube-scheduler/>kube-scheduler에 대한 참고 문서</a>를 확인한다.</p><p>사용 예:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta2<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.16.0<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>scheduler</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>bind-address</span>:<span style=color:#bbb> </span><span style=color:#666>0.0.0.0</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>config</span>:<span style=color:#bbb> </span>/home/johndoe/schedconfig.yaml<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubeconfig</span>:<span style=color:#bbb> </span>/home/johndoe/kubeconfig.yaml<span style=color:#bbb>
</span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-015edbc7cc688d31b1d1edce7c186135>3.2.1.3 - 고가용성 토폴로지 선택</h1><p>이 페이지는 고가용성(HA) 쿠버네티스 클러스터의 토플로지를 구성하는 두 가지 선택 사항을 설명한다.</p><p>다음과 같이 HA 클러스터를 구성할 수 있다.</p><ul><li>etcd 노드와 컨트롤 플레인 노드를 함께 위치시키는 중첩된(stacked) 컨트롤 플레인 노드 방식</li><li>etcd와 컨트롤 플레인이 분리된 노드에서 운영되는 외부 etcd 노드 방식</li></ul><p>HA 클러스터를 구성하기 전에 각 토플로지의 장단점을 주의 깊게 고려해야 한다.</p><blockquote class="note callout"><div><strong>참고:</strong> kubeadm은 etcd 클러스터를 정적으로 부트스트랩한다. 자세한 내용은 etcd <a href=https://github.com/etcd-io/etcd/blob/release-3.4/Documentation/op-guide/clustering.md#static>클러스터 구성 가이드</a>
를 읽는다.</div></blockquote><h2 id=중첩된-etcd-토플로지>중첩된 etcd 토플로지</h2><p>중첩된 HA 클러스터는 etcd에서 제공하는 분산 데이터 저장소 클러스터를,
컨트롤 플레인 구성 요소를 실행하는 kubeadm으로 관리되는 노드에 의해서 형성된 클러스터 상단에
중첩하는 <a href=https://en.wikipedia.org/wiki/Network_topology>토플로지</a>이다.</p><p>각 컨트롤 플레인 노드는 <code>kube-apiserver</code>, <code>kube-scheduler</code>, <code>kube-controller-manager</code> 인스턴스를 운영한다.
<code>kube-apiserver</code>는 로드 밸런서를 이용하여 워커 노드에 노출되어 있다.</p><p>각 컨트롤 플레인 노드는 지역 etcd 맴버를 생성하고
이 etcd 맴버는 오직 해당 노드의 <code>kube-apiserver</code>와 통신한다.
비슷한 방식이 지역의 <code>kube-controller-manager</code>와 <code>kube-scheduler</code>에도 적용된다.</p><p>이 토플로지는 컨트롤 플레인과 etcd 맴버가 같은 노드에 묶여 있다.
이는 외부 etcd 노드의 클러스터를 구성하는 것보다는 단순하며 복제 관리도 간단하다.</p><p>그러나 중첩된 클러스터는 커플링에 실패할 위험이 있다. 한 노드가 다운되면 etcd 맴버와 컨트롤 플레인을 모두 잃어버리고,
중복성도 손상된다. 더 많은 컨트롤 플레인 노드를 추가하여 이 위험을 완화할 수 있다.</p><p>그러므로 HA 클러스터를 위해 최소 3개인 중첩된 컨트롤 플레인 노드를 운영해야 한다.</p><p>이는 kubeadm의 기본 토플로지이다. 지역 etcd 맴버는
<code>kubeadm init</code>와 <code>kubeadm join --control-plane</code> 을 이용할 때에 컨트롤 플레인 노드에 자동으로 생성된다.</p><p><img src=/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg alt="중첩된 etcd 토플로지"></p><h2 id=외부-etcd-토플로지>외부 etcd 토플로지</h2><p>외부 etcd를 이용하는 HA 클러스터는 etcd로 제공한 분산된 데이터 스토리지 클러스터가 컨트롤 플레인 구성 요소를 운영하는 노드로 형성하는 클러스터의 외부에 있는 <a href=https://en.wikipedia.org/wiki/Network_topology>토플로지</a>이다.</p><p>중첩된 etcd 토플로지와 유사하게, 외부 etcd 토플로지에 각 컨트롤 플레인 노드는 <code>kube-apiserver</code>, <code>kube-scheduler</code>, <code>kube-controller-manager</code>의 인스턴스를 운영한다. 그리고 <code>kube-apiserver</code>는 로드 밸런서를 이용하여 워커노드에 노출한다. 그러나 etcd 맴버는 분리된 호스트에서 운영되고, 각 etcd 호스트는 각 컨트롤 플레인 노드의 <code>kube-apiserver</code>와 통신한다.</p><p>이 토플로지는 컨트롤 플레인과 etcd 맴버를 분리한다. 이는 그러므로
컨트롤 플레인 인스턴스나 etcd 맴버를 잃는 충격이 덜하고,
클러스터 중복성에 있어 중첩된 HA 토플로지만큼 영향을 미치지 않는다.</p><p>그러나, 이 토플로지는 중첩된 토플로지에 비해 호스트 개수가 두배나 필요하다.
이 토플로지로 HA 클러스터를 구성하기 위해서는 최소한 3개의 컨트롤 플레인과 3개의 etcd 노드가 필요하다.</p><p><img src=/images/kubeadm/kubeadm-ha-topology-external-etcd.svg alt="외부 etcd 토플로지"></p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/setup/production-environment/tools/kubeadm/high-availability/>kubeadm을 이용하여 고가용성 클러스터 구성하기</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ed857e09999827b013ee9062dc9c59bb>3.2.1.4 - 컨트롤 플레인을 자체 호스팅하기 위해 쿠버네티스 클러스터 구성하기</h1><h3 id=self-hosting>쿠버네티스 컨트롤 플레인 자체 호스팅하기</h3><p>kubeadm은 실험적으로 <em>자체 호스팅</em> 된 쿠버네티스 컨트롤 플레인을 만들 수 있도록
해준다. API 서버, 컨트롤러 매니저 및 스케줄러와 같은 주요 구성 요소가 정적(static) 파일을
통해 kubelet에 구성된 <a href=/ko/docs/tasks/configure-pod-container/static-pod/>스태틱(static) 파드</a>
대신 쿠버네티스 API를 통해 구성된 <a href=/ko/docs/concepts/workloads/controllers/daemonset/>데몬셋(DaemonSet) 파드</a>
로 실행된다.</p><p>자체 호스팅된 클러스터를 만들려면 <a href=/docs/reference/setup-tools/kubeadm/kubeadm-alpha/#cmd-selfhosting>kubeadm alpha selfhosting pivot</a>
명령어를 확인한다.</p><h4 id=주의사항>주의사항</h4><blockquote class="caution callout"><div><strong>주의:</strong> 이 기능은 클러스터를 지원되지 않는 상태로 전환하여 더 이상 클러스터를 관리할 수 없게 만든다.
이것은 <code>kubeadm upgrade</code>를 포함한다.</div></blockquote><ol><li><p>1.8 이후 버전에서 자체 호스팅은 몇 가지 중요한 한계가 있다.
특히 자체 호스팅된 클러스터는 수동 조정 없이는
<em>컨트롤 플레인 노드를 재부팅하고 나서 복구할 수 없다.</em></p></li><li><p>기본적으로 자체 호스팅된 컨트롤 플레인 파드는
<a href=/ko/docs/concepts/storage/volumes/#hostpath><code>hostPath</code></a> 볼륨에서 불러 온
자격 증명에 의존한다. 초기 생성을 제외하고, 이러한 자격 증명은 kubeadm에 의해
관리되지 않는다.</p></li><li><p>컨트롤 플레인의 자체 호스팅된 부분에는 스태틱 파드로 실행되는 etcd가
포함되지 않는다.</p></li></ol><h4 id=프로세스>프로세스</h4><p>자체 호스팅 부트스트랩 프로세스는 <a href=https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.9.md#optional-self-hosting>kubeadm 설계
문서</a>에 기록되어 있다.</p><p>요약하면 <code>kubeadm alpha selfhosting</code>은 다음과 같이 작동한다.</p><ol><li><p>부트스트랩 스태틱 컨트롤 플레인이 실행되고 정상 상태가 될 때까지 기다린다.
이것은 자체 호스팅이 없는 <code>kubeadm init</code> 프로세스와 동일하다.</p></li><li><p>스태틱 컨트롤 플레인 파드 매니페스트를 사용하여 자체 호스팅된 컨트롤
플레인을 실행할 데몬셋 매니페스트 집합을 구성한다. 또한 필요한 경우
해당 매니페스트를 수정한다. 예를 들어, 시크릿을 위한 새로운 볼륨을
추가한다.</p></li><li><p><code>kube-system</code> 네임스페이스에 데몬셋을 생성하고 결과 파드가 실행될 때까지
대기한다.</p></li><li><p>일단 자체 호스팅된 파드가 동작하면 관련 스태틱 파드가 삭제되고
kubeadm은 계속해서 다음 구성 요소를 설치한다.
이것은 kubelet이 스태틱 파드를 멈추게 한다.</p></li><li><p>기존의 컨트롤 플레인이 멈추면 새롭게 자체 호스팅된 컨트롤 플레인은
리스닝 포트에 바인딩하여 활성화할 수 있다.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-478acca1934b6d89a0bc00fb25bfe5b6>3.2.2 - Kops로 쿠버네티스 설치하기</h1><p>이곳 빠른 시작에서는 사용자가 얼마나 쉽게 AWS에 쿠버네티스 클러스터를 설치할 수 있는지 보여준다.
<a href=https://github.com/kubernetes/kops><code>kops</code></a>라는 이름의 툴을 이용할 것이다.</p><p>kops는 자동화된 프로비저닝 시스템인데,</p><ul><li>완전 자동화된 설치</li><li>DNS를 통해 클러스터들의 신원 확인</li><li>자체 복구: 모든 자원이 Auto-Scaling Groups에서 실행</li><li>다양한 OS 지원(Debian, Ubuntu 16.04 supported, CentOS & RHEL, Amazon Linux and CoreOS) - <a href=https://github.com/kubernetes/kops/blob/master/docs/operations/images.md>images.md</a> 보기</li><li>고가용성 지원 - <a href=https://github.com/kubernetes/kops/blob/master/docs/operations/high_availability.md>high_availability.md</a> 보기</li><li>직접 프로비저닝 하거나 또는 할 수 있도록 terraform 매니페스트를 생성 - <a href=https://github.com/kubernetes/kops/blob/master/docs/terraform.md>terraform.md</a> 보기</li></ul><h2 id=시작하기-전에>시작하기 전에</h2><ul><li><p><a href=/ko/docs/tasks/tools/>kubectl</a>을 반드시 설치해야 한다.</p></li><li><p>반드시 64-bit (AMD64 그리고 Intel 64)디바이스 아키텍쳐 위에서 <code>kops</code> 를 <a href=https://github.com/kubernetes/kops#installing>설치</a> 한다.</p></li><li><p><a href=https://docs.aws.amazon.com/polly/latest/dg/setting-up.html>AWS 계정</a>이 있고 <a href=https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys>IAM 키</a>를 생성하고 <a href=https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html#cli-quick-configuration>구성</a>해야 한다. IAM 사용자는 <a href=https://github.com/kubernetes/kops/blob/master/docs/getting_started/aws.md#setup-iam-user>적절한 권한</a>이 필요하다.</p></li></ul><h2 id=클러스터-구축>클러스터 구축</h2><h3 id=1-5-kops-설치>(1/5) kops 설치</h3><h4 id=설치>설치</h4><p><a href=https://github.com/kubernetes/kops/releases>releases page</a>에서 kops를 다운로드한다(소스 코드로부터 빌드하는 것도 역시 편리하다).</p><ul class="nav nav-tabs" id=kops-installation role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kops-installation-0 role=tab aria-controls=kops-installation-0 aria-selected=true>macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kops-installation-1 role=tab aria-controls=kops-installation-1>리눅스</a></li></ul><div class=tab-content id=kops-installation><div id=kops-installation-0 class="tab-pane show active" role=tabpanel aria-labelledby=kops-installation-0><p><p>최신 버전의 릴리스를 다운받는 명령어:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl -LO https://github.com/kubernetes/kops/releases/download/<span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest
| grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>/kops-darwin-amd64
</code></pre></div><p>특정 버전을 다운로드 받는다면 명령의 다음 부분을 특정 kops 버전으로 변경한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>
</code></pre></div><p>예를 들어 kops 버전을 v1.15.0을 다운로드 하려면 다음을 입력한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl -LO  https://github.com/kubernetes/kops/releases/download/1.15.0/kops-darwin-amd64
</code></pre></div><p>kops 바이너리를 실행 가능하게 만든다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>chmod +x kops-darwin-amd64
</code></pre></div><p>kops 바이너리를 사용자의 PATH로 이동한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo mv kops-darwin-amd64 /usr/local/bin/kops
</code></pre></div><p>사용자는 <a href=https://brew.sh/>Homebrew</a>를 이용해서 kops를 설치할 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>brew update <span style=color:#666>&amp;&amp;</span> brew install kops
</code></pre></div></div><div id=kops-installation-1 class=tab-pane role=tabpanel aria-labelledby=kops-installation-1><p><p>최신 릴리스를 다운로드 받는 명령어:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl -LO https://github.com/kubernetes/kops/releases/download/<span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>/kops-linux-amd64
</code></pre></div><p>특정 버전의 kops를 다운로드하려면 명령의 다음 부분을 특정 kops 버전으로 변경한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>
</code></pre></div><p>예를 들어 kops 버전을 v1.15.0을 다운로드 하려면 다음을 입력한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl -LO  https://github.com/kubernetes/kops/releases/download/1.15.0/kops-linux-amd64
</code></pre></div><p>kops 바이너리를 실행 가능하게 만든다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>chmod +x kops-linux-amd64
</code></pre></div><p>kops 바이너리를 사용자의 PATH로 이동한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo mv kops-linux-amd64 /usr/local/bin/kops
</code></pre></div><p>사용자는 <a href=https://docs.brew.sh/Homebrew-on-Linux>Homebrew</a>를 이용해서 kops를 설치할 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>brew update <span style=color:#666>&amp;&amp;</span> brew install kops
</code></pre></div></div></div><h3 id=2-5-클러스터에-사용할-route53-domain-생성>(2/5) 클러스터에 사용할 route53 domain 생성</h3><p>kops는 클러스터 내부와 외부 모두에서 검색을 위해 DNS을 사용하기에 클라이언트에서 쿠버네티스 API 서버에 연결할
수 있다.</p><p>이런 클러스터 이름에 kops는 명확한 견해을 가지는데: 반드시 유효한 DNS 이름이어야 한다. 이렇게 함으로써
사용자는 클러스터를 헷갈리지 않을것이고, 동료들과 혼선없이 공유할 수 있으며,
IP를 기억할 필요없이 접근할 수 있다.</p><p>그렇게 하고 있겠지만, 클러스터를 구분하기 위해 서브도메인을 활용할 수 있다. 예를 들어
<code>useast1.dev.example.com</code>을 이용한다면, API 서버 엔드포인트는 <code>api.useast1.dev.example.com</code>가 될 것이다.</p><p>Route53 hosted zone은 서브도메인도 지원한다. 여러분의 hosted zone은 <code>useast1.dev.example.com</code>,
<code>dev.example.com</code> 그리고 <code>example.com</code> 같은 것도 될 수 있다. kops는 이것들 모두와 잘 동작하며,
사용자는 보통 조직적인 부분을 고려해 결정한다(예를 들어, 사용자가 <code>dev.example.com</code>하위에 레코드를 생성하는것은 허용되지만,
<code>example.com</code>하위에는 그렇지 않을 수 있다).</p><p><code>dev.example.com</code>을 hosted zone으로 사용하고 있다고 가정해보자.
보통 사용자는 <a href=https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingNewSubdomain.html>일반적인 방법</a> 에 따라 생성하거나
<code>aws route53 create-hosted-zone --name dev.example.com --caller-reference 1</code> 와 같은 커맨드를 이용한다.</p><p>그 후 도메인 내 레코드들을 확인할 수 있도록 상위 도메인내에 NS 레코드를 생성해야 한다. 여기서는,
<code>dev</code> NS 레코드를 <code>example.com</code>에 생성한다. 만약 이것이 루트 도메인 네임이라면 이 NS 레코드들은
도메인 등록기관을 통해서 생성해야 한다(예를 들어, <code>example.com</code>는 <code>example.com</code>를 구매한 곳에서 설정 할 수 있다).</p><p>route53 도메인 설정을 확인한다(문제를 만드는 가장 큰 이유이다!). dig 툴을 실행해서
클러스터 설정이 정확한지 한번 더 확인한다.</p><p><code>dig NS dev.example.com</code></p><p>당신의 hosted zone용으로 할당된 3~4개의 NS 레코드를 Route53에서 확인할 수 있어야 한다.</p><h3 id=3-5-클러스터-상태-저장용-s3-버킷-생성>(3/5) 클러스터 상태 저장용 S3 버킷 생성</h3><p>kops는 설치 이후에도 클러스터를 관리할 수 있다. 이를 위해 사용자가 생성한 클러스터의 상태나
사용하는 키 정보들을 지속적으로 추적해야 한다. 이 정보가 S3에 저장된다.
이 버킷의 접근은 S3 권한으로 제어한다.</p><p>다수의 클러스터는 동일한 S3 버킷을 이용할 수 있고, 사용자는 이 S3 버킷을 같은 클러스트를
운영하는 동료에게 공유할 수 있다. 하지만 이 S3 버킷에 접근 가능한 사람은 사용자의
모든 클러스터에 관리자 접근이 가능하게 되니, 운영팀 이외로
공유되지 않도록 해야 한다.</p><p>그래서 보통 한 운영팀 당 하나의 S3 버킷을 가지도록 하기도 한다.(그리고 종종 운영팀
이름은 위에서 언급한 hosted zone과 동일하게 짓기도 한다!)</p><p>우리 예제에서는, <code>dev.example.com</code>를 hosted zone으로 했으니 <code>clusters.dev.example.com</code>를
S3 버킷 이름으로 정하자.</p><ul><li><p><code>AWS_PROFILE</code>를 선언한다. (AWS CLI 동작을 위해 다른 profile을 선택해야 할 경우)</p></li><li><p><code>aws s3 mb s3://clusters.dev.example.com</code>를 이용해 S3 버킷을 생성한다.</p></li><li><p><code>export KOPS_STATE_STORE=s3://clusters.dev.example.com</code> 하면, kops는 이 위치를 기본값으로 인식할 것이다.
이 부분을 bash profile등에 넣어두는것을 권장한다.</p></li></ul><h3 id=4-5-클러스터-설정-구성>(4/5) 클러스터 설정 구성</h3><p>클러스터 설정하려면, <code>kops create cluster</code> 를 실행한다:</p><p><code>kops create cluster --zones=us-east-1c useast1.dev.example.com</code></p><p>kops는 클러스터에 사용될 설정을 생성할것이다. 여기서 주의할 점은 실제 클러스트 리소스가 아닌 <em>설정</em>
만을 생성한다는 것에 주의하자 - 이 부분은 다음 단계에서 <code>kops update cluster</code> 으로
구성해볼 것이다. 그 때 만들어진 설정을 점검하거나 변경할 수 있다.</p><p>더 자세한 내용을 알아보기 위한 커맨드가 출력된다.</p><ul><li>클러스터 조회: <code>kops get cluster</code></li><li>클러스트 수정: <code>kops edit cluster useast1.dev.example.com</code></li><li>인스턴스 그룹 수정: <code>kops edit ig --name=useast1.dev.example.com nodes</code></li><li>마스터 인스턴스 그룹 수정: <code>kops edit ig --name=useast1.dev.example.com master-us-east-1c</code></li></ul><p>만약 kops사용이 처음이라면, 얼마 걸리지 않으니 이들을 시험해 본다. 인스턴스 그룹은
쿠버네티스 노드로 등록된 인스턴스의 집합을 말한다. AWS상에서는 auto-scaling-groups를
통해 만들어진다. 사용자는 여러 개의 인스턴스 그룹을 관리할 수 있는데,
예를 들어, spot과 on-demand 인스턴스 조합 또는 GPU 와 non-GPU 인스턴스의 조합으로 구성할 수 있다.</p><h3 id=5-5-aws에-클러스터-생성>(5/5) AWS에 클러스터 생성</h3><p><code>kops update cluster</code>를 실행해 AWS에 클러스터를 생성한다.</p><p><code>kops update cluster useast1.dev.example.com --yes</code></p><p>실행은 수 초 만에 되지만, 실제로 클러스터가 준비되기 전까지 수 분이 걸릴 수 있다.
언제든 <code>kops update cluster</code>로 클러스터 설정을 변경할 수 있다. 사용자가
변경한 클러스터 설정을 그대로 반영해 줄 것이며, 필요다하면 AWS 나 쿠버네티스를 재설정 해 줄것이다.</p><p>예를 들면, <code>kops edit ig nodes</code> 뒤에 <code>kops update cluster --yes</code>를 실행해 설정을 반영한다.
그리고 <code>kops rolling-update cluster</code>로 설정을 즉시 원복시킬 수 있다.</p><p><code>--yes</code>를 명시하지 않으면 <code>kops update cluster</code> 커맨드 후 어떤 설정이 변경될지가 표시된다.
운영계 클러스터 관리할 때 사용하기 좋다!</p><h3 id=다른-애드온-탐험>다른 애드온 탐험</h3><p><a href=/ko/docs/concepts/cluster-administration/addons/>애드온 리스트</a> 에서 쿠버네티스 클러스터용 로깅, 모니터링, 네트워크 정책, 시각화 & 제어 등을 포함한 다른 애드온을 확인해본다.</p><h2 id=정리하기>정리하기</h2><ul><li><code>kops delete cluster useast1.dev.example.com --yes</code> 로 클러스터를 삭제한다.</li></ul><h2 id=다음-내용>다음 내용</h2><ul><li>쿠버네티스 <a href=/ko/docs/concepts/>개념</a> 과 <a href=/ko/docs/reference/kubectl/overview/><code>kubectl</code></a>에 대해 더 알아보기.</li><li>튜토리얼, 모범사례 및 고급 구성 옵션에 대한 <code>kops</code> <a href=https://kops.sigs.k8s.io/>고급 사용법</a>에 대해 더 자세히 알아본다.</li><li>슬랙(Slack)에서 <code>kops</code> 커뮤니티 토론을 할 수 있다: <a href=https://github.com/kubernetes/kops#other-ways-to-communicate-with-the-contributors>커뮤니티 토론</a></li><li>문제를 해결하거나 이슈를 제기하여 <code>kops</code> 에 기여한다. <a href=https://github.com/kubernetes/kops/issues>깃헙 이슈</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f8b4964187fe973644e06ee629eff1de>3.2.3 - Kubespray로 쿠버네티스 설치하기</h1><p>이 가이드는 <a href=https://github.com/kubernetes-sigs/kubespray>Kubespray</a>를 이용하여 GCE, Azure, OpenStack, AWS, vSphere, Packet(베어메탈), Oracle Cloud infrastructure(실험적) 또는 베어메탈 등에서 운영되는 쿠버네티스 클러스터를 설치하는 과정을 보여준다.</p><p>Kubespray는 <a href=https://docs.ansible.com/>Ansible</a> 플레이북, <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/ansible.md>인벤토리</a>, 프로비저닝 도구와 일반적인 운영체제, 쿠버네티스 클러스터의 설정 관리 작업에 대한 도메인 지식의 결합으로 만들어졌다. Kubespray는 아래와 같은 기능을 제공한다.</p><ul><li>고가용성을 지닌 클러스터</li><li>구성할 수 있는 속성들</li><li>대부분의 인기있는 리눅스 배포판들에 대한 지원<ul><li>Ubuntu 16.04, 18.04, 20.04</li><li>CentOS/RHEL/Oracle Linux 7, 8</li><li>Debian Buster, Jessie, Stretch, Wheezy</li><li>Fedora 31, 32</li><li>Fedora CoreOS</li><li>openSUSE Leap 15</li><li>Flatcar Container Linux by Kinvolk</li></ul></li><li>지속적인 통합 (CI) 테스트</li></ul><p>클러스터를 설치해 줄 도구로 유스케이스와 가장 잘 맞는 것을 고르고 싶다면, kubespray를 <a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>, <a href=/ko/docs/setup/production-environment/tools/kops/>kops</a>와 <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md>비교한 글</a>을 읽어보자.</p><h2 id=클러스터-생성하기>클러스터 생성하기</h2><h3 id=1-5-아래의-요건-충족하기>(1/5) 아래의 요건 충족하기</h3><p>언더레이(underlay) <a href=https://github.com/kubernetes-sigs/kubespray#requirements>요건</a>을 만족하는 프로비전 한다.</p><ul><li><strong>Ansible의 명령어를 실행하기 위해 Ansible v 2.9와 Python netaddr 라이브러리가 머신에 설치되어 있어야 한다</strong></li><li><strong>Ansible 플레이북을 실행하기 위해 2.11 (혹은 그 이상) 버전의 Jinja가 필요하다</strong></li><li>타겟 서버들은 docker 이미지를 풀(pull) 하기 위해 반드시 인터넷에 접속할 수 있어야 한다. 아니라면, 추가적인 설정을 해야 한다 (<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/offline-environment.md>오프라인 환경 확인하기</a>)</li><li>타겟 서버들의 <strong>IPv4 포워딩</strong>이 활성화되어야 한다</li><li><strong>SSH 키</strong>가 인벤토리의 모든 서버들에 복사되어야 한다</li><li><strong>방화벽은 관리되지 않는다</strong>. 사용자가 예전 방식대로 고유한 규칙을 구현해야 한다. 디플로이먼트 과정에서의 문제를 방지하려면 방화벽을 비활성화해야 한다</li><li>만약 kubespray가 루트가 아닌 사용자 계정에서 실행되었다면, 타겟 서버에서 알맞은 권한 확대 방법이 설정되어야 한다. 그 뒤 <code>ansible_become</code> 플래그나 커맨드 파라미터들, <code>--become</code> 또는 <code>-b</code> 가 명시되어야 한다</li></ul><p>Kubespray는 환경에 맞는 프로비저닝을 돕기 위해 아래와 같은 서비스를 제공한다:</p><ul><li>아래 클라우드 제공 업체를 위한 <a href=https://www.terraform.io/>Terraform</a> 스크립트:<ul><li><a href=https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform/aws>AWS</a></li><li><a href=https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform/openstack>OpenStack</a></li><li><a href=https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform/packet>Packet</a></li></ul></li></ul><h3 id=2-5-인벤토리-파일-구성하기>(2/5) 인벤토리 파일 구성하기</h3><p>서버들을 프로비저닝 한 후, <a href=https://docs.ansible.com/ansible/intro_inventory.html>Ansible의 인벤토리 파일</a>을 만들어야 한다. 수동으로 만들 수도 있고, 동적인 인벤토리 스크립트를 통해 만들 수도 있다. 더 많이 알고싶다면 " <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#building-your-own-inventory>나만의 인벤토리 만들기</a>" 글을 확인하자.</p><h3 id=3-5-클러스터-디플로이먼트-계획하기>(3/5) 클러스터 디플로이먼트 계획하기</h3><p>Kubespray에서는 디플로이먼트의 많은 속성들을 사용자가 정의(customize)할 수 있다:</p><ul><li>디플로이먼트 모드의 선택: kubeadm 또는 그 외</li><li>CNI(네트워킹) 플러그인</li><li>DNS 설정</li><li>컨트롤 플레인 선택: 네이티브/바이너리 또는 컨테이너화 된 것</li><li>컴포넌트 버전</li><li>Calico 라우터 리플렉터</li><li>컴포넌트 런타임 옵션<ul><li><a class=glossary-tooltip title="Docker는 운영 시스템 수준의 가상화를 제공하는 소프트웨어 기술이며, 컨테이너로도 알려져 있다." data-toggle=tooltip data-placement=top href=https://docs.docker.com/engine/ target=_blank aria-label=도커(Docker)>도커(Docker)</a></li><li><a class=glossary-tooltip title="A container runtime with an emphasis on simplicity, robustness and portability" data-toggle=tooltip data-placement=top href=https://containerd.io/docs/ target=_blank aria-label=containerd>containerd</a></li><li><a class=glossary-tooltip title="A lightweight container runtime specifically for Kubernetes" data-toggle=tooltip data-placement=top href=https://cri-o.io/#what-is-cri-o target=_blank aria-label=CRI-O>CRI-O</a></li></ul></li><li>인증서 생성 방법</li></ul><p>Kubespray의 <a href=https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html>변수 파일들</a>을 사용자가 정의할 수 있다. 만약 Kubespray를 처음 접하는 경우, kubespray의 기본 설정값을 이용해 클러스터를 배포하고 쿠버네티스를 탐색하는 것이 좋다.</p><h3 id=4-5-클러스터-배포하기>(4/5) 클러스터 배포하기</h3><p>다음으로, 클러스터를 배포한다.</p><p><a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#starting-custom-deployment>Ansible-플레이북</a>을 이용한 클러스터 디플로이먼트</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>ansible-playbook -i your/inventory/inventory.ini cluster.yml -b -v <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  --private-key<span style=color:#666>=</span>~/.ssh/private_key
</code></pre></div><p>규모가 큰 디플로이먼트는 (100개 이상의 노드) 최적의 결과를 얻기 위해 <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/large-deployments.md>특정한 조정</a>을 필요로 할 수도 있다.</p><h3 id=5-5-디플로이먼트-검증하기>(5/5) 디플로이먼트 검증하기</h3><p>Kubespray는 Netchecker를 사용하여 파드 사이의 연결성과 DNS 해석을 검증할 방법을 제공한다. Netchecker는 netchecker-agents 파드들이 DNS 요청을 해석하고 기본(default) 네임스페이스 내부에서 서로에게 ping을 보낼 수 있도록 보장한다. 그 파드들은 나머지 워크로드의 유사한 동작을 모방하고 클러스터의 상태 표시기 역할을 한다.</p><h2 id=클러스터-동작>클러스터 동작</h2><p>Kubespray는 클러스터를 관리하기 위한 추가적인 플레이북, <em>scale</em> 과 <em>upgrade</em> 를 제공한다.</p><h3 id=클러스터-스케일링하기>클러스터 스케일링하기</h3><p>scale 플레이북을 실행해 클러스터에 워커 노드를 추가할 수 있다. 더 자세히 알고 싶다면, "<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#adding-nodes>노드 추가하기</a>" 문서를 확인하자. remove-node 플레이북을 실행하면 클러스터로부터 워커 노드를 제거할 수 있다. 더 알고 싶다면 "<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#remove-nodes>노드 제거하기</a>" 문서를 확인하자.</p><h3 id=클러스터-업그레이드-하기>클러스터 업그레이드 하기</h3><p>upgrade-cluster 플레이북을 실행해 클러스터를 업그레이드 할 수 있다. 더 자세히 알고 싶다면 "<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/upgrades.md>업그레이드</a>" 문서를 확인하자.</p><h2 id=클린업>클린업</h2><p><a href=https://github.com/kubernetes-sigs/kubespray/blob/master/reset.yml>reset 플레이북</a>을 이용하여 노드들을 리셋하고 Kubespray로 설치된 모든 구성요소를 삭제할 수 있다.</p><blockquote class="caution callout"><div><strong>주의:</strong> reset 플레이북을 실행할 때, 실수로 프로덕션 클러스터를 타겟으로 삼지 않도록 해야 한다!</div></blockquote><h2 id=피드백>피드백</h2><ul><li>Slack 채널: <a href=https://kubernetes.slack.com/messages/kubespray/>#kubespray</a> (<a href=https://slack.k8s.io/>이 곳</a>에서 초대를 받을 수 있다)</li><li><a href=https://github.com/kubernetes-sigs/kubespray/issues>GitHub Issues</a></li></ul><h2 id=다음-내용>다음 내용</h2><p>Kubespray의 <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/roadmap.md>로드맵</a>에서 계획중인 작업을 확인해보자.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-acce7e24090fea04715a7a516ba3e69b>3.3 - 쿠버네티스에서 윈도우</h1></div><div class=td-content><h1 id=pg-a307d413f1f7430fced233023087e2a1>3.3.1 - 쿠버네티스의 윈도우 지원 소개</h1><p>윈도우 애플리케이션은 많은 조직에서 실행되는 서비스 및 애플리케이션의 상당 부분을 구성한다. <a href=https://aka.ms/windowscontainers>윈도우 컨테이너</a>는 프로세스와 패키지 종속성을 캡슐화하는 현대적인 방법을 제공하여, 데브옵스(DevOps) 사례를 더욱 쉽게 ​​사용하고 윈도우 애플리케이션의 클라우드 네이티브 패턴을 따르도록 한다. 쿠버네티스는 사실상의 표준 컨테이너 오케스트레이터가 되었으며, 쿠버네티스 1.14 릴리스에는 쿠버네티스 클러스터의 윈도우 노드에서 윈도우 컨테이너 스케줄링을 위한 프로덕션 지원이 포함되어 있어, 광범위한 윈도우 애플리케이션 생태계가 쿠버네티스의 강력한 기능을 활용할 수 있다. 윈도우 기반 애플리케이션과 리눅스 기반 애플리케이션에 투자한 조직은 워크로드를 관리하기 위해 별도의 오케스트레이터를 찾을 필요가 없으므로, 운영 체제와 관계없이 배포 전반에 걸쳐 운영 효율성이 향상된다.</p><h2 id=쿠버네티스의-윈도우-컨테이너>쿠버네티스의 윈도우 컨테이너</h2><p>쿠버네티스에서 윈도우 컨테이너 오케스트레이션을 활성화하려면, 기존 리눅스 클러스터에 윈도우 노드를 포함한다. 쿠버네티스의 <a class=glossary-tooltip title="파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>에서 윈도우 컨테이너를 스케줄링하는 것은 리눅스 기반 컨테이너를 스케줄링하는 것과 유사하다.</p><p>윈도우 컨테이너를 실행하려면, 쿠버네티스 클러스터에 리눅스를 실행하는 컨트롤 플레인 노드와 사용자의 워크로드 요구에 따라 윈도우 또는 리눅스를 실행하는 워커가 있는 여러 운영 체제가 포함되어 있어야 한다. 윈도우 서버 2019는 윈도우에서 <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architecture.md#the-kubernetes-node>쿠버네티스 노드</a>를 활성화하는 유일한 윈도우 운영 체제이다(kubelet, <a href=https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/deploy-containers/containerd>컨테이너 런타임</a> 및 kube-proxy 포함). 윈도우 배포 채널에 대한 자세한 설명은 <a href=https://docs.microsoft.com/ko-kr/windows-server/get-started-19/servicing-channels-19>Microsoft 문서</a>를 참고한다.</p><blockquote class="note callout"><div><strong>참고:</strong> <a href=/ko/docs/concepts/overview/components/>마스터 컴포넌트</a>를 포함한 쿠버네티스 컨트롤 플레인은 리눅스에서 계속 실행된다. 윈도우 전용 쿠버네티스 클러스터는 계획이 없다.</div></blockquote><blockquote class="note callout"><div><strong>참고:</strong> 이 문서에서 윈도우 컨테이너에 대해 이야기할 때 프로세스 격리된 윈도우 컨테이너를 의미한다. <a href=https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/manage-containers/hyperv-container>Hyper-V 격리</a>가 있는 윈도우 컨테이너는 향후 릴리스로 계획되어 있다.</div></blockquote><h2 id=지원되는-기능-및-제한>지원되는 기능 및 제한</h2><h3 id=지원되는-기능>지원되는 기능</h3><h4 id=윈도우-os-버전-지원>윈도우 OS 버전 지원</h4><p>쿠버네티스의 윈도우 운영 체제 지원은 다음 표를 참조한다. 단일 이기종 쿠버네티스 클러스터에는 윈도우 및 리눅스 워커 노드가 모두 있을 수 있다. 윈도우 컨테이너는 윈도우 노드에서, 리눅스 컨테이너는 리눅스 노드에서 스케줄되어야 한다.</p><table><thead><tr><th>쿠버네티스 버전</th><th>윈도우 서버 LTSC 릴리스</th><th>윈도우 서버 SAC 릴리스</th></tr></thead><tbody><tr><td><em>Kubernetes v1.17</em></td><td>Windows Server 2019</td><td>Windows Server ver 1809</td></tr><tr><td><em>Kubernetes v1.18</em></td><td>Windows Server 2019</td><td>Windows Server ver 1809, Windows Server ver 1903, Windows Server ver 1909</td></tr><tr><td><em>Kubernetes v1.19</em></td><td>Windows Server 2019</td><td>Windows Server ver 1909, Windows Server ver 2004</td></tr><tr><td><em>Kubernetes v1.20</em></td><td>Windows Server 2019</td><td>Windows Server ver 1909, Windows Server ver 2004</td></tr></tbody></table><p><blockquote class="note callout"><div><strong>참고:</strong> 지원 모델을 포함한 다양한 윈도우 서버 서비스 채널에 대한 정보는 <a href=https://docs.microsoft.com/ko-kr/windows-server/get-started-19/servicing-channels-19>윈도우 서버 서비스 채널</a>에서 확인할 수 있다.</div></blockquote><blockquote class="note callout"><div><strong>참고:</strong> 모든 윈도우 고객이 앱의 운영 체제를 자주 업데이트하는 것은 아니다. 애플리케이션 업그레이드를 위해서는 클러스터에 새 노드를 업그레이드하거나 도입하는 것이 필요하다. 이 문서에서 쿠버네티스에서 실행되는 컨테이너의 운영 체제를 업그레이드하기로 선택한 고객을 위해 새 운영 체제 버전에 대한 지원을 추가할 때의 가이드와 단계별 지침을 제공한다. 이 가이드에는 클러스터 노드와 함께 사용자 애플리케이션을 업그레이드하기 위한 권장 업그레이드 절차가 포함된다. 윈도우 노드는 현재 리눅스 노드와 동일한 방식으로 쿠버네티스 <a href=/ko/docs/setup/release/version-skew-policy/>버전-스큐(skew) 정책</a>(노드 대 컨트롤 플레인 버전 관리)을 준수한다.</div></blockquote><blockquote class="note callout"><div><strong>참고:</strong> 윈도우 서버 호스트 운영 체제에는 <a href=https://www.microsoft.com/ko-kr/cloud-platform/windows-server-pricing>윈도우 서버</a> 라이선스가 적용된다. 윈도우 컨테이너 이미지에는 <a href=https://docs.microsoft.com/en-us/virtualization/windowscontainers/images-eula>윈도우 컨테이너에 대한 추가 사용 조건</a>이 적용된다.</div></blockquote><blockquote class="note callout"><div><strong>참고:</strong> 프로세스 격리가 포함된 윈도우 컨테이너에는 엄격한 호환성 규칙이 있으며, <a href=https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/deploy-containers/version-compatibility>여기서 호스트 OS 버전은 컨테이너 베이스 이미지 OS 버전과 일치해야 한다</a>. 일단 쿠버네티스에서 Hyper-V 격리가 포함된 윈도우 컨테이너를 지원하면, 제한 및 호환성 규칙이 변경될 것이다.</div></blockquote></p><h4 id=퍼즈-pause-이미지>퍼즈(Pause) 이미지</h4><p>Microsoft는 <code>mcr.microsoft.com/oss/kubernetes/pause:1.4.1</code>에서 윈도우 퍼즈 인프라 컨테이너를 유지한다.</p><h4 id=컴퓨트>컴퓨트</h4><p>API 및 kubectl의 관점에서, 윈도우 컨테이너는 리눅스 기반 컨테이너와 거의 같은 방식으로 작동한다. 그러나 <a href=#%EC%A0%9C%ED%95%9C>제한 섹션</a>에 요약된 주요 기능에는 몇 가지 눈에 띄는 차이점이 있다.</p><p>윈도우에서 주요 쿠버네티스 요소는 리눅스와 동일한 방식으로 작동한다. 이 섹션에서는, 주요 워크로드 인에이블러(enabler) 일부와 이들이 윈도우에 매핑되는 방법에 대해 설명한다.</p><ul><li><p><a href=/ko/docs/concepts/workloads/pods/>파드</a></p><p>파드는 쿠버네티스의 기본 빌딩 블록이다 - 쿠버네티스 오브젝트 모델에서 생성하고 배포하는 가장 작고 간단한 단위. 동일한 파드에 윈도우 및 리눅스 컨테이너를 배포할 수 없다. 파드의 모든 컨테이너는 단일 노드로 스케줄되며 각 노드는 특정 플랫폼 및 아키텍처를 나타낸다. 다음과 같은 파드 기능, 속성 및 이벤트가 윈도우 컨테이너에서 지원된다.</p><ul><li>프로세스 분리 및 볼륨 공유 기능을 갖춘 파드 당 하나 또는 여러 개의 컨테이너</li><li>파드 상태 필드</li><li>준비성(readiness) 및 활성 프로브(liveness probe)</li><li>postStart 및 preStop 컨테이너 라이프사이클 이벤트</li><li>컨피그맵(ConfigMap), 시크릿(Secrets): 환경 변수 또는 볼륨으로</li><li>EmptyDir</li><li>명명된 파이프 호스트 마운트</li><li>리소스 제한</li></ul></li><li><p><a href=/ko/docs/concepts/workloads/controllers/>컨트롤러</a></p><p>쿠버네티스 컨트롤러는 파드의 의도한 상태(desired state)를 처리한다. 윈도우 컨테이너에서 지원되는 워크로드 컨트롤러는 다음과 같다.</p><ul><li>레플리카셋(ReplicaSet)</li><li>레플리케이션컨트롤러(ReplicationController)</li><li>디플로이먼트(Deployment)</li><li>스테이트풀셋(StatefulSet)</li><li>데몬셋(DaemonSet)</li><li>잡(Job)</li><li>크론잡(CronJob)</li></ul></li><li><p><a href=/ko/docs/concepts/services-networking/service/>서비스</a></p><p>쿠버네티스 서비스는 논리적인 파드 집합과 그것에(마이크로 서비스라고도 함) 접근하는 정책을 정의하는 추상화 개념이다. 상호-운영 체제 연결을 위해 서비스를 사용할 수 있다. 윈도우에서 서비스는 다음의 유형, 속성 및 기능을 활용할 수 있다.</p><ul><li>서비스 환경 변수</li><li>노드포트(NodePort)</li><li>클러스터IP(ClusterIP)</li><li>로드밸런서(LoadBalancer)</li><li>ExternalName</li><li>헤드리스 서비스(Headless services)</li></ul></li></ul><p>파드, 컨트롤러 및 서비스는 쿠버네티스에서 윈도우 워크로드를 관리하는데 중요한 요소이다. 그러나 그 자체로는 동적 클라우드 네이티브 환경에서 윈도우 워크로드의 적절한 수명 주기 관리를 수행하기에 충분하지 않다. 다음 기능에 대한 지원이 추가되었다.</p><ul><li>파드와 컨테이너 메트릭</li><li>Horizontal Pod Autoscaler 지원</li><li>kubectl Exec</li><li>리소스쿼터(Resource Quotas)</li><li>스케쥴러 선점(preemption)</li></ul><h4 id=컨테이너-런타임>컨테이너 런타임</h4><h5 id=docker-ee>Docker EE</h5><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Docker EE-basic 19.03 이상은 모든 윈도우 서버 버전에 대해 권장되는 컨테이너 런타임이다. 이것은 kubelet에 포함된 dockershim 코드와 함께 작동한다.</p><h5 id=cri-containerd>CRI-ContainerD</h5><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.20 [stable]</code></div><p><a class=glossary-tooltip title="A container runtime with an emphasis on simplicity, robustness and portability" data-toggle=tooltip data-placement=top href=https://containerd.io/docs/ target=_blank aria-label=ContainerD>ContainerD</a> 1.4.0+는 윈도우 쿠버네티스 노드의 컨테이너 런타임으로도 사용할 수 있다.</p><p><a href=/ko/docs/setup/production-environment/container-runtimes/#containerd-%EC%84%A4%EC%B9%98>윈도우에 ContainerD 설치</a> 방법을 확인한다.</p><blockquote class="caution callout"><div><strong>주의:</strong> ContainerD와 함께 GMSA를 사용하여 커널 패치가 필요한 윈도우 네트워크 공유에 액세스 할 때 <a href=/docs/tasks/configure-pod-container/configure-gmsa/#gmsa-limitations>알려진 제한</a>이 있다. 이 제한을 해결하기위한 업데이트는 현재 Windows Server, 버전 2004에서 사용할 수 있으며 2021년 초에 Windows Server 2019에서 사용할 수 있다. <a href=https://github.com/microsoft/Windows-Containers/issues/44>Microsoft 윈도우 컨테이너 이슈 트래커</a>에서 업데이트를 확인한다.</div></blockquote><h4 id=퍼시스턴트-스토리지-persistent-storage>퍼시스턴트 스토리지(Persistent Storage)</h4><p>쿠버네티스 <a href=/ko/docs/concepts/storage/volumes/>볼륨</a>을 사용하면 데이터 지속성(persistence) 및 파드 볼륨 공유 요구 사항이 있는 복잡한 애플리케이션을 쿠버네티스에 배포할 수 있다. 특정 스토리지 백엔드 또는 프로토콜과 관련된 퍼시스턴트 볼륨 관리에는 볼륨 프로비저닝/디-프로비저닝/크기 조정, 쿠버네티스 노드에 볼륨 연결/분리, 데이터를 유지해야 하는 파드의 개별 컨테이너에 볼륨 마운트/분리와 같은 작업이 포함된다. 특정 스토리지 백엔드 또는 프로토콜에 대해 이러한 볼륨 관리 작업을 구현하는 코드는 쿠버네티스 볼륨 <a href=/ko/docs/concepts/storage/volumes/#%EB%B3%BC%EB%A5%A8-%EC%9C%A0%ED%98%95%EB%93%A4>플러그인</a>의 형태로 제공된다. 다음과 같은 광범위한 쿠버네티스 볼륨 플러그인 클래스가 윈도우에서 지원된다.</p><h5 id=인-트리-in-tree-볼륨-플러그인>인-트리(In-tree) 볼륨 플러그인</h5><p>인-트리 볼륨 플러그인과 관련된 코드는 핵심 쿠버네티스 코드 베이스의 일부로 제공된다. 인-트리 볼륨 플러그인 배포는 추가 스크립트를 설치하거나 별도의 컨테이너화된 플러그인 컴포넌트를 배포할 필요가 없다. 이러한 플러그인들은 볼륨 프로비저닝/디-프로비저닝, 스토리지 백엔드 볼륨 크기 조정, 쿠버네티스 노드에 볼륨 연결/분리, 파드의 개별 컨테이너에 볼륨 마운트/분리를 처리할 수 있다. 다음의 인-트리 플러그인은 윈도우 노드를 지원한다.</p><ul><li><a href=/ko/docs/concepts/storage/volumes/#awselasticblockstore>awsElasticBlockStore</a></li><li><a href=/ko/docs/concepts/storage/volumes/#azuredisk>azureDisk</a></li><li><a href=/ko/docs/concepts/storage/volumes/#azurefile>azureFile</a></li><li><a href=/ko/docs/concepts/storage/volumes/#gcepersistentdisk>gcePersistentDisk</a></li><li><a href=/ko/docs/concepts/storage/volumes/#vspherevolume>vsphereVolume</a></li></ul><h5 id=flexvolume-플러그인>FlexVolume 플러그인</h5><p><a href=/ko/docs/concepts/storage/volumes/#flexVolume>FlexVolume</a> 플러그인과 관련된 코드는 아웃-오브-트리(out-of-tree) 스크립트 또는 호스트에 직접 배포해야 하는 바이너리로 제공된다. FlexVolume 플러그인은 쿠버네티스 노드에 볼륨 연결/분리 및 파드의 개별 컨테이너에 볼륨 마운트/분리를 처리한다. FlexVolume 플러그인과 관련된 퍼시스턴트 볼륨의 프로비저닝/디-프로비저닝은 일반적으로 FlexVolume 플러그인과는 별도의 외부 프로비저너를 통해 처리될 수 있다. 호스트에서 powershell 스크립트로 배포된 다음의 FlexVolume <a href=https://github.com/Microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows>플러그인</a>은 윈도우 노드를 지원한다.</p><ul><li><a href=https://github.com/microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows/plugins/microsoft.com~smb.cmd>SMB</a></li><li><a href=https://github.com/microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows/plugins/microsoft.com~iscsi.cmd>iSCSI</a></li></ul><h5 id=csi-플러그인>CSI 플러그인</h5><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code></div><p><a class=glossary-tooltip title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> 플러그인과 관련된 코드는 일반적으로 컨테이너 이미지로 배포되고 데몬셋(DaemonSets) 및 스테이트풀셋(StatefulSets)과 같은 표준 쿠버네티스 구성을 사용하여 배포되는 아웃-오브-트리 스크립트 및 바이너리로 제공된다. CSI 플러그인은 쿠버네티스에서 볼륨 프로비저닝/디-프로비저닝, 볼륨 크기 조정, 쿠버네티스 노드에 볼륨 연결/분리, 파드의 개별 컨테이너에 볼륨 마운트/분리, 스냅샷 및 복제를 사용하여 퍼시스턴트 데이터 백업/복원과 같은 다양한 볼륨 관리 작업을 처리한다. CSI 플러그인은 일반적으로 (각 노드에서 데몬셋으로 실행되는) 노드 플러그인과 컨트롤러 플러그인으로 구성된다.</p><p>CSI 노드 플러그인(특히 블록 디바이스 또는 공유 파일시스템으로 노출된 퍼시스턴트 볼륨과 관련된 플러그인)은 디스크 장치 스캔, 파일 시스템 마운트 등과 같은 다양한 특권이 필요한(privileged) 작업을 수행해야 한다. 이러한 작업은 호스트 운영 체제마다 다르다. 리눅스 워커 노드의 경우 컨테이너화된 CSI 노드 플러그인은 일반적으로 특권을 가진 컨테이너로 배포된다. 윈도우 워커 노드의 경우 컨테이너화된 CSI 노드 플러그인에 대한 특권이 필요한 작업은 커뮤니티에서 관리되고, 각 윈도우 노드에 사전 설치되어야 하는 독립형(stand-alone) 바이너리인 <a href=https://github.com/kubernetes-csi/csi-proxy>csi-proxy</a>를 사용하여 지원된다. 자세한 내용은 배포하려는 CSI 플러그인의 배포 가이드를 참조한다.</p><h4 id=네트워킹>네트워킹</h4><p>윈도우 컨테이너용 네트워킹은 <a href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/>CNI 플러그인</a>을 통해 노출된다. 윈도우 컨테이너는 네트워킹과 관련하여 가상 머신과 유사하게 작동한다. 각 컨테이너에는 Hyper-V 가상 스위치(vSwitch)에 연결된 가상 네트워크 어댑터(vNIC)가 있다. 호스트 네트워킹 서비스(HNS)와 호스트 컴퓨팅 서비스(HCS)는 함께 작동하여 컨테이너를 만들고 컨테이너 vNIC을 네트워크에 연결한다. HCS는 컨테이너 관리를 담당하는 반면 HNS는 다음과 같은 네트워킹 리소스 관리를 담당한다.</p><ul><li>가상 네트워크(vSwitch 생성 포함)</li><li>엔드포인트 / vNIC</li><li>네임스페이스</li><li>정책(패킷 캡슐화, 로드 밸런싱 규칙, ACL, NAT 규칙 등)</li></ul><p>다음의 서비스 사양 유형이 지원된다.</p><ul><li>NodePort</li><li>ClusterIP</li><li>LoadBalancer</li><li>ExternalName</li></ul><h5 id=네트워크-모드>네트워크 모드</h5><p>윈도우는 L2bridge, L2tunnel, Overlay, Transparent 및 NAT의 다섯 가지 네트워킹 드라이버/모드를 지원한다. 윈도우와 리눅스 워커 노드가 있는 이기종 클러스터에서는 윈도우와 리눅스 모두에서 호환되는 네트워킹 솔루션을 선택해야 한다. 윈도우에서 다음과 같은 out-of-tree 플러그인이 지원되며 각 CNI 사용 시 권장 사항이 있다.</p><table><thead><tr><th>네트워크 드라이버</th><th>설명</th><th>컨테이너 패킷 수정</th><th>네트워크 플러그인</th><th>네트워크 플러그인 특성</th></tr></thead><tbody><tr><td>L2bridge</td><td>컨테이너는 외부 vSwitch에 연결된다. 컨테이너는 언더레이 네트워크에 연결된다. 하지만 인그레스/이그레스시에 재작성되기 때문에 물리적 네트워크가 컨테이너 MAC을 학습할 필요가 없다.</td><td>MAC은 호스트 MAC에 다시 쓰여지고, IP는 HNS OutboundNAT 정책을 사용하여 호스트 IP에 다시 쓰여질 수 있다.</td><td><a href=https://github.com/containernetworking/plugins/tree/master/plugins/main/windows/win-bridge>win-bridge</a>, <a href=https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md>Azure-CNI</a>, Flannel 호스트 게이트웨이는 win-bridge를 사용한다.</td><td>win-bridge는 L2bridge 네트워크 모드를 사용하고, 컨테이너를 호스트의 언더레이에 연결하여 최상의 성능을 제공한다. 노드 간 연결을 위해 사용자 정의 경로(user-defined routes, UDR)가 필요하다.</td></tr><tr><td>L2Tunnel</td><td>이것은 l2bridge의 특별한 케이스이지만 Azure에서만 사용된다. 모든 패킷은 SDN 정책이 적용되는 가상화 호스트로 전송된다.</td><td>MAC 재작성되고, 언더레이 네트워크 상에서 IP가 보인다.</td><td><a href=https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md>Azure-CNI</a></td><td>Azure-CNI를 사용하면 컨테이너를 Azure vNET과 통합할 수 있으며, <a href=https://azure.microsoft.com/ko-kr/services/virtual-network/>Azure Virtual Network에서 제공하는</a> 기능 집합을 활용할 수 있다. 예를 들어 Azure 서비스에 안전하게 연결하거나 Azure NSG를 사용한다. <a href=https://docs.microsoft.com/ko-kr/azure/aks/concepts-network#azure-cni-advanced-networking>azure-cni 예제</a>를 참고한다.</td></tr><tr><td>오버레이(쿠버네티스에서 윈도우용 오버레이 네트워킹은 <em>알파</em> 단계에 있음)</td><td>컨테이너에는 외부 vSwitch에 연결된 vNIC이 제공된다. 각 오버레이 네트워크는 사용자 지정 IP 접두사로 정의된 자체 IP 서브넷을 가져온다. 오버레이 네트워크 드라이버는 VXLAN 캡슐화를 사용한다.</td><td>외부 헤더로 캡슐화된다.</td><td><a href=https://github.com/containernetworking/plugins/tree/master/plugins/main/windows/win-overlay>Win-overlay</a>, Flannel VXLAN(win-overlay 사용)</td><td>win-overlay는 가상 컨테이너 네트워크를 호스트의 언더레이에서 격리하려는 경우(예: 보안 상의 이유로) 사용해야 한다. 데이터 센터의 IP에 제한이 있는 경우, (다른 VNID 태그가 있는) 다른 오버레이 네트워크에 IP를 재사용할 수 있다. 이 옵션을 사용하려면 윈도우 서버 2019에서 <a href=https://support.microsoft.com/help/4489899>KB4489899</a>가 필요하다.</td></tr><tr><td>Transparent(<a href=https://github.com/openvswitch/ovn-kubernetes>ovn-kubernetes</a>의 특수한 유스케이스)</td><td>외부 vSwitch가 필요하다. 컨테이너는 논리적 네트워크(논리적 스위치 및 라우터)를 통해 파드 내 통신을 가능하게 하는 외부 vSwitch에 연결된다.</td><td>패킷은 <a href=https://datatracker.ietf.org/doc/draft-gross-geneve/>GENEVE</a> 또는 <a href=https://datatracker.ietf.org/doc/draft-davie-stt>STT</a>를 통해 캡슐화되는데, 동일한 호스트에 있지 않은 파드에 도달하기 위한 터널링을 한다.<br>패킷은 ovn 네트워크 컨트롤러에서 제공하는 터널 메타데이터 정보를 통해 전달되거나 삭제된다.<br>NAT는 north-south 통신(데이터 센터와 클라이언트, 네트워크 상의 데이터 센터 외부와의 통신)을 위해 수행된다.</td><td><a href=https://github.com/openvswitch/ovn-kubernetes>ovn-kubernetes</a></td><td><a href=https://github.com/openvswitch/ovn-kubernetes/tree/master/contrib>ansible을 통해 배포</a>한다. 분산 ACL은 쿠버네티스 정책을 통해 적용할 수 있다. IPAM을 지원한다. kube-proxy 없이 로드 밸런싱을 수행할 수 있다. NAT를 수행할 때 iptables/netsh를 사용하지 않고 수행된다.</td></tr><tr><td>NAT(<em>쿠버네티스에서 사용되지 않음</em>)</td><td>컨테이너에는 내부 vSwitch에 연결된 vNIC이 제공된다. DNS/DHCP는 <a href=https://blogs.technet.microsoft.com/virtualization/2016/05/25/windows-nat-winnat-capabilities-and-limitations/>WinNAT</a>라는 내부 컴포넌트를 사용하여 제공된다.</td><td>MAC 및 IP는 호스트 MAC/IP에 다시 작성된다.</td><td><a href=https://github.com/Microsoft/windows-container-networking/tree/master/plugins/nat>nat</a></td><td>완전성을 위해 여기에 포함되었다.</td></tr></tbody></table><p>위에서 설명한대로 <a href=https://github.com/coreos/flannel>플란넬(Flannel)</a> CNI <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel>메타 플러그인</a>은 <a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>VXLAN 네트워크 백엔드</a>(<strong>alpha 지원</strong>, win-overlay에 위임) 및 <a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#host-gw>host-gateway network backend</a> (안정적인 지원, win-bridge에 위임)를 통해 <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel#windows-support-experimental>윈도우</a>에서도 지원된다. 이 플러그인은 자동 노드 서브넷 임대 할당과 HNS 네트워크 생성을 위해 윈도우 (Flanneld)에서 Flannel 데몬과 함께 작동하도록 참조 CNI 플러그인 (win-overlay, win-bridge) 중 하나에 대한 위임을 지원한다. 이 플러그인은 자체 구성 파일 (cni.conf)을 읽고, 이를 FlannelD 생성하는 subnet.env 파일의 환경 변수와 함께 집계한다. 이후 네트워크 연결을 위한 참조 CNI 플러그인 중 하나에 위임하고 노드 할당 서브넷을 포함하는 올바른 구성을 IPAM 플러그인 (예: 호스트-로컬)으로 보낸다.</p><p>노드, 파드, 서비스 오브젝트의 경우 TCP/UDP 트래픽에 대해 다음 네트워크 흐름이 지원된다.</p><ul><li>파드 -> 파드(IP)</li><li>파드 -> 파드(Name)</li><li>파드 -> 서비스(Cluster IP)</li><li>파드 -> 서비스(PQDN, 단 "."이 없는 경우에만)</li><li>파드 -> 서비스(FQDN)</li><li>파드 -> External(IP)</li><li>파드 -> External(DNS)</li><li>노드 -> 파드</li><li>파드 -> 노드</li></ul><h5 id=ip-주소-관리-ipam>IP 주소 관리(IPAM)</h5><p>윈도우에서는 다음 IPAM 옵션이 지원된다.</p><ul><li><a href=https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local>호스트-로컬</a></li><li>HNS IPAM(Inbox 플랫폼 IPAM, 이것은 IPAM이 설정되지 않은 경우 폴백(fallback)이다)</li><li><a href=https://github.com/Azure/azure-container-networking/blob/master/docs/ipam.md>Azure-vnet-ipam</a>(azure-cni 전용)</li></ul><h5 id=로드-밸런싱과-서비스>로드 밸런싱과 서비스</h5><p>윈도우에서는 다음 설정을 사용하여 서비스 및 로드 밸런싱 동작을 구성할 수 있다.</p><table><caption style=display:none>윈도우 서비스 구성</caption><thead><tr><th>기능</th><th>설명</th><th>지원되는 쿠버네티스 버전</th><th>지원되는 윈도우 OS 빌드</th><th>활성화하는 방법</th></tr></thead><tbody><tr><td>세션 어피니티</td><td>특정 클라이언트의 연결이 매번 동일한 파드로 전달되도록 한다.</td><td>v1.19 이상</td><td><a href=https://blogs.windows.com/windowsexperience/2020/01/28/announcing-windows-server-vnext-insider-preview-build-19551/>윈도우 서버 vNext Insider Preview Build 19551</a> 이상</td><td><code>service.spec.sessionAffinity</code>를 "ClientIP"로 설정</td></tr><tr><td>직접 서버 반환</td><td>IP 주소 수정 및 LBNAT가 컨테이너 vSwitch 포트에서 직접 발생하는 로드 밸런싱 모드. 서비스 트래픽은 소스 IP가 원래 파드 IP로 설정된 상태로 도착한다. 낮은 지연 시간과 확장성을 약속한다.</td><td>v1.15 이상</td><td>윈도우 서버, 버전 2004</td><td>kube-proxy에서 다음 플래그를 설정한다. <code>--feature-gates="WinDSR=true" --enable-dsr=true</code></td></tr><tr><td>대상 보존(Preserve-Destination)</td><td>서비스 트래픽의 DNAT를 스킵하여, 백엔드 파드에 도달하는 패킷에서 대상 서비스의 가상 IP를 보존한다. 이 설정은 또한 수신 패킷의 클라이언트 IP가 보존되도록 한다.</td><td>v1.15 이상</td><td>윈도우 서버, 버전 1903 (이상)</td><td>서비스 어느테이션에서 <code>"preserve-destination": "true"</code>를 설정하고 kube-proxy에서 DSR 플래그를 활성화한다.</td></tr><tr><td>IPv4/IPv6 이중 스택 네트워킹</td><td>클러스터 내/외부 기본 IPv4-to-IPv4 통신과 함께 IPv6-to-IPv6 통신</td><td>v1.19 이상</td><td>윈도우 서버 vNext Insider Preview Build 19603(또는 그 이상)</td><td><a href=#ipv4ipv6-%EC%9D%B4%EC%A4%91-%EC%8A%A4%ED%83%9D>IPv4/IPv6 이중 스택</a>을 참고한다.</td></tr></tbody></table><h4 id=ipv4-ipv6-이중-스택>IPv4/IPv6 이중 스택</h4><p><code>IPv6DualStack</code> <a href=/ko/docs/reference/command-line-tools-reference/feature-gates/>기능 게이트</a>를 사용하여 <code>l2bridge</code> 네트워크에 IPv4/IPv6 이중 스택 네트워킹을 활성화할 수 있다. 자세한 내용은 <a href=/ko/docs/concepts/services-networking/dual-stack/#ipv4-ipv6-%EC%9D%B4%EC%A4%91-%EC%8A%A4%ED%83%9D-%ED%99%9C%EC%84%B1%ED%99%94>IPv4/IPv6 이중 스택 활성화</a>를 참조한다.</p><blockquote class="note callout"><div><strong>참고:</strong> 윈도우에서 쿠버네티스와 함께 IPv6를 사용하려면 윈도우 서버 버전 2004 (커널 버전 10.0.19041.610) 이상이 필요하다.</div></blockquote><blockquote class="note callout"><div><strong>참고:</strong> 윈도우의 오버레이(VXLAN) 네트워크는 현재 이중 스택 네트워킹을 지원하지 않는다.</div></blockquote><h3 id=제한>제한</h3><p>윈도우는 쿠버네티스 아키텍처 및 컴포넌트 매트릭스에서 워커 노드로만 지원된다. 즉, 쿠버네티스 클러스터에는 항상 리눅스 마스터 노드가 반드시 포함되어야 하고, 0개 이상의 리눅스 워커 노드 및 0개 이상의 윈도우 워커 노드가 포함된다.</p><h4 id=자원-관리>자원 관리</h4><p>리눅스 cgroup은 리눅스에서 리소스 제어를 위한 파드 경계로 사용된다. 컨테이너는 네트워크, 프로세스 및 파일시스템 격리를 위해 해당 경계 내에 생성된다. cgroups API는 cpu/io/memory 통계를 수집하는 데 사용할 수 있다. 반대로 윈도우는 시스템 네임스페이스 필터가 있는 컨테이너별로 잡(Job) 오브젝트를 사용하여 컨테이너의 모든 프로세스를 포함하고 호스트와의 논리적 격리를 제공한다. 네임스페이스 필터링 없이 윈도우 컨테이너를 실행할 수 있는 방법은 없다. 즉, 시스템 권한은 호스트 컨텍스트에서 삽입 될(assert) 수 없으므로 권한이 있는(privileged) 컨테이너는 윈도우에서 사용할 수 없다. 보안 계정 매니져(Security Account Manager, SAM)가 분리되어 있으므로 컨테이너는 호스트의 ID를 가정할 수 없다.</p><h4 id=자원-예약>자원 예약</h4><h5 id=메모리-예약>메모리 예약</h5><p>윈도우에는 리눅스에는 있는 메모리 부족 프로세스 킬러가 없다. 윈도우는 모든 사용자-모드 메모리 할당을 항상 가상 메모리처럼 처리하며, 페이지파일이 필수이다. 결과적으로 윈도우에서는 리눅스에서 발생할 수 있는 메모리 부족 상태에 도달하지 않으며, 프로세스는 메모리 부족 (out of memory, OOM) 종료를 겪는 대신 디스크로 페이징한다. 메모리가 오버프로비저닝되고 모든 물리 메모리가 고갈되면 페이징으로 인해 성능이 저하될 수 있다.</p><p>kubelet 파라미터 <code>--kubelet-reserve</code> 를 사용하여 메모리 사용량을 합리적인 범위 내로 유지할 수 있으며, <code>--system-reserve</code> 를 사용하여 노드(컨테이너 외부)의 메모리 사용량을 예약할 수 있다. 이들을 사용하면 그만큼 <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>노드 할당(NodeAllocatable)</a>은 줄어든다.</p><blockquote class="note callout"><div><strong>참고:</strong> 워크로드를 배포할 때, 컨테이너에 리소스 제한을 사용한다 (제한만 설정하거나, 제한이 요청과 같아야 함). 이 또한 NodeAllocatable에서 차감되며, 메모리가 꽉 찬 노드에 스케줄러가 파드를 할당하지 않도록 제한한다.</div></blockquote><p>오버프로비저닝을 방지하는 가장 좋은 방법은 윈도우, 도커, 그리고 쿠버네티스 프로세스를 위해 최소 2GB 이상의 시스템 예약 메모리로 kubelet을 설정하는 것이다.</p><h5 id=cpu-예약>CPU 예약</h5><p>윈도우, 도커, 그리고 다른 쿠버네티스 호스트 프로세스가 이벤트에 잘 응답할 수 있도록, CPU의 일정 비율을 예약하는 것이 좋다. 이 값은 윈도우 노드에 있는 CPU 코어 수에 따라 조정해야 한다. 이 비율을 결정하려면, 각 노드의 최대 파드 밀도(density)를 관찰하고, 시스템 서비스의 CPU 사용량을 모니터링하여 워크로드 요구 사항을 충족하는 값을 선택해야 한다.</p><p>kubelet 파라미터 <code>--kubelet-reserve</code> 를 사용하여 CPU 사용량을 합리적인 범위 내로 유지할 수 있으며, <code>--system-reserve</code> 를 사용하여 노드(컨테이너 외부)의 CPU 사용량을 예약할 수 있다. 이들을 사용하면 그만큼 <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>노드 할당(NodeAllocatable)</a>은 줄어든다.</p><h4 id=기능-제한>기능 제한</h4><ul><li>TerminationGracePeriod: 구현되지 않음</li><li>단일 파일 매핑: CRI-ContainerD로 구현 예정</li><li>종료 메시지: CRI-ContainerD로 구현 예정</li><li>특권을 가진(Privileged) 컨테이너: 현재 윈도우 컨테이너에서 지원되지 않음</li><li>HugePages: 현재 윈도우 컨테이너에서 지원되지 않음</li><li>기존 노드 문제 감지기는 리눅스 전용이며 특권을 가진 컨테이너가 필요하다. 윈도우에서 특권을 가진 컨테이너를 지원하지 않기 때문에 일반적으로 윈도우에서 이 기능이 사용될 것으로 예상하지 않는다.</li><li>공유 네임스페이스의 모든 기능이 지원되는 것은 아니다. (자세한 내용은 API 섹션 참조).</li></ul><h4 id=각-플래그의-리눅스와의-차이점>각 플래그의 리눅스와의 차이점</h4><p>윈도우 노드에서의 kubelet 플래그는 아래와 같이 다르게 동작한다.</p><ul><li><code>--kubelet-reserve</code>, <code>--system-reserve</code>, <code>--eviction-hard</code> 플래그는 Node Allocatable 업데이트</li><li><code>--enforce-node-allocable</code>을 사용한 축출(Eviction)은 구현되지 않았다.</li><li><code>--eviction-hard</code>와 <code>--eviction-soft</code>를 사용한 축출은 구현되지 않았다.</li><li>MemoryPressure 조건은 구현되지 않았다.</li><li>kubelet이 취한 OOM 축출 조치가 없다.</li><li>윈도우 노드에서 실행되는 Kubelet에는 메모리 제한이 없다. <code>--kubelet-reserve</code>와 <code>--system-reserve</code>는 호스트에서 실행되는 kubelet 또는 프로세스에 제한을 설정하지 않는다. 이는 호스트의 kubelet 또는 프로세스가 node-allocatable 및 스케줄러 외부에서 메모리 리소스 부족을 유발할 수 있음을 의미한다.</li><li>kubelet 프로세스의 우선 순위를 설정하는 추가 플래그는 <code>--windows-priorityclass</code>라는 윈도우 노드에서 사용할 수 있다. 이 플래그를 사용하면 kubelet 프로세스가 윈도우 호스트에서 실행중인 다른 프로세스와 비교할 때 더 많은 CPU 시간 슬라이스을 얻을 수 있다. 허용되는 값과 그 의미에 대한 자세한 내용은 <a href=https://docs.microsoft.com/en-us/windows/win32/procthread/scheduling-priorities#priority-class>윈도우 우선순위 클래스</a>에서 확인할 수 있다. kubelet이 항상 충분한 CPU주기를 갖도록 하려면 이 플래그를 <code>ABOVE_NORMAL_PRIORITY_CLASS</code> 이상으로 설정하는 것이 좋다.</li></ul><h4 id=스토리지>스토리지</h4><p>윈도우에는 컨테이너 계층을 마운트하고 NTFS를 기반으로 하는 복제 파일시스템을 만드는 레이어드(layered) 파일시스템 드라이버가 있다. 컨테이너의 모든 파일 경로는 해당 컨테이너의 컨텍스트 내에서만 확인된다.</p><ul><li>도커 볼륨 마운트는 개별 파일이 아닌 컨테이너의 디렉토리 만 대상으로 할 수 있다. 이 제한은 CRI-containerD에는 존재하지 않는다.</li><li>볼륨 마운트는 파일이나 디렉터리를 호스트 파일시스템으로 다시 투영할 수 없다.</li><li>읽기 전용 파일시스템은 윈도우 레지스트리 및 SAM 데이터베이스에 항상 쓰기 접근이 필요하기 때문에 지원되지 않는다. 그러나 읽기 전용 볼륨은 지원된다.</li><li>볼륨 사용자 마스크(user-masks) 및 권한은 사용할 수 없다. SAM은 호스트와 컨테이너 간에 공유되지 않기 때문에 이들 간에 매핑이 없다. 모든 권한은 컨테이너 컨텍스트 내에서 해결된다.</li></ul><p>결과적으로, 다음 스토리지 기능은 윈도우 노드에서 지원되지 않는다.</p><ul><li>볼륨 하위 경로(subpath) 마운트. 전체 볼륨만 윈도우 컨테이너에 마운트할 수 있다.</li><li>시크릿에 대한 하위 경로 볼륨 마운트</li><li>호스트 마운트 프로젝션</li><li>DefaultMode(UID/GID 종속성에 기인함)</li><li>읽기 전용 루트 파일시스템. 매핑된 볼륨은 여전히 ​​읽기 전용을 지원한다.</li><li>블록 디바이스 매핑</li><li>저장 매체로서의 메모리</li><li>uui/guid, 사용자별 리눅스 파일시스템 권한과 같은 파일시스템 기능</li><li>NFS 기반 스토리지/볼륨 지원</li><li>마운트된 볼륨 확장(resizefs)</li></ul><h4 id=네트워킹-제한>네트워킹</h4><p>윈도우 컨테이너 네트워킹은 리눅스 네트워킹과 몇 가지 중요한 면에서 다르다. <a href=https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/container-networking/architecture>윈도우 컨테이너 네트워킹에 대한 Microsoft 문서</a>에는 추가 세부 정보와 배경이 포함되어 있다.</p><p>윈도우 호스트 네트워킹 서비스와 가상 스위치는 네임스페이스를 구현하고 파드 또는 컨테이너에 필요한 가상 NIC을 만들 수 있다. 그러나 DNS, 라우트, 메트릭과 같은 많은 구성은 리눅스에서와 같이 /etc/... 파일이 아닌 윈도우 레지스트리 데이터베이스에 저장된다. 컨테이너의 윈도우 레지스트리는 호스트 레지스트리와 별개이므로 호스트에서 컨테이너로 /etc/resolv.conf를 매핑하는 것과 같은 개념은 리눅스에서와 동일한 효과를 갖지 않는다. 해당 컨테이너의 컨텍스트에서 실행되는 윈도우 API를 사용하여 구성해야 한다. 따라서 CNI 구현에서는 파일 매핑에 의존하는 대신 HNS를 호출하여 네트워크 세부 정보를 파드 또는 컨테이너로 전달해야 한다.</p><p>다음 네트워킹 기능은 윈도우 노드에서 지원되지 않는다.</p><ul><li>윈도우 파드에서는 호스트 네트워킹 모드를 사용할 수 없다.</li><li>노드 자체에서 로컬 NodePort 접근은 실패한다. (다른 노드 또는 외부 클라이언트에서는 가능)</li><li>노드에서 서비스 VIP에 접근하는 것은 향후 윈도우 서버 릴리스에서 사용할 수 있다.</li><li>한 서비스는 최대 64개의 백엔드 파드 또는 고유한 목적지 IP를 지원할 수 있다.</li><li>kube-proxy의 오버레이 네트워킹 지원은 알파 릴리스이다. 또한 윈도우 서버 2019에 <a href=https://support.microsoft.com/ko-kr/help/4482887/windows-10-update-kb4482887>KB4482887</a>을 설치해야 한다.</li><li>로컬 트래픽 정책 및 DSR 모드</li><li>l2bridge, l2tunnel 또는 오버레이 네트워크에 연결된 윈도우 컨테이너는 IPv6 스택을 통한 통신을 지원하지 않는다. 이러한 네트워크 드라이버가 IPv6 주소를 사용하고 kubelet, kube-proxy 및 CNI 플러그인에서 후속 쿠버네티스 작업을 사용할 수 있도록 하는데 필요한 뛰어난 윈도우 플랫폼 작업이 있다.</li><li>win-overlay, win-bridge, Azure-CNI 플러그인을 통해 ICMP 프로토콜을 사용하는 아웃바운드 통신. 특히, 윈도우 데이터 플레인(<a href=https://www.microsoft.com/en-us/research/project/azure-virtual-filtering-platform/>VFP</a>)은 ICMP 패킷 치환을 지원하지 않는다. 이것은 다음을 의미한다.<ul><li>동일한 네트워크(예: ping을 통한 파드 간 통신) 내의 목적지로 전달되는 ICMP 패킷은 예상대로 제한 없이 작동한다.</li><li>TCP/UDP 패킷은 예상대로 제한 없이 작동한다.</li><li>원격 네트워크를 통과하도록 지정된 ICMP 패킷(예: ping을 통한 파드에서 외부 인터넷으로의 통신)은 치환될 수 없으므로 소스로 다시 라우팅되지 않는다.</li><li>TCP/UDP 패킷은 여전히 ​​치환될 수 있기 때문에 <code>ping &lt;destination></code>을 <code>curl &lt;destination></code>으로 대체하여 외부와의 연결을 디버깅할 수 있다.</li></ul></li></ul><p>해당 기능은 쿠버네티스 v1.15에 추가되었다.</p><ul><li><code>kubectl port-forward</code></li></ul><h5 id=cni-플러그인>CNI 플러그인</h5><ul><li>윈도우 참조 네트워크 플러그인 win-bridge와 win-overlay는 현재 "CHECK" 구현 누락으로 인해 <a href=https://github.com/containernetworking/cni/blob/master/SPEC.md>CNI 사양</a> v0.4.0을 구현하지 않는다.</li><li>Flannel VXLAN CNI는 윈도우에서 다음과 같은 제한이 있다.</li></ul><ol><li>노드-파드 연결은 설계상 불가능하다. Flannel v0.12.0(또는 그 이상)이 있는 로컬 파드에서만 가능하다.</li><li>VNI 4096와 UDP 4789 포트 사용은 제한된다. VNI 제한은 작업 중이며 향후 릴리스(오픈 소스 flannel 변경)에서 구현될 것이다. 이러한 파라미터에 대한 자세한 내용은 공식 <a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>Flannel VXLAN</a> 백엔드 문서를 참고한다.</li></ol><h5 id=dns-limitations>DNS</h5><ul><li>ClusterFirstWithHostNet은 DNS에서 지원되지 않는다. 윈도우는 '.'이 있는 모든 이름을 FQDN으로 처리하고 PQDN 확인을 건너뛴다.</li><li>리눅스에서는 PQDN을 확인하려고 할 때 사용되는 DNS 접미사 목록이 있다. 윈도우에서는 해당 파드의 네임스페이스(예: mydns.svc.cluster.local)와 연결된 DNS 접미사인 DNS 접미사 1개만 있다. 윈도우는 FQDN과 서비스 또는 해당 접미사만으로 확인할 수 있는 이름을 확인할 수 있다. 예를 들어, 디폴트 네임스페이스에서 생성된 파드에는 DNS 접미사 <strong>default.svc.cluster.local</strong>이 있다. 윈도우 파드에서는 <strong>kubernetes.default.svc.cluster.local</strong> 및 <strong>kubernetes</strong>를 모두 확인할 수 있지만 <strong>kubernetes.default</strong> 또는 <strong>kubernetes.default.svc</strong>와 같은 중간 항목은 확인할 수 없다.</li><li>윈도우에서는 사용할 수 있는 여러 가지의 DNS 리졸버(resolver)가 있다. 이들은 약간 다른 동작을 제공하므로, 이름 쿼리 확인을 위해 <code>Resolve-DNSName</code> 유틸리티를 사용하는 것이 좋다.</li></ul><h5 id=ipv6>IPv6</h5><p>윈도우의 쿠버네티스는 단일 스택 "IPv6 전용" 네트워킹을 지원하지 않는다. 그러나 단일 제품군 서비스를 사용하는 파드와 노드에 대한 이중 스택 IPv4/IPv6 네트워킹이 지원된다. 자세한 내용은 <a href=#ipv4ipv6-%EC%9D%B4%EC%A4%91-%EC%8A%A4%ED%83%9D>IPv4/IPv6 이중 스택 네트워킹</a>을 참고한다.</p><h5 id=세션-어피니티-affinity>세션 어피니티(affinity)</h5><p><code>service.spec.sessionAffinityConfig.clientIP.timeoutSeconds</code>를 사용하는 윈도우 서비스의 최대 세션 고정(sticky) 시간 설정은 지원되지 않는다.</p><h5 id=보안>보안</h5><p>시크릿(Secret)은 노드의 볼륨(리눅스의 tmpfs/in-memory와 비교)에 일반 텍스트로 작성된다. 이는 고객이 두 가지 작업을 수행해야 함을 의미한다.</p><ol><li>파일 ACL을 사용하여 시크릿 파일 위치를 보호한다.</li><li><a href=https://docs.microsoft.com/ko-kr/windows/security/information-protection/bitlocker/bitlocker-how-to-deploy-on-windows-server>BitLocker</a>를 사용한 볼륨-레벨 암호화를 사용한다.</li></ol><p><a href=/ko/docs/tasks/configure-pod-container/configure-runasusername>RunAsUsername</a>은 컨테이너 프로세스를 노드 기본 사용자로 실행하기 위해 윈도우 파드 또는 컨테이너에 지정할 수 있다. 이것은 <a href=/ko/docs/concepts/policy/pod-security-policy/#%EC%82%AC%EC%9A%A9%EC%9E%90-%EB%B0%8F-%EA%B7%B8%EB%A3%B9>RunAsUser</a>와 거의 동일하다.</p><p>SELinux, AppArmor, Seccomp, 기능(POSIX 기능)과 같은 리눅스 특유의 파드 시큐리티 컨텍스트 권한은 지원하지 않는다.</p><p>또한 이미 언급했듯이 특권을 가진 컨테이너는 윈도우에서 지원되지 않는다.</p><h4 id=api>API</h4><p>대부분의 Kubernetes API가 윈도우에서 작동하는 방식은 차이가 없다. 중요한 차이점은 OS와 컨테이너 런타임의 차이로 귀결된다. 특정 상황에서 파드 또는 컨테이너와 같은 워크로드 API의 일부 속성은 리눅스에서 구현되고 윈도우에서 실행되지 않는다는 가정 하에 설계되었다.</p><p>높은 수준에서 이러한 OS 개념은 다르다.</p><ul><li>ID - 리눅스는 정수형으로 표시되는 userID(UID) 및 groupID(GID)를 사용한다. 사용자와 그룹 이름은 정식 이름이 아니다. UID+GID에 대한 <code>/etc/groups</code> 또는 <code>/etc/passwd</code>의 별칭일 뿐이다. 윈도우는 윈도우 보안 계정 관리자(Security Account Manager, SAM) 데이터베이스에 저장된 더 큰 이진 보안 식별자(SID)를 사용한다. 이 데이터베이스는 호스트와 컨테이너 간에 또는 컨테이너들 간에 공유되지 않는다.</li><li>파일 퍼미션 - 윈도우는 권한 및 UUID+GID의 비트 마스크(bitmask) 대신 SID를 기반으로 하는 접근 제어 목록을 사용한다.</li><li>파일 경로 - 윈도우의 규칙은 <code>/</code> 대신 <code>\</code>를 사용하는 것이다. Go IO 라이브러리는 두 가지 파일 경로 분리자를 모두 허용한다. 하지만, 컨테이너 내부에서 해석되는 경로 또는 커맨드 라인을 설정할 때 <code>\</code>가 필요할 수 있다.</li><li>신호(Signals) - 윈도우 대화형(interactive) 앱은 종료를 다르게 처리하며, 다음 중 하나 이상을 구현할 수 있다.<ul><li>UI 스레드는 WM_CLOSE를 포함하여 잘 정의된(well-defined) 메시지를 처리한다.</li><li>콘솔 앱은 컨트롤 핸들러(Control Handler)를 사용하여 ctrl-c 또는 ctrl-break를 처리한다.</li><li>서비스는 SERVICE_CONTROL_STOP 제어 코드를 수용할 수 있는 Service Control Handler 함수를 등록한다.</li></ul></li></ul><p>종료 코드는 0일 때 성공, 0이 아닌 경우 실패인 동일한 규칙을 따른다. 특정 오류 코드는 윈도우와 리눅스에서 다를 수 있다. 그러나 쿠버네티스 컴포넌트(kubelet, kube-proxy)에서 전달된 종료 코드는 변경되지 않는다.</p><h5 id=v1-container>V1.Container</h5><ul><li>V1.Container.ResourceRequirements.limits.cpu 및 V1.Container.ResourceRequirements.limits.memory - 윈도우는 CPU 할당에 하드 리밋(hard limit)을 사용하지 않는다. 대신 공유 시스템이 사용된다. 밀리코어를 기반으로 하는 기존 필드는 윈도우 스케줄러가 뒤따르는 상대적인 공유로 스케일된다. <a href=https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/helpers_windows.go>참고: kuberuntime/helpers_windows.go</a>, <a href=https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/manage-containers/resource-controls>참고: Microsoft 문서 내 리소스 제어</a><ul><li>Huge page는 윈도우 컨테이너 런타임에서 구현되지 않으며, 사용할 수 없다. 컨테이너에 대해 구성할 수 없는 <a href=https://docs.microsoft.com/en-us/windows/desktop/Memory/large-page-support>사용자 권한(privilege) 어설트</a>가 필요하다.</li></ul></li><li>V1.Container.ResourceRequirements.requests.cpu 및 V1.Container.ResourceRequirements.requests.memory - 노드의 사용 가능한 리소스에서 요청(requests)을 빼서, 노드에 대한 오버 프로비저닝을 방지하는데 사용할 수 있다. 그러나 오버 프로비저닝된 노드에서 리소스를 보장하는 데는 사용할 수 없다. 운영자가 오버 프로비저닝을 완전히 피하려는 경우 모범 사례로 모든 컨테이너에 적용해야 한다.</li><li>V1.Container.SecurityContext.allowPrivilegeEscalation - 윈도우에서는 불가능하며, 어떤 기능도 연결되지 않는다.</li><li>V1.Container.SecurityContext.Capabilities - POSIX 기능은 윈도우에서 구현되지 않는다.</li><li>V1.Container.SecurityContext.privileged - 윈도우는 특권을 가진 컨테이너를 지원하지 않는다.</li><li>V1.Container.SecurityContext.procMount - 윈도우에는 /proc 파일시스템이 없다.</li><li>V1.Container.SecurityContext.readOnlyRootFilesystem - 윈도우에서는 불가능하며, 레지스트리 및 시스템 프로세스가 컨테이너 내부에서 실행되려면 쓰기 권한이 필요하다.</li><li>V1.Container.SecurityContext.runAsGroup - 윈도우에서는 불가능하며, GID 지원이 없다.</li><li>V1.Container.SecurityContext.runAsNonRoot - 윈도우에는 root 사용자가 없다. 가장 가까운 항목은 노드에 존재하지 않는 아이덴티티(identity)인 ContainerAdministrator이다.</li><li>V1.Container.SecurityContext.runAsUser - 윈도우에서는 불가능하며, 정수값으로의 UID 지원이 없다.</li><li>V1.Container.SecurityContext.seLinuxOptions - 윈도우에서는 불가능하며, SELinux가 없다.</li><li>V1.Container.terminationMessagePath - 윈도우가 단일 파일 매핑을 지원하지 않는다는 점에서 몇 가지 제한이 있다. 기본값은 /dev/termination-log이며, 기본적으로 윈도우에 존재하지 않기 때문에 작동한다.</li></ul><h5 id=v1-pod>V1.Pod</h5><ul><li>V1.Pod.hostIPC, v1.pod.hostpid - 윈도우에서 호스트 네임스페이스 공유가 불가능하다.</li><li>V1.Pod.hostNetwork - 호스트 네트워크를 공유하기 위한 윈도우 OS 지원이 없다.</li><li>V1.Pod.dnsPolicy - ClusterFirstWithHostNet - 윈도우에서 호스트 네트워킹이 지원되지 않기 때문에 지원되지 않는다.</li><li>V1.Pod.podSecurityContext - 아래 V1.PodSecurityContext 내용을 참고한다.</li><li>V1.Pod.shareProcessNamespace - 이것은 베타 기능이며, 윈도우에서 구현되지 않은 리눅스 네임스페이스에 따라 다르다. 윈도우는 프로세스 네임스페이스 또는 컨테이너의 루트 파일시스템을 공유할 수 없다. 네트워크만 공유할 수 있다.</li><li>V1.Pod.terminationGracePeriodSeconds - 이것은 윈도우의 도커에서 완전히 구현되지 않았다. <a href=https://github.com/moby/moby/issues/25982>참조</a>의 내용을 참고한다. 현재 동작은 ENTRYPOINT 프로세스가 CTRL_SHUTDOWN_EVENT로 전송된 다음, 윈도우가 기본적으로 5초를 기다린 후, 마지막으로 정상적인 윈도우 종료 동작을 사용하여 모든 프로세스를 종료하는 것이다. 5초 기본값은 실제로 <a href=https://github.com/moby/moby/issues/25982#issuecomment-426441183>컨테이너 내부</a> 윈도우 레지스트리에 있으므로 컨테이너를 빌드할 때 재정의 할 수 있다.</li><li>V1.Pod.volumeDevices - 이것은 베타 기능이며, 윈도우에서 구현되지 않는다. 윈도우는 원시 블록 장치(raw block device)를 파드에 연결할 수 없다.</li><li>V1.Pod.volumes - EmptyDir, 시크릿, 컨피그맵, HostPath - 모두 작동하며 TestGrid에 테스트가 있다.<ul><li>V1.emptyDirVolumeSource - 노드 기본 매체는 윈도우의 디스크이다. 윈도우에는 내장 RAM 디스크가 없기 때문에 메모리는 지원되지 않는다.</li></ul></li><li>V1.VolumeMount.mountPropagation - 마운트 전파(propagation)는 윈도우에서 지원되지 않는다.</li></ul><h5 id=v1-podsecuritycontext>V1.PodSecurityContext</h5><p>PodSecurityContext 필드는 윈도우에서 작동하지 않는다. 참조를 위해 여기에 나열한다.</p><ul><li>V1.PodSecurityContext.SELinuxOptions - SELinux는 윈도우에서 사용할 수 없다.</li><li>V1.PodSecurityContext.RunAsUser - 윈도우에서는 사용할 수 없는 UID를 제공한다.</li><li>V1.PodSecurityContext.RunAsGroup - 윈도우에서는 사용할 수 없는 GID를 제공한다.</li><li>V1.PodSecurityContext.RunAsNonRoot - 윈도우에는 root 사용자가 없다. 가장 가까운 항목은 노드에 존재하지 않는 아이덴티티인 ContainerAdministrator이다.</li><li>V1.PodSecurityContext.SupplementalGroups - 윈도우에서는 사용할 수 없는 GID를 제공한다.</li><li>V1.PodSecurityContext.Sysctls - 이것들은 리눅스 sysctl 인터페이스의 일부이다. 윈도우에는 이에 상응하는 것이 없다.</li></ul><h4 id=운영-체제-버전-제한>운영 체제 버전 제한</h4><p>윈도우에는 호스트 OS 버전이 컨테이너 베이스 이미지 OS 버전과 일치해야 하는 엄격한 호환성 규칙이 있다. 윈도우 서버 2019의 컨테이너 운영 체제가 있는 윈도우 컨테이너만 지원된다. 윈도우 컨테이너 이미지 버전의 일부 이전 버전과의 호환성을 가능하게 하는 컨테이너의 Hyper-V 격리는 향후 릴리스로 계획되어 있다.</p><h2 id=troubleshooting>도움 받기 및 트러블슈팅</h2><p>쿠버네티스 클러스터 트러블슈팅을 위한 기본 도움말은 이 <a href=/docs/tasks/debug-application-cluster/troubleshooting/>섹션</a>에서 먼저 찾아야 한다. 이 섹션에는 몇 가지 추가 윈도우 관련 트러블슈팅 도움말이 포함되어 있다. 로그는 쿠버네티스에서 트러블슈팅하는데 중요한 요소이다. 다른 기여자로부터 트러블슈팅 지원을 구할 때마다 이를 포함해야 한다. SIG-Windows <a href=https://github.com/kubernetes/community/blob/master/sig-windows/CONTRIBUTING.md#gathering-logs>로그 수집에 대한 기여 가이드</a>의 지침을 따른다.</p><ol><li><p>start.ps1이 성공적으로 완료되었는지 어떻게 알 수 있는가?</p><p>kubelet, kube-proxy 및 (Flannel을 네트워킹 솔루션으로 선택한 경우) 노드에서 실행 중인 flanneld 호스트 에이전트 프로세스를 확인할 수 있어야 하는데, 별도의 PowerShell 윈도우에서 실행 중인 로그가 표시된다. 또한 윈도우 노드는 쿠버네티스 클러스터에서 "Ready"로 조회되어야 한다.</p></li><li><p>백그라운드에서 서비스로 실행되도록 쿠버네티스 노드 프로세스를 구성할 수 있는가?</p><p>Kubelet 및 kube-proxy는 이미 기본 윈도우 서비스로 실행되도록 구성되어 있으며, 실패(예: 프로세스 충돌) 시 서비스를 자동으로 다시 시작하여 복원력(resiliency)을 제공한다. 이러한 노드 컴포넌트를 서비스로 구성하기 위한 두 가지 옵션이 있다.</p><ol><li><p>네이티브 윈도우 서비스</p><p>Kubelet와 kube-proxy는 <code>sc.exe</code>를 사용하여 네이티브 윈도우 서비스로 실행될 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># 두 개의 개별 명령으로 kubelet 및 kube-proxy에 대한 서비스 생성</span>
sc.exe create &lt;컴포넌트_명&gt; binPath= <span style=color:#b44>&#34;&lt;바이너리_경로&gt; --service &lt;다른_인자&gt;&#34;</span>

<span style=color:#080;font-style:italic># 인자에 공백이 포함된 경우 이스케이프 되어야 한다.</span>
sc.exe create kubelet binPath= <span style=color:#b44>&#34;C:\kubelet.exe --service --hostname-override &#39;minion&#39; &lt;다른_인자&gt;&#34;</span>

<span style=color:#080;font-style:italic># 서비스 시작</span>
<span style=color:#a2f>Start-Service</span> kubelet
<span style=color:#a2f>Start-Service</span> kube-proxy

<span style=color:#080;font-style:italic># 서비스 중지</span>
<span style=color:#a2f>Stop-Service</span> kubelet (-Force)
<span style=color:#a2f>Stop-Service</span> kube-proxy (-Force)

<span style=color:#080;font-style:italic># 서비스 상태 질의</span>
<span style=color:#a2f>Get-Service</span> kubelet
<span style=color:#a2f>Get-Service</span> kube-proxy
</code></pre></div></li><li><p>nssm.exe 사용</p><p>또한 언제든지 <a href=https://nssm.cc/>nssm.exe</a>와 같은 대체 서비스 관리자를 사용하여 백그라운드에서 이러한 프로세스(flanneld, kubelet, kube-proxy)를 실행할 수 있다. 이 <a href=https://github.com/Microsoft/SDN/tree/master/Kubernetes/flannel/register-svc.ps1>샘플 스크립트</a>를 사용하여 백그라운드에서 윈도우 서비스로 실행하기 위해 nssm.exe를 활용하여 kubelet, kube-proxy, flanneld.exe를 등록할 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>register-svc</span>.ps1 -NetworkMode &lt;네트워크 모드&gt; -ManagementIP &lt;윈도우 노드 IP&gt; -ClusterCIDR &lt;클러스터 서브넷&gt; -KubeDnsServiceIP &lt;Kube-dns 서비스 IP&gt; -LogDir &lt;로그 위치 디렉터리&gt;

<span style=color:#080;font-style:italic># NetworkMode      = 네트워크 모드 l2bridge(flannel host-gw, 기본값이기도 함) 또는 네트워크 솔루션으로 선택한 오버레이(flannel vxlan)</span>
<span style=color:#080;font-style:italic># ManagementIP     = 윈도우 노드에 할당된 IP 주소. ipconfig를 사용하여 찾을 수 있다.</span>
<span style=color:#080;font-style:italic># ClusterCIDR      = 클러스터 서브넷 범위. (기본값 10.244.0.0/16)</span>
<span style=color:#080;font-style:italic># KubeDnsServiceIP = 쿠버네티스 DNS 서비스 IP (기본값 10.96.0.10)</span>
<span style=color:#080;font-style:italic># LogDir           = kubelet 및 kube-proxy 로그가 각각의 출력 파일로 리다이렉션되는 디렉터리(기본값 C:\k)</span>
</code></pre></div><p>위에 언급된 스크립트가 적합하지 않은 경우, 다음 예제를 사용하여 nssm.exe를 수동으로 구성할 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># flanneld.exe 등록</span>
nssm install flanneld C:\flannel\flanneld.exe
nssm <span style=color:#a2f>set </span>flanneld AppParameters --kubeconfig<span style=color:#666>-file</span>=c:\k\config --iface=&lt;ManagementIP&gt; --ip-masq=1 --kube-subnet-mgr=1
nssm <span style=color:#a2f>set </span>flanneld AppEnvironmentExtra NODE_NAME=&lt;hostname&gt;
nssm <span style=color:#a2f>set </span>flanneld AppDirectory C:\flannel
nssm <span style=color:#a2f>start </span>flanneld

<span style=color:#080;font-style:italic># kubelet.exe 등록</span>
<span style=color:#080;font-style:italic># Microsoft는 mcr.microsoft.com/oss/kubernetes/pause:1.4.1에서 pause 인프라 컨테이너를 릴리스했다.</span>
nssm install kubelet C:\k\kubelet.exe
nssm <span style=color:#a2f>set </span>kubelet AppParameters --hostname-override=&lt;hostname&gt; --v=6 --pod-infra-container-image=mcr.microsoft.com/oss/kubernetes/pause<span>:</span>1.4.1 --resolv-conf=<span style=color:#b44>&#34;&#34;</span> --allow-privileged=true --enable-debugging-handlers --cluster-dns=&lt;DNS-service-IP&gt; --cluster-domain=cluster.local --kubeconfig=c:\k\config --hairpin-mode=promiscuous-bridge --image-pull-progress-deadline=20m --cgroups-per-qos=false  --log-dir=&lt;log directory&gt; --logtostderr=false --enforce-node-allocatable=<span style=color:#b44>&#34;&#34;</span> --network-plugin=cni --cni-bin-dir=c:\k\cni --cni-conf-dir=c:\k\cni\config
nssm <span style=color:#a2f>set </span>kubelet AppDirectory C:\k
nssm <span style=color:#a2f>start </span>kubelet

<span style=color:#080;font-style:italic># kube-proxy.exe 등록 (l2bridge / host-gw)</span>
nssm install kube-proxy C:\k\kube-proxy.exe
nssm <span style=color:#a2f>set </span>kube-proxy AppDirectory c:\k
nssm <span style=color:#a2f>set </span>kube-proxy AppParameters --v=4 --proxy-mode=kernelspace --hostname-override=&lt;hostname&gt;--kubeconfig=c:\k\config --enable-dsr=false --log-dir=&lt;log directory&gt; --logtostderr=false
nssm.exe <span style=color:#a2f>set </span>kube-proxy AppEnvironmentExtra KUBE_NETWORK=cbr0
nssm <span style=color:#a2f>set </span>kube-proxy DependOnService kubelet
nssm <span style=color:#a2f>start </span>kube-proxy

<span style=color:#080;font-style:italic># kube-proxy.exe 등록 (overlay / vxlan)</span>
nssm install kube-proxy C:\k\kube-proxy.exe
nssm <span style=color:#a2f>set </span>kube-proxy AppDirectory c:\k
nssm <span style=color:#a2f>set </span>kube-proxy AppParameters --v=4 --proxy-mode=kernelspace --feature-gates=<span style=color:#b44>&#34;WinOverlay=true&#34;</span> --hostname-override=&lt;hostname&gt; --kubeconfig=c:\k\config --network-name=vxlan0 --source-vip=&lt;source-vip&gt; --enable-dsr=false --log-dir=&lt;log directory&gt; --logtostderr=false
nssm <span style=color:#a2f>set </span>kube-proxy DependOnService kubelet
nssm <span style=color:#a2f>start </span>kube-proxy
</code></pre></div><p>초기 트러블슈팅을 위해 <a href=https://nssm.cc/>nssm.exe</a>에서 다음 플래그를 사용하여 stdout 및 stderr을 출력 파일로 리다이렉션할 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>nssm <span style=color:#a2f>set </span>&lt;Service Name&gt; AppStdout C:\k\mysvc.log
nssm <span style=color:#a2f>set </span>&lt;Service Name&gt; AppStderr C:\k\mysvc.log
</code></pre></div><p>자세한 내용은 공식 <a href=https://nssm.cc/usage>nssm 사용</a> 문서를 참고한다.</p></li></ol></li><li><p>내 윈도우 파드에 네트워크 연결이 없다.</p><p>가상 머신을 사용하는 경우, 모든 VM 네트워크 어댑터에서 MAC 스푸핑이 활성화되어 있는지 확인한다.</p></li><li><p>내 윈도우 파드가 외부 리소스를 ping 할 수 없다.</p><p>윈도우 파드에는 현재 ICMP 프로토콜용으로 프로그래밍된 아웃바운드 규칙이 없다. 그러나 TCP/UDP는 지원된다. 클러스터 외부 리소스에 대한 연결을 시연하려는 경우, <code>ping &lt;IP></code>를 해당 <code>curl &lt;IP></code>명령으로 대체한다.</p><p>여전히 문제가 발생하는 경우, <a href=https://github.com/Microsoft/SDN/blob/master/Kubernetes/flannel/l2bridge/cni/config/cni.conf>cni.conf</a>의 네트워크 구성에 특별히 추가 확인이 필요하다. 언제든지 이 정적 파일을 편집할 수 있다. 구성 업데이트는 새로 생성된 모든 쿠버네티스 리소스에 적용된다.</p><p>쿠버네티스 네트워킹 요구 사항 중 하나(<a href=/ko/docs/concepts/cluster-administration/networking/>쿠버네티스 모델</a>)는 클러스터 통신이 내부적으로 NAT 없이 발생하는 것이다. 이 요구 사항을 준수하기 위해 아웃바운드 NAT가 발생하지 않도록 하는 모든 통신에 대한 <a href=https://github.com/Microsoft/SDN/blob/master/Kubernetes/flannel/l2bridge/cni/config/cni.conf#L20>ExceptionList</a>가 있다. 그러나 이것은 쿼리하려는 외부 IP를 ExceptionList에서 제외해야 함도 의미한다. 그래야만 윈도우 파드에서 발생하는 트래픽이 제대로 SNAT 되어 외부에서 응답을 받는다. 이와 관련하여 <code>cni.conf</code>의 ExceptionList는 다음과 같아야 한다.</p><pre><code class=language-conf data-lang=conf>&quot;ExceptionList&quot;: [
                &quot;10.244.0.0/16&quot;,  # 클러스터 서브넷
                &quot;10.96.0.0/12&quot;,   # 서비스 서브넷
                &quot;10.127.130.0/24&quot; # 관리(호스트) 서브넷
            ]
</code></pre></li><li><p>내 윈도우 노드가 NodePort 서비스에 접근할 수 없다.</p><p>노드 자체에서는 로컬 NodePort 접근이 실패한다. 이것은 알려진 제약사항이다. NodePort 접근은 다른 노드 또는 외부 클라이언트에서는 가능하다.</p></li><li><p>컨테이너의 vNIC 및 HNS 엔드포인트가 삭제되었다.</p><p>이 문제는 <code>hostname-override</code> 파라미터가 <a href=/ko/docs/reference/command-line-tools-reference/kube-proxy/>kube-proxy</a>에 전달되지 않은 경우 발생할 수 있다. 이를 해결하려면 사용자는 다음과 같이 hostname을 kube-proxy에 전달해야 한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>C:\k\kube-proxy.exe --hostname-override=$(hostname)
</code></pre></div></li><li><p>플란넬(flannel)을 사용하면 클러스터에 다시 조인(join)한 후 노드에 이슈가 발생한다.</p><p>이전에 삭제된 노드가 클러스터에 다시 조인될 때마다, flannelD는 새 파드 서브넷을 노드에 할당하려고 한다. 사용자는 다음 경로에서 이전 파드 서브넷 구성 파일을 제거해야 한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>Remove-Item</span> C:\k\SourceVip.json
<span style=color:#a2f>Remove-Item</span> C:\k\SourceVipRequest.json
</code></pre></div></li><li><p><code>start.ps1</code>을 시작한 후, flanneld가 "Waiting for the Network to be created"에서 멈춘다.</p><p>이 <a href=https://github.com/coreos/flannel/issues/1066>이슈</a>에 대한 수많은 보고가 있다. 플란넬 네트워크의 관리 IP가 설정될 때의 타이밍 이슈일 가능성이 높다. 해결 방법은 start.ps1을 다시 시작하거나 다음과 같이 수동으로 다시 시작하는 것이다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>PS </span>C:&gt; <span style=color:#800>[Environment]</span>::SetEnvironmentVariable(<span style=color:#b44>&#34;NODE_NAME&#34;</span>, <span style=color:#b44>&#34;&lt;Windows_Worker_Hostname&gt;&#34;</span>)
<span style=color:#a2f>PS </span>C:&gt; C:\flannel\flanneld.exe --kubeconfig<span style=color:#666>-file</span>=c:\k\config --iface=&lt;Windows_Worker_Node_IP&gt; --ip-masq=1 --kube-subnet-mgr=1
</code></pre></div></li><li><p><code>/run/flannel/subnet.env</code> 누락으로 인해 윈도우 파드를 시작할 수 없다.</p><p>이것은 플란넬이 제대로 실행되지 않았음을 나타낸다. flanneld.exe를 다시 시작하거나 쿠버네티스 마스터의 <code>/run/flannel/subnet.env</code>에서 윈도우 워커 노드의 <code>C:\run\flannel\subnet.env</code>로 파일을 수동으로 복사할 수 있고, <code>FLANNEL_SUBNET</code> 행을 다른 숫자로 수정한다. 예를 들어, 다음은 노드 서브넷 10.244.4.1/24가 필요한 경우이다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-env data-lang=env><span style=color:#b8860b>FLANNEL_NETWORK</span><span style=color:#666>=</span>10.244.0.0/16
<span style=color:#b8860b>FLANNEL_SUBNET</span><span style=color:#666>=</span>10.244.4.1/24
<span style=color:#b8860b>FLANNEL_MTU</span><span style=color:#666>=</span><span style=color:#666>1500</span>
<span style=color:#b8860b>FLANNEL_IPMASQ</span><span style=color:#666>=</span><span style=color:#a2f>true</span>
</code></pre></div></li><li><p>내 윈도우 노드가 서비스 IP를 사용하여 내 서비스에 접근할 수 없다.</p><p>이는 윈도우에서 현재 네트워킹 스택의 알려진 제약 사항이다. 그러나 윈도우 파드는 서비스 IP에 접근할 수 있다.</p></li><li><p>kubelet을 시작할 때 네트워크 어댑터를 찾을 수 없다.</p><p>윈도우 네트워킹 스택에는 쿠버네티스 네트워킹이 작동하기 위한 가상 어댑터가 필요하다. 다음 명령이 (어드민 셸에서) 결과를 반환하지 않으면, Kubelet이 작동하는데 필요한 필수 구성 요소인 가상 네트워크 생성이 실패한 것이다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>Get-HnsNetwork</span> | ? Name <span style=color:#666>-ieq</span> <span style=color:#b44>&#34;cbr0&#34;</span>
<span style=color:#a2f>Get-NetAdapter</span> | ? Name <span style=color:#666>-Like</span> <span style=color:#b44>&#34;vEthernet (Ethernet*&#34;</span>
</code></pre></div><p>호스트 네트워크 어댑터가 "Ethernet"이 아닌 경우, 종종 start.ps1 스크립트의 <a href=https://github.com/microsoft/SDN/blob/master/Kubernetes/flannel/start.ps1#L7>InterfaceName</a> 파라미터를 수정하는 것이 좋다. 그렇지 않으면 <code>start-kubelet.ps1</code> 스크립트의 출력을 참조하여 가상 네트워크 생성 중에 오류가 있는지 확인한다.</p></li><li><p>내 파드가 "Container Creating"에서 멈췄거나 계속해서 다시 시작된다.</p><p>pause 이미지가 OS 버전과 호환되는지 확인한다. <a href=https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/deploying-resources>지침</a>에서는 OS와 컨테이너가 모두 버전 1803이라고 가정한다. 이후 버전의 윈도우가 있는 경우, Insider 빌드와 같이 그에 따라 이미지를 조정해야 한다. 이미지는 Microsoft의 <a href=https://hub.docker.com/u/microsoft/>도커 리포지터리</a>를 참조한다. 그럼에도 불구하고, pause 이미지 Dockerfile과 샘플 서비스는 이미지가 :latest로 태그될 것으로 예상한다.</p></li><li><p>DNS 확인(resolution)이 제대로 작동하지 않는다.</p><p>이 <a href=#dns-limitations>섹션</a>에서 윈도우에 대한 DNS 제한을 확인한다.</p></li><li><p><code>kubectl port-forward</code>가 "unable to do port forwarding: wincat not found"로 실패한다.</p><p>이는 쿠버네티스 1.15 및 pause 인프라 컨테이너 <code>mcr.microsoft.com/oss/kubernetes/pause:1.4.1</code>에서 구현되었다. 해당 버전 또는 최신 버전을 사용해야 한다.
자체 pause 인프라 컨테이너를 빌드하려면 <a href=https://github.com/kubernetes-sigs/sig-windows-tools/tree/master/cmd/wincat>wincat</a>을 포함해야 한다.</p></li><li><p>내 윈도우 서버 노드가 프록시 뒤에 있기 때문에 내 쿠버네티스 설치가 실패한다.</p><p>프록시 뒤에 있는 경우 다음 PowerShell 환경 변수를 정의해야 한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-PowerShell data-lang=PowerShell><span style=color:#800>[Environment]</span>::SetEnvironmentVariable(<span style=color:#b44>&#34;HTTP_PROXY&#34;</span>, <span style=color:#b44>&#34;http://proxy.example.com:80/&#34;</span>, <span style=color:#800>[EnvironmentVariableTarget]</span>::Machine)
<span style=color:#800>[Environment]</span>::SetEnvironmentVariable(<span style=color:#b44>&#34;HTTPS_PROXY&#34;</span>, <span style=color:#b44>&#34;http://proxy.example.com:443/&#34;</span>, <span style=color:#800>[EnvironmentVariableTarget]</span>::Machine)
</code></pre></div></li><li><p><code>pause</code> 컨테이너란 무엇인가?</p><p>쿠버네티스 파드에서는 컨테이너 엔드포인트를 호스팅하기 위해 먼저 인프라 또는 "pause" 컨테이너가 생성된다. 인프라 및 워커 컨테이너를 포함하여 동일한 파드에 속하는 컨테이너는 공통 네트워크 네임스페이스 및 엔드포인트(동일한 IP 및 포트 공간)를 공유한다. 네트워크 구성을 잃지 않고 워커 컨테이너가 충돌하거나 다시 시작되도록 하려면 pause 컨테이너가 필요하다.</p><p>"pause" (인프라) 이미지는 Microsoft Container Registry(MCR)에서 호스팅된다. <code>mcr.microsoft.com/oss/kubernetes/pause:1.4.1</code>을 사용하여 접근할 수 있다. 자세한 내용은 <a href=https://github.com/kubernetes-sigs/windows-testing/blob/master/images/pause/Dockerfile>DOCKERFILE</a>을 참고한다.</p></li></ol><h3 id=추가-조사>추가 조사</h3><p>이러한 단계로 문제가 해결되지 않으면, 다음을 통해 쿠버네티스의 윈도우 노드에서 윈도우 컨테이너를 실행하는데 도움을 받을 수 있다.</p><ul><li>스택오버플로우 <a href=https://stackoverflow.com/questions/tagged/windows-server-container>윈도우 서버 컨테이너</a> 주제</li><li>쿠버네티스 공식 포럼 <a href=https://discuss.kubernetes.io/>discuss.kubernetes.io</a></li><li>쿠버네티스 슬랙 <a href=https://kubernetes.slack.com/messages/sig-windows>#SIG-Windows Channel</a></li></ul><h2 id=이슈-리포팅-및-기능-요청>이슈 리포팅 및 기능 요청</h2><p>버그처럼 보이는 부분이 있거나 기능 요청을 하고 싶다면, <a href=https://github.com/kubernetes/kubernetes/issues>GitHub 이슈 트래킹 시스템</a>을 활용한다. <a href=https://github.com/kubernetes/kubernetes/issues/new/choose>GitHub</a>에서 이슈를 열고 SIG-Windows에 할당할 수 있다. 먼저 이전에 보고된 이슈 목록을 검색하고 이슈에 대한 경험을 언급하고 추가 로그를 첨부해야 한다. SIG-Windows 슬랙은 티켓을 만들기 전에 초기 지원 및 트러블슈팅 아이디어를 얻을 수 있는 좋은 방법이기도 하다.</p><p>버그를 제출하는 경우, 다음과 같이 문제를 재현하는 방법에 대한 자세한 정보를 포함한다.</p><ul><li>쿠버네티스 버전: kubectl version</li><li>환경 세부사항: 클라우드 공급자, OS 배포판, 네트워킹 선택 및 구성, 도커 버전</li><li>문제를 재현하기 위한 세부 단계</li><li><a href=https://github.com/kubernetes/community/blob/master/sig-windows/CONTRIBUTING.md#gathering-logs>관련 로그</a></li><li>SIG-Windows 회원의 주의를 끌 수 있도록 <code>/sig windows</code>로 이슈에 대해 어노테이션을 달아 이슈에 sig/windows 태그를 지정한다.</li></ul><h2 id=다음-내용>다음 내용</h2><p>로드맵에는 많은 기능이 있다. 요약된 높은 수준의 목록이 아래에 포함되어 있지만, <a href=https://github.com/orgs/kubernetes/projects/8>로드맵 프로젝트</a>를 보고 <a href=https://github.com/kubernetes/community/blob/master/sig-windows/>기여</a>하여 윈도우 지원을 개선하는데 도움이 주는 것이 좋다.</p><h3 id=hyper-v-격리-isolation>Hyper-V 격리(isolation)</h3><p>쿠버네티스에서 윈도우 컨테이너에 대해 다음 유스케이스를 사용하려면 Hyper-V 격리가 필요하다.</p><ul><li>추가 보안을 위해 파드 간 하이퍼바이저 기반 격리</li><li>하위 호환성을 통해 컨테이너를 다시 빌드할 필요 없이 노드에서 최신 윈도우 서버 버전을 실행할 수 있다.</li><li>파드에 대한 특정 CPU/NUMA 설정</li><li>메모리 격리 및 예약</li></ul><p>Hyper-V 격리 지원은 이후 릴리스에 추가되며 CRI-Containerd가 필요하다.</p><h3 id=kubeadm-및-클러스터-api를-사용한-배포>kubeadm 및 클러스터 API를 사용한 배포</h3><p>Kubeadm은 사용자가 쿠버네티스 클러스터를 배포하기 위한 사실상의 표준이
되고 있다. kubeadm의 윈도우 노드 지원은 현재 작업 중이지만
<a href=/ko/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes/>여기</a>에서 가이드를 사용할 수 있다.
또한 윈도우 노드가 적절하게 프로비저닝되도록 클러스터 API에
투자하고 있다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3a51e66c5de55f9093a8dc55742006d3>3.3.2 - 쿠버네티스에서 윈도우 컨테이너 스케줄링을 위한 가이드</h1><p>많은 조직에서 실행하는 서비스와 애플리케이션의 상당 부분이 윈도우 애플리케이션으로 구성된다. 이 가이드는 쿠버네티스에서 윈도우 컨테이너를 구성하고 배포하는 단계를 안내한다.</p><h2 id=목표>목표</h2><ul><li>윈도우 노드에서 윈도우 컨테이너를 실행하는 예시 디플로이먼트를 구성한다.</li><li>(선택) 그룹 매니지드 서비스 어카운트(GMSA)를 이용한 사용자 파드를 위한 액티브 디렉터리 신원(Active Directory Identity)을 구성한다.</li></ul><h2 id=시작하기-전에>시작하기 전에</h2><ul><li><a href=/ko/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes>윈도우 서버에서 운영하는 마스터와 워커 노드</a>를 포함한 쿠버네티스 클러스터를 생성한다.</li><li>쿠버네티스에서 서비스와 워크로드를 생성하고 배포하는 것은 리눅스나 윈도우 컨테이너 모두 비슷한 방식이라는 것이 중요하다. <a href=/ko/docs/reference/kubectl/overview/>Kubectl 커맨드</a>로 클러스터에 접속하는 것은 동일하다. 아래 단원의 예시는 윈도우 컨테이너를 경험하기 위해 제공한다.</li></ul><h2 id=시작하기-윈도우-컨테이너-배포하기>시작하기: 윈도우 컨테이너 배포하기</h2><p>쿠버네티스에서 윈도우 컨테이너를 배포하려면, 먼저 예시 애플리케이션을 생성해야 한다. 아래 예시 YAML 파일은 간단한 웹서버 애플리케이션을 생성한다. 아래 내용으로 채운 서비스 스펙을 <code>win-webserver.yaml</code>로 생성하자.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># 이 서비스에서 제공하는 포트</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>NodePort<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>windowswebserver<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mcr.microsoft.com/windows/servercore:ltsc2019<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- powershell.exe<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- -command<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;&lt;#code used from https://gist.github.com/19WAS85/5424431#&gt; ; $$listener = New-Object System.Net.HttpListener ; $$listener.Prefixes.Add(&#39;http://*:80/&#39;) ; $$listener.Start() ; $$callerCounts = @{} ; Write-Host(&#39;Listening at http://*:80/&#39;) ; while ($$listener.IsListening) { ;$$context = $$listener.GetContext() ;$$requestUrl = $$context.Request.Url ;$$clientIP = $$context.Request.RemoteEndPoint.Address ;$$response = $$context.Response ;Write-Host &#39;&#39; ;Write-Host(&#39;&gt; {0}&#39; -f $$requestUrl) ;  ;$$count = 1 ;$$k=$$callerCounts.Get_Item($$clientIP) ;if ($$k -ne $$null) { $$count += $$k } ;$$callerCounts.Set_Item($$clientIP, $$count) ;$$ip=(Get-NetAdapter | Get-NetIpAddress); $$header=&#39;&lt;html&gt;&lt;body&gt;&lt;H1&gt;Windows Container Web Server&lt;/H1&gt;&#39; ;$$callerCountsString=&#39;&#39; ;$$callerCounts.Keys | % { $$callerCountsString+=&#39;&lt;p&gt;IP {0} callerCount {1} &#39; -f $$ip[1].IPAddress,$$callerCounts.Item($$_) } ;$$footer=&#39;&lt;/body&gt;&lt;/html&gt;&#39; ;$$content=&#39;{0}{1}{2}&#39; -f $$header,$$callerCountsString,$$footer ;Write-Output $$content ;$$buffer = [System.Text.Encoding]::UTF8.GetBytes($$content) ;$$response.ContentLength64 = $$buffer.Length ;$$response.OutputStream.Write($$buffer, 0, $$buffer.Length) ;$$response.Close() ;$$responseStatus = $$response.StatusCode ;Write-Host(&#39;&lt; {0}&#39; -f $$responseStatus)  } ; &#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kubernetes.io/os</span>:<span style=color:#bbb> </span>windows<span style=color:#bbb>
</span></code></pre></div><blockquote class="note callout"><div><strong>참고:</strong> 포트 매핑도 지원하지만, 간략한 예시를 위해 컨테이너 포트 80을 직접 서비스로 노출한다.</div></blockquote><ol><li><p>모든 노드가 건강한지 확인한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get nodes
</code></pre></div></li><li><p>서비스를 배포하고 파드 갱신을 지켜보자.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl apply -f win-webserver.yaml
kubectl get pods -o wide -w
</code></pre></div><p>이 서비스가 정확히 배포되면 모든 파드는 Ready로 표기된다. 지켜보기를 중단하려면, Ctrl+C 를 누르자.</p></li><li><p>이 디플로이먼트가 성공적인지 확인한다. 다음을 검토하자.</p><ul><li>윈도우 노드에 파드당 두 컨테이너, <code>docker ps</code>를 사용한다.</li><li>리눅스 마스터에서 나열된 두 파드, <code>kubectl get pods</code>를 사용한다.</li><li>네트워크를 통한 노드에서 파드 간에 통신, 리눅스 마스터에서 <code>curl</code>을 파드 IP 주소의 80 포트로 실행하여 웹 서버 응답을 확인한다.</li><li>파드와 파드 간에 통신, <code>docker exec</code> 나 <code>kubectl exec</code>를 이용해 파드 간에 핑(ping)한다(윈도우 노드를 여럿가지고 있다면 호스트를 달리하며).</li><li>서비스와 파드 간에 통신, 리눅스 마스터와 독립 파드에서 <code>curl</code>을 가상 서비스 IP 주소(<code>kubectl get services</code>로 보여지는)로 실행한다.</li><li>서비스 검색(discovery), 쿠버네티스 <a href=/ko/docs/concepts/services-networking/dns-pod-service/#%EC%84%9C%EB%B9%84%EC%8A%A4>기본 DNS 접미사</a>와 서비스 이름으로 <code>curl</code>을 실행한다.</li><li>인바운드 연결, 클러스터 외부 장비나 리눅스 마스터에서 NodePort로 <code>curl</code>을 실행한다.</li><li>아웃바운드 연결, <code>kubectl exec</code>를 이용해서 파드에서 외부 IP 주소로 <code>curl</code>을 실행한다.</li></ul></li></ol><blockquote class="note callout"><div><strong>참고:</strong> 윈도우 컨테이너 호스트는 현재 윈도우 네트워킹 스택의 플랫폼 제한으로 인해, 그 안에서 스케줄링하는 서비스의 IP 주소로 접근할 수 없다. 윈도우 파드만 서비스 IP 주소로 접근할 수 있다.</div></blockquote><h2 id=가시성>가시성</h2><h3 id=워크로드에서-로그-캡쳐하기>워크로드에서 로그 캡쳐하기</h3><p>로그는 가시성의 중요한 요소이다. 로그는 사용자가 워크로드의 운영측면을 파악할 수 있도록 하며 문제 해결의 핵심 요소이다. 윈도우 컨테이너와 워크로드 내의 윈도우 컨테이너가 리눅스 컨테이너와는 다르게 동작하기 때문에, 사용자가 로그를 수집하는 데 어려움을 겪었기에 운영 가시성이 제한되었다. 예를 들어 윈도우 워크로드는 일반적으로 ETW(Event Tracing for Windows)에 로그인하거나 애플리케이션 이벤트 로그에 항목을 푸시하도록 구성한다. Microsoft의 오픈 소스 도구인 <a href=https://github.com/microsoft/windows-container-tools/tree/master/LogMonitor>LogMonitor</a>는 윈도우 컨테이너 안에 구성된 로그 소스를 모니터링하는 권장하는 방법이다. LogMonitor는 이벤트 로그, ETW 공급자 그리고 사용자 정의 애플리케이션 로그 모니터링을 지원하고 <code>kubectl logs &lt;pod></code> 에 의한 사용을 위해 STDOUT으로 파이프한다.</p><p>LogMonitor Github 페이지의 지침에 따라 모든 컨테이너 바이너리와 설정 파일을 복사하고, LogMonitor에 필요한 입력 지점을 추가해서 로그를 STDOUT으로 푸시한다.</p><h2 id=설정-가능한-컨테이너-username-사용하기>설정 가능한 컨테이너 username 사용하기</h2><p>쿠버네티스 v1.16 부터, 윈도우 컨테이너는 이미지 기본 값과는 다른 username으로 엔트리포인트와 프로세스를 실행하도록 설정할 수 있다. 이 방식은 리눅스 컨테이너에서 지원되는 방식과는 조금 차이가 있다. <a href=/docs/tasks/configure-pod-container/configure-runasusername/>여기</a>에서 이에 대해 추가적으로 배울 수 있다.</p><h2 id=그룹-매니지드-서비스-어카운트를-이용하여-워크로드-신원-관리하기>그룹 매니지드 서비스 어카운트를 이용하여 워크로드 신원 관리하기</h2><p>쿠버네티스 v1.14부터 윈도우 컨테이너 워크로드는 그룹 매니지드 서비스 어카운트(GMSA, Group Managed Service Account)를 이용하여 구성할 수 있다. 그룹 매니지드 서비스 어카운트는 액티브 디렉터리 어카운트의 특정한 종류로 자동 암호 관리 기능, 단순화된 서비스 주체 이름(SPN, simplified service principal name), 여러 서버의 다른 관리자에게 관리를 위임하는 기능을 제공한다. GMSA로 구성한 컨테이너는 GMSA로 구성된 신원을 들고 있는 동안 외부 액티브 디렉터리 도메인 리소스를 접근할 수 있다. 윈도우 컨테이너를 위한 GMSA를 이용하고 구성하는 방법은 <a href=/docs/tasks/configure-pod-container/configure-gmsa/>여기</a>에서 알아보자.</p><h2 id=테인트-taint-와-톨러레이션-toleration>테인트(Taint)와 톨러레이션(Toleration)</h2><p>오늘날 사용자는 리눅스와 윈도우 워크로드를 특정 OS 노드별로 보존하기 위해 테인트와 노드 셀렉터(nodeSelector)의 조합을 이용해야 한다. 이것은 윈도우 사용자에게만 부담을 줄 것으로 보인다. 아래는 권장되는 방식의 개요인데, 이것의 주요 목표 중에 하나는 이 방식이 기존 리눅스 워크로드와 호환되어야 한다는 것이다.</p><h3 id=특정-os-워크로드를-적절한-컨테이너-호스트에서-처리하도록-보장하기>특정 OS 워크로드를 적절한 컨테이너 호스트에서 처리하도록 보장하기</h3><p>사용자는 윈도우 컨테이너가 테인트와 톨러레이션을 이용해서 적절한 호스트에서 스케줄링되기를 보장할 수 있다. 오늘날 모든 쿠버네티스 노드는 다음 기본 레이블을 가지고 있다.</p><ul><li>kubernetes.io/os = [windows|linux]</li><li>kubernetes.io/arch = [amd64|arm64|...]</li></ul><p>파드 사양에 노드 셀렉터를 <code>"kubernetes.io/os": windows</code>와 같이 지정하지 않았다면, 그 파드는 리눅스나 윈도우, 아무 호스트에나 스케줄링될 수 있다. 윈도우 컨테이너는 윈도우에서만 운영될 수 있고 리눅스 컨테이너는 리눅스에서만 운영될 수 있기 때문에 이는 문제를 일으킬 수 있다. 가장 좋은 방법은 노드 셀렉터를 사용하는 것이다.</p><p>그러나 많은 경우 사용자는 이미 존재하는 대량의 리눅스 컨테이너용 디플로이먼트를 가지고 있을 뿐만 아니라, 헬름(Helm) 차트 커뮤니티 같은 상용 구성의 에코시스템이나, 오퍼레이터(Operator) 같은 프로그래밍 방식의 파드 생성 사례가 있음을 알고 있다. 이런 상황에서는 노드 셀렉터를 추가하는 구성 변경을 망설일 수 있다. 이에 대한 대안은 테인트를 사용하는 것이다. Kubelet은 등록하는 동안 테인트를 설정할 수 있기 때문에, 윈도우에서만 운영할 때에 자동으로 테인트를 추가하기 쉽다.</p><p>예를 들면, <code>--register-with-taints='os=windows:NoSchedule'</code></p><p>모든 윈도우 노드에 테인트를 추가하여 아무 것도 거기에 스케줄링하지 않게 될 것이다(존재하는 리눅스 파드를 포함하여). 윈도우 파드가 윈도우 노드에 스케줄링되려면, 윈도우를 선택하기 위한 노드 셀렉터 및 적합하게 일치하는 톨러레이션이 모두 필요하다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/os</span>:<span style=color:#bbb> </span>windows<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>node.kubernetes.io/windows-build</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;10.0.17763&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;os&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;windows&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></code></pre></div><h3 id=동일-클러스터에서-여러-윈도우-버전을-조작하는-방법>동일 클러스터에서 여러 윈도우 버전을 조작하는 방법</h3><p>파드에서 사용하는 윈도우 서버 버전은 노드 버전과 일치해야 한다. 만약 동일한 클러스터에서 여러 윈도우
서버 버전을 사용하려면, 추가로 노드 레이블과 nodeSelectors를 설정해야만 한다.</p><p>쿠버네티스 1.17은 이것을 단순화하기 위해 새로운 레이블인 <code>node.kubernetes.io/windows-build</code> 를 자동으로 추가 한다. 만약 이전 버전을
실행 중인 경우 이 레이블을 윈도우 노드에 수동으로 추가하는 것을 권장한다.</p><p>이 레이블은 호환성을 일치해야 하는 윈도우 메이저, 마이너 및 빌드 번호를 나타낸다. 여기에 현재
사용하는 각 윈도우 서버 버전이 있다.</p><table><thead><tr><th>제품 이름</th><th>빌드 번호</th></tr></thead><tbody><tr><td>윈도우 서버 2019</td><td>10.0.17763</td></tr><tr><td>윈도우 서버 버전 1809</td><td>10.0.17763</td></tr><tr><td>윈도우 서버 버전 1903</td><td>10.0.18362</td></tr></tbody></table><h3 id=runtimeclass로-단순화>RuntimeClass로 단순화</h3><p><a href=https://kubernetes.io/docs/concepts/containers/runtime-class/>RuntimeClass</a> 를 사용해서 테인트(taint)와 톨러레이션(toleration)을 사용하는 프로세스를 간소화 할 수 있다. 클러스터 관리자는
이 테인트와 톨러레이션을 캡슐화하는데 사용되는 <code>RuntimeClass</code> 오브젝트를 생성할 수 있다.</p><ol><li>이 파일을 <code>runtimeClasses.yml</code> 로 저장한다. 여기에는 윈도우 OS, 아키텍처 및 버전에 적합한 <code>nodeSelector</code> 가 포함되었다.</li></ol><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>node.k8s.io/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>RuntimeClass<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>windows-2019<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>handler</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;docker&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>scheduling</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/os</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;windows&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/arch</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;amd64&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>node.kubernetes.io/windows-build</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;10.0.17763&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>os<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>Equal<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;windows&#34;</span><span style=color:#bbb>
</span></code></pre></div><ol start=2><li>클러스터 관리자로 <code>kubectl create -f runtimeClasses.yml</code> 를 실행해서 사용한다.</li><li>파드 사양에 적합한 <code>runtimeClassName: windows-2019</code> 를 추가한다.</li></ol><p>예시:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>runtimeClassName</span>:<span style=color:#bbb> </span>windows-2019<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2019<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>800Mi<span style=color:#bbb>
</span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>.1<span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>300Mi<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-84b6491601d6a2b3da4cd5a105c866ba>4 - 모범 사례</h1></div><div class=td-content><h1 id=pg-c797ee17120176c685455db89ae091a9>4.1 - 대형 클러스터에 대한 고려 사항</h1><p>클러스터는 <a class=glossary-tooltip title="컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어." data-toggle=tooltip data-placement=top href="/ko/docs/reference/glossary/?all=true#term-control-plane" target=_blank aria-label="컨트롤 플레인">컨트롤 플레인</a>에서 관리하는
쿠버네티스 에이전트를 실행하는 <a class=glossary-tooltip title="노드는 쿠버네티스의 작업 장비(worker machine)이다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a>(물리
또는 가상 머신)의 집합이다.
쿠버네티스 v1.20는 노드 5000개까지의 클러스터를 지원한다. 보다 정확하게는,
쿠버네티스는 다음 기준을 <em>모두</em> 만족하는 설정을 수용하도록 설계되었다.</p><ul><li>노드 당 파드 100 개 이하</li><li>노드 5000개 이하</li><li>전체 파드 150000개 이하</li><li>전체 컨테이너 300000개 이하</li></ul><p>노드를 추가하거나 제거하여 클러스터를 확장할 수 있다. 이를 수행하는 방법은
클러스터 배포 방법에 따라 다르다.</p><h2 id=quota-issues>클라우드 프로바이더 리소스 쿼터</h2><p>여러 노드를 가지는 클러스터를 만들 때, 클라우드 프로바이더 쿼터 이슈를 피하기 위해
고려할 점은 다음과 같다.</p><ul><li>다음과 같은 클라우드 리소스에 대한 쿼터 증가를 요청한다.<ul><li>컴퓨터 인스턴스</li><li>CPU</li><li>스토리지 볼륨</li><li>사용 중인 IP 주소</li><li>패킷 필터링 규칙 세트</li><li>로드밸런서 개수</li><li>로그 스트림</li></ul></li><li>일부 클라우드 프로바이더는 새로운 인스턴스 생성 속도에 상한이 있어, 클러스터 확장 작업 간 새로운 노드를 일괄적으로 배치하고, 배치 간에 일시 중지한다.</li></ul><h2 id=컨트롤-플레인-컴포넌트>컨트롤 플레인 컴포넌트</h2><p>대규모 클러스터의 경우, 충분한 컴퓨트 및 기타 리소스가 있는 컨트롤 플레인이
필요하다.</p><p>일반적으로 장애 영역 당 하나 또는 두 개의 컨트롤 플레인 인스턴스를
실행하고, 해당 인스턴스를 수직으로(vertically) 먼저 확장한 다음 (수직) 규모로 하락하는
지점에 도달한 후 수평으로(horizontally) 확장한다.</p><p>내결함성을 제공하려면 장애 영역 당 하나 이상의 인스턴스를 실행해야 한다. 쿠버네티스
노드는 동일한 장애 영역에 있는 컨트롤 플레인 엔드포인트로 트래픽을
자동으로 조정하지 않는다. 그러나, 클라우드 프로바이더는 이를 수행하기 위한 자체 메커니즘을 가지고 있을 수 있다.</p><p>예를 들어, 관리형 로드 밸런서를 사용하여 장애 영역 <em>A</em> 의
kubelet 및 파드에서 시작되는 트래픽을 전송하도록 로드 밸런서를 구성하고, 해당 트래픽을
<em>A</em> 영역에 있는 컨트롤 플레인 호스트로만 전달한다. 단일 컨트롤 플레인 호스트 또는
엔드포인트 장애 영역 <em>A</em> 이 오프라인이 되면, 영역 <em>A</em> 의 노드에 대한
모든 컨트롤 플레인 트래픽이 이제 영역간에 전송되고 있음을 의미한다. 각 영역에서 여러 컨트롤 플레인 호스트를
실행하면 가용성이 낮아진다.</p><h3 id=etcd-저장소>etcd 저장소</h3><p>큰 클러스터의 성능 향상을 위해, 사용자는 이벤트 오브젝트를 각각의
전용 etcd 인스턴스에 저장한다.</p><p>클러스터 생성시의 부가 스트립트이다.
클러스터 생성 시에 (사용자 도구를 사용하여) 다음을 수행할 수 있다.</p><ul><li>추가 ectd 인스턴스 시작 및 설정</li><li>이벤트를 저장하기 위한 <a class=glossary-tooltip title="쿠버네티스 API를 제공하는 컨트롤 플레인 컴포넌트." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label="API server">API server</a> 설정</li></ul><h2 id=애드온-리소스>애드온 리소스</h2><p>쿠버네티스 <a href=/ko/docs/concepts/configuration/manage-resources-containers/>리소스 제한</a>은
파드와 컨테이너가 다른 컴포넌트에 영향을 줄 수 있는 메모리 누수 및 기타 방식의 영향을
최소화하는 데 도움이 된다. 이러한 리소스 제한은 애플리케이션 워크로드에 적용될 수 있는 것처럼
<a class=glossary-tooltip title="Resources that extend the functionality of Kubernetes." data-toggle=tooltip data-placement=top href=/docs/concepts/cluster-administration/addons/ target=_blank aria-label=애드온>애드온</a> 리소스에도 적용될 수 있다.</p><p>예를 들어, 로깅 컴포넌트에 대한 CPU 및 메모리 제한을 설정할 수 있다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-cloud-logging<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>fluent/fluentd-kubernetes-daemonset:v1<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></code></pre></div><p>애드온의 기본 제한은 일반적으로 중소형 쿠버네티스 클러스터에서
각 애드온을 실행한 경험에서 수집된 데이터를 기반으로 한다. 대규모 클러스터에서
실행할 때, 애드온은 종종 기본 제한보다 많은 리소스를 소비한다.
이러한 값을 조정하지 않고 대규모 클러스터를 배포하면, 애드온이
메모리 제한에 계속 도달하기 때문에 지속적으로 종료될 수 있다.
또는, 애드온이 실행될 수 있지만 CPU 시간 슬라이스 제한으로 인해
성능이 저하된다.</p><p>클러스터 애드온 리소스 문제가 발생하지 않도록, 노드가 많은 클러스터를
만들 때, 다음 사항을 고려한다.</p><ul><li>일부 애드온은 수직으로 확장된다. 클러스터 또는 전체 장애 영역을
제공하는 애드온 레플리카가 하나 있다. 이러한 애드온의 경우, 클러스터를 확장할 때
요청과 제한을 늘린다.</li><li>많은 애드온은 수평으로 확장된다. 더 많은 파드를 실행하여 용량을 추가하지만,
매우 큰 클러스터에서는 CPU 또는 메모리 제한을 약간 높여야 할 수도 있다.
VerticalPodAutoscaler는 <em>recommender</em> 모드에서 실행되어 요청 및 제한에 대한
제안 수치를 제공할 수 있다.</li><li>일부 애드온은 <a class=glossary-tooltip title="파드의 복제본을 클러스터 노드 집합에서 동작하게 한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=데몬셋(DaemonSet)>데몬셋(DaemonSet)</a>에 의해 제어되는 노드 당 하나의 복사본으로 실행된다(예: 노드 수준 로그 수집기). 수평
확장 애드온의 경우와 유사하게, CPU 또는 메모리 제한을 약간 높여야
할 수도 있다.</li></ul><h2 id=다음-내용>다음 내용</h2><p><code>VerticalPodAutoscaler</code> 는 리소스 요청 및 파드 제한을 관리하는 데 도움이 되도록
클러스터에 배포할 수 있는 사용자 정의 리소스이다.
클러스터에 중요한 애드온을 포함하여 클러스터 컴포넌트를 확장하는 방법에 대한
자세한 내용은 <a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#readme>Vertical Pod Autoscaler</a>를
방문하여 배워본다.</p><p><a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#readme>클러스터 오토스케일러</a>는
여러 클라우드 프로바이더와 통합되어 클러스터의 리소스 요구 수준에 맞는
노드 수를 실행할 수 있도록 도와준다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-970615c97499e3651fd3a98e0387cefc>4.2 - 여러 영역에서 실행</h1><p>이 페이지에서는 여러 영역에서 쿠버네티스를 실행하는 방법을 설명한다.</p><h2 id=배경>배경</h2><p>쿠버네티스는 단일 쿠버네티스 클러스터가 여러 장애 영역에서
실행될 수 있도록 설계되었다. 일반적으로 이러한 영역은 <em>지역(region)</em> 이라는
논리적 그룹 내에 적합하다. 주요 클라우드 제공자는 지역을 일관된 기능 집합을
제공하는 장애 영역 집합(<em>가용성 영역</em> 이라고도 함)으로
정의한다. 지역 내에서 각 영역은 동일한 API 및
서비스를 제공한다.</p><p>일반적인 클라우드 아키텍처는 한 영역의 장애가 다른 영역의 서비스도
손상시킬 가능성을 최소화하는 것을 목표로 한다.</p><h2 id=컨트롤-플레인-동작>컨트롤 플레인 동작</h2><p>모든 <a href=/ko/docs/concepts/overview/components/#%EC%BB%A8%ED%8A%B8%EB%A1%A4-%ED%94%8C%EB%A0%88%EC%9D%B8-%EC%BB%B4%ED%8F%AC%EB%84%8C%ED%8A%B8>컨트롤 플레인 컴포넌트</a>는
컴포넌트별로 복제되는 교환 가능한 리소스 풀로 실행을
지원한다.</p><p>클러스터 컨트롤 플레인을 배포할 때, 여러 장애 영역에
컨트롤 플레인 컴포넌트의 복제본을 배치한다. 가용성이
중요한 문제인 경우, 3개 이상의 장애 영역을 선택하고
각 개별 컨트롤 플레인 컴포넌트(API 서버, 스케줄러, etcd,
클러스터 컨트롤러 관리자)를 3개 이상의 장애 영역에 복제한다.
클라우드 컨트롤러 관리자를 실행 중인 경우 선택한
모든 장애 영역에 걸쳐 이를 복제해야 한다.</p><blockquote class="note callout"><div><strong>참고:</strong> 쿠버네티스는 API 서버 엔드포인트에 대한 교차 영역 복원성을 제공하지
않는다. DNS 라운드-로빈, SRV 레코드 또는 상태 확인 기능이 있는
써드파티 로드 밸런싱 솔루션을 포함하여 다양한 기술을 사용하여
클러스터 API 서버의 가용성을 향상시킬 수 있다.</div></blockquote><h2 id=노드-동작>노드 동작</h2><p>쿠버네티스는 클러스터의 여러 노드에 걸쳐
워크로드 리소스(예: <a class=glossary-tooltip title="클러스터에서 복제된 애플리케이션을 관리한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=디플로이먼트(Deployment)>디플로이먼트(Deployment)</a>
또는 <a class=glossary-tooltip title="내구성이 있는 스토리지와 파드별로 지속성 식별자를 사용해서 파드 집합의 디플로이먼트와 스케일링을 관리한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=스테이트풀셋(StatefulSet)>스테이트풀셋(StatefulSet)</a>)에
대한 파드를 자동으로 분배한다. 이러한 분배는
실패에 대한 영향을 줄이는 데 도움이 된다.</p><p>노드가 시작되면, 각 노드의 kubelet이 쿠버네티스 API에서
특정 kubelet을 나타내는 노드 오브젝트에
<a class=glossary-tooltip title="사용자에게 의미 있고 관련성 높은 특징으로 식별할 수 있도록 오브젝트에 태그를 붙인다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/working-with-objects/labels target=_blank aria-label=레이블>레이블</a>을 자동으로 추가한다.
이러한 레이블에는
<a href=/docs/reference/labels-annotations-taints/#topologykubernetesiozone>영역 정보</a>가 포함될 수 있다.</p><p>클러스터가 여러 영역 또는 지역에 걸쳐있는 경우,
<a href=/ko/docs/concepts/workloads/pods/pod-topology-spread-constraints/>파드 토폴로지 분배 제약 조건</a>과
함께 노드 레이블을 사용하여
파드가 장애 도메인(지역, 영역, 특정 노드) 간 클러스터에
분산되는 방식을 제어할 수 있다.
이러한 힌트를 통해
<a class=glossary-tooltip title="노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>는
더 나은 예상 가용성을 위해 파드를 배치할 수 있으므로, 상관 관계가 있는
오류가 전체 워크로드에 영향을 미칠 위험을 줄일 수 있다.</p><p>예를 들어, 가능할 때마다 스테이트풀셋의
3개 복제본이 모두 서로 다른 영역에서 실행되도록 제약 조건을
설정할 수 있다. 각 워크로드에 사용 중인
가용 영역을 명시적으로 정의하지 않고 이를 선언적으로
정의할 수 있다.</p><h3 id=여러-영역에-노드-분배>여러 영역에 노드 분배</h3><p>쿠버네티스의 코어는 사용자를 위해 노드를 생성하지 않는다. 사용자가 직접 수행하거나,
<a href=https://cluster-api.sigs.k8s.io/>클러스터 API</a>와 같은 도구를 사용하여
사용자 대신 노드를 관리해야 한다.</p><p>클러스터 API와 같은 도구를 사용하면 여러 장애 도메인에서
클러스터의 워커 노드로 실행할 머신 집합과 전체 영역 서비스 중단 시
클러스터를 자동으로 복구하는 규칙을 정의할 수 있다.</p><h2 id=파드에-대한-수동-영역-할당>파드에 대한 수동 영역 할당</h2><p>생성한 파드와 디플로이먼트, 스테이트풀셋, 잡(Job)과
같은 워크로드 리소스의 파드 템플릿에 <a href=/ko/docs/concepts/scheduling-eviction/assign-pod-node/#%EB%85%B8%EB%93%9C-%EC%85%80%EB%A0%89%ED%84%B0-nodeselector>노드 셀렉터 제약 조건</a>을
적용할 수 있다.</p><h2 id=영역에-대한-스토리지-접근>영역에 대한 스토리지 접근</h2><p>퍼시스턴트 볼륨이 생성되면, <code>PersistentVolumeLabel</code>
<a href=/docs/reference/access-authn-authz/admission-controllers/>어드미션 컨트롤러</a>는
특정 영역에 연결된 모든 퍼시스턴트볼륨(PersistentVolume)에 영역 레이블을 자동으로
추가한다. 그런 다음 <a class=glossary-tooltip title="노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>는
<code>NoVolumeZoneConflict</code> 프레디케이트(predicate)를 통해 주어진 퍼시스턴트볼륨을 요구하는 파드가
해당 볼륨과 동일한 영역에만 배치되도록 한다.</p><p>해당 클래스의 스토리지가 사용할 수 있는 장애 도메인(영역)을 지정하는
퍼시스턴트볼륨클레임(PersistentVolumeClaims)에 대한
<a class=glossary-tooltip title="스토리지클래스는 관리자가 사용 가능한 다양한 스토리지 유형을 설명할 수 있는 방법을 제공한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/storage/storage-classes target=_blank aria-label=스토리지클래스(StorageClass)>스토리지클래스(StorageClass)</a>를 지정할 수 있다.
장애 도메인 또는 영역을 인식하는 스토리지클래스 구성에 대한 자세한 내용은
<a href=/ko/docs/concepts/storage/storage-classes/#%ED%97%88%EC%9A%A9%EB%90%9C-%ED%86%A0%ED%8F%B4%EB%A1%9C%EC%A7%80>허용된 토폴로지</a>를 참고한다.</p><h2 id=네트워킹>네트워킹</h2><p>쿠버네티스가 스스로 영역-인지(zone-aware) 네트워킹을 포함하지는 않는다.
<a href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/>네트워크 플러그인</a>을
사용하여 클러스터 네트워킹을 구성할 수 있으며, 해당 네트워크 솔루션에는 영역별 요소가
있을 수 있다. 예를 들어, 클라우드 제공자가
<code>type=LoadBalancer</code> 를 사용하여 서비스를 지원하는 경우, 로드 밸런서는 지정된 연결을 처리하는
로드 밸런서 요소와 동일한 영역에서 실행 중인 파드로만 트래픽을 보낼 수 있다.
자세한 내용은 클라우드 제공자의 문서를 확인한다.</p><p>사용자 정의 또는 온-프레미스 배포의 경우, 비슷한 고려 사항이 적용된다.
다른 장애 영역 처리를 포함한 <a class=glossary-tooltip title="네트워크 서비스로 파드 집합에서 실행 중인 애플리케이션을 노출하는 방법" data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=서비스>서비스</a>와
<a class=glossary-tooltip title="클러스터 내의 서비스에 대한 외부 접근을 관리하는 API 오브젝트이며, 일반적으로 HTTP를 관리함." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/services-networking/ingress/ target=_blank aria-label=인그레스(Ingress)>인그레스(Ingress)</a> 동작은
클러스터가 설정된 방식에 명확히 의존한다.</p><h2 id=장애-복구>장애 복구</h2><p>클러스터를 설정할 때, 한 지역의 모든 장애 영역이 동시에
오프라인 상태가 되는 경우 설정에서 서비스를 복원할 수 있는지
여부와 방법을 고려해야 할 수도 있다. 예를 들어, 영역에서 파드를 실행할 수 있는
노드가 적어도 하나 이상 있어야 하는가?
클러스터에 중요한 복구 작업이 클러스터에
적어도 하나 이상의 정상 노드에 의존하지 않는지 확인한다. 예를 들어, 모든 노드가
비정상인 경우, 하나 이상의 노드를 서비스할 수 있을 만큼 복구를 완료할 수 있도록 특별한
<a class=glossary-tooltip title="세 가지 필수 속성: 키(key), 값(value), 효과(effect)로 구성된 코어 오브젝트. 톨러레이션은 매칭되는 테인트(taint)를 가진 노드나 노드 그룹에 파드가 스케줄링되는 것을 활성화한다." data-toggle=tooltip data-placement=top href=/docs/concepts/scheduling-eviction/taint-and-toleration/ target=_blank aria-label=톨러레이션(toleration)>톨러레이션(toleration)</a>으로
복구 작업을 실행해야 할 수 있다.</p><p>쿠버네티스는 이 문제에 대한 답을 제공하지 않는다. 그러나,
고려해야 할 사항이다.</p><h2 id=다음-내용>다음 내용</h2><p>스케줄러가 구성된 제약 조건을 준수하면서, 클러스터에 파드를 배치하는 방법을 알아보려면,
<a href=/ko/docs/concepts/scheduling-eviction/>스케줄링과 축출(eviction)</a>을 참고한다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f89867de1d34943f1524f67a241f5cc9>4.3 - 노드 구성 검증하기</h1><h2 id=노드-적합성-테스트>노드 적합성 테스트</h2><p><em>노드 적합성 테스트</em> 는 노드의 시스템 검증과 기능 테스트를 제공하기 위해 컨테이너화된 테스트 프레임워크이다.
테스트는 노드가 쿠버네티스를 위한 최소 요구조건을 만족하는지를 검증한다. 그리고 테스트를 통과한 노드는 쿠버네티스 클러스터에 참
여할 자격이 주어진다.</p><h2 id=노드-필수-구성-요소>노드 필수 구성 요소</h2><p>노드 적합성 테스트를 실행하기 위해서는, 해당 노드는 표준 쿠버네티스 노드로서 동일한 전제조건을 만족해야 한다.
노드는 최소한 아래 데몬들이 설치되어 있어야 한다.</p><ul><li>컨테이너 런타임 (Docker)</li><li>Kubelet</li></ul><h2 id=노드-적합성-테스트-실행>노드 적합성 테스트 실행</h2><p>노드 적합성 테스트는 다음 순서로 진행된다.</p><ol><li>kubelet에 대한 <code>--kubeconfig</code> 옵션의 값을 계산한다. 예를 들면, 다음과 같다.
<code>--kubeconfig = / var / lib / kubelet / config.yaml</code>.
테스트 프레임워크는 kubelet을 테스트하기 위해 로컬 컨트롤 플레인을 시작하기 때문에,
<code>http://localhost:8080</code> 을 API 서버의 URL로 사용한다.
사용할 수 있는 kubelet 커맨드 라인 파라미터가 몇 개 있다.</li></ol><ul><li><code>--pod-cidr</code>: <code>kubenet</code>을 사용 중이라면, 임의의 CIDR을 Kubelet에 지정해주어야 한다. 예) <code>--pod-cidr=10.180.0.0/24</code>.</li><li><code>--cloud-provider</code>: <code>--cloud-provider=gce</code>를 사용 중이라면, 테스트 실행 시에는 제거해야 한다.</li></ul><ol start=2><li>다음 커맨드로 노드 적합성 테스트를 실행한다.</li></ol><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># $CONFIG_DIR는 Kublet의 파드 매니페스트 경로이다.</span>
<span style=color:#080;font-style:italic># $LOG_DIR는 테스트 출력 경로이다.</span>
sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  k8s.gcr.io/node-test:0.2
</code></pre></div><h2 id=다른-아키텍처에서-노드-적합성-테스트-실행>다른 아키텍처에서 노드 적합성 테스트 실행</h2><p>쿠버네티스는 다른 아키텍쳐용 노드 적합성 테스트 Docker 이미지도 제공한다.</p><table><thead><tr><th>Arch</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td>amd64</td><td style=text-align:center>node-test-amd64</td></tr><tr><td>arm</td><td style=text-align:center>node-test-arm</td></tr><tr><td>arm64</td><td style=text-align:center>node-test-arm64</td></tr></tbody></table><h2 id=선택된-테스트-실행>선택된 테스트 실행</h2><p>특정 테스트만 실행하기 위해서는 환경 변수 <code>FOCUS</code>에 테스트하고자 하는 테스트를 정규식으로 지정한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs:ro -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -e <span style=color:#b8860b>FOCUS</span><span style=color:#666>=</span>MirrorPod <span style=color:#b62;font-weight:700>\ </span><span style=color:#080;font-style:italic># MirrorPod 테스트만 실행</span>
  k8s.gcr.io/node-test:0.2
</code></pre></div><p>특정 테스트를 건너뛰기 위해서는, 환경 변수 <code>SKIP</code>에 건너뛰고자 하는 테스트를 정규식으로 지정한다.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs:ro -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -e <span style=color:#b8860b>SKIP</span><span style=color:#666>=</span>MirrorPod <span style=color:#b62;font-weight:700>\ </span><span style=color:#080;font-style:italic># MirrorPod 테스트만 건너뛰고 모든 적합성 테스트를 실행한다</span>
  k8s.gcr.io/node-test:0.2
</code></pre></div><p>노드 적합성 테스트는 <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/e2e-node-tests.md>노드 e2e 테스트</a>를 컨테이너화한 버전이다.
기본적으로, 모든 적합성 테스트를 실행한다.</p><p>이론적으로, 컨테이너와 필요한 볼륨을 적절히 설정했다면 어떤 노드 e2e 테스트도 수행할 수 있다.
하지만, 적합성 테스트가 아닌 테스트들은 훨씬 복잡한 설정이 필요하기 때문에 <strong>적합성 테스트만 실행하기를 강하게 추천한다.</strong></p><h2 id=주의-사항>주의 사항</h2><ul><li>테스트 후, 노드 적합성 테스트 이미지 및 기능 테스트에 사용된 이미지들을 포함하여 몇 개의 Docker 이미지들이 노드에 남는다.</li><li>테스트 후, 노드에 죽은 컨테이너가 남는다. 기능 테스트 도중에 생성된 컨테이너들이다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0394f813094b7a35058dffe5b8bacd20>4.4 - PKI 인증서 및 요구 조건</h1><p>쿠버네티스는 TLS 위에 인증을 위해 PKI 인증서가 필요하다.
만약 <a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>으로 쿠버네티스를 설치했다면, 클러스터에 필요한 인증서는 자동으로 생성된다.
또한 더 안전하게 자신이 소유한 인증서를 생성할 수 있다. 이를 테면, 개인키를 API 서버에 저장하지 않으므로 더 안전하게 보관할 수 있다.
이 페이지는 클러스터에 필요한 인증서를 설명한다.</p><h2 id=클러스터에서-인증서는-어떻게-이용되나>클러스터에서 인증서는 어떻게 이용되나?</h2><p>쿠버네티스는 다음 작업에서 PKI가 필요하다.</p><ul><li>kubelet에서 API 서버 인증서를 인증시 사용하는 클라이언트 인증서</li><li>API 서버 엔드포인트를 위한 서버 인증서</li><li>API 서버에 클러스터 관리자 인증을 위한 클라이언트 인증서</li><li>API 서버에서 kubelet과 통신을 위한 클라이언트 인증서</li><li>API 서버에서 etcd 간의 통신을 위한 클라이언트 인증서</li><li>컨트롤러 매니저와 API 서버 간의 통신을 위한 클라이언트 인증서/kubeconfig</li><li>스케줄러와 API 서버간 통신을 위한 클라이언트 인증서/kubeconfig</li><li><a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>front-proxy</a>를 위한 클라이언트와 서버 인증서</li></ul><blockquote class="note callout"><div><strong>참고:</strong> <code>front-proxy</code> 인증서는 kube-proxy에서 <a href=/ko/docs/tasks/extend-kubernetes/setup-extension-api-server/>API 서버 확장</a>을 지원할 때만 kube-proxy에서 필요하다.</div></blockquote><p>etcd 역시 클라이언트와 피어 간에 상호 TLS 인증을 구현한다.</p><h2 id=인증서를-저장하는-위치>인증서를 저장하는 위치</h2><p>만약 쿠버네티스를 kubeadm으로 설치했다면 인증서는 <code>/etc/kubernets/pki</code>에 저장된다. 이 문서에 언급된 모든 파일 경로는 그 디렉터리에 상대적이다.</p><h2 id=인증서-수동-설정>인증서 수동 설정</h2><p>필요한 인증서를 kubeadm으로 생성하기 싫다면 다음 방법 중 하나로 생성할 수 있다.</p><h3 id=단일-루트-ca>단일 루트 CA</h3><p>관리자에 의해 제어되는 단일 루트 CA를 만들 수 있다. 이 루트 CA는 여러 중간 CA를 생성할 수 있고, 모든 추가 생성에 관해서도 쿠버네티스 자체에 위임할 수 있다.</p><p>필요 CA:</p><table><thead><tr><th>경로</th><th>기본 CN</th><th>설명</th></tr></thead><tbody><tr><td>ca.crt,key</td><td>kubernetes-ca</td><td>쿠버네티스 일반 CA</td></tr><tr><td>etcd/ca.crt,key</td><td>etcd-ca</td><td>모든 etcd 관련 기능을 위해서</td></tr><tr><td>front-proxy-ca.crt,key</td><td>kubernetes-front-proxy-ca</td><td><a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>front-end proxy</a> 위해서</td></tr></tbody></table><p>위의 CA외에도, 서비스 계정 관리를 위한 공개/개인 키 쌍인 <code>sa.key</code> 와 <code>sa.pub</code> 을 얻는 것이 필요하다.</p><h3 id=모든-인증서>모든 인증서</h3><p>이런 개인키를 API 서버에 복사하기 원치 않는다면, 모든 인증서를 스스로 생성할 수 있다.</p><p>필요한 인증서:</p><table><thead><tr><th>기본 CN</th><th>부모 CA</th><th>O (주체에서)</th><th>종류</th><th>호스트 (SAN)</th></tr></thead><tbody><tr><td>kube-etcd</td><td>etcd-ca</td><td></td><td>server, client</td><td><code>localhost</code>, <code>127.0.0.1</code></td></tr><tr><td>kube-etcd-peer</td><td>etcd-ca</td><td></td><td>server, client</td><td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>localhost</code>, <code>127.0.0.1</code></td></tr><tr><td>kube-etcd-healthcheck-client</td><td>etcd-ca</td><td></td><td>client</td><td></td></tr><tr><td>kube-apiserver-etcd-client</td><td>etcd-ca</td><td>system:masters</td><td>client</td><td></td></tr><tr><td>kube-apiserver</td><td>kubernetes-ca</td><td></td><td>server</td><td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>&lt;advertise_IP></code>, <code>[1]</code></td></tr><tr><td>kube-apiserver-kubelet-client</td><td>kubernetes-ca</td><td>system:masters</td><td>client</td><td></td></tr><tr><td>front-proxy-client</td><td>kubernetes-front-proxy-ca</td><td></td><td>client</td><td></td></tr></tbody></table><p>[1]: 클러스터에 접속한 다른 IP 또는 DNS 이름(<a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a> 이 사용하는 로드 밸런서 안정 IP 또는 DNS 이름, <code>kubernetes</code>, <code>kubernetes.default</code>, <code>kubernetes.default.svc</code>,
<code>kubernetes.default.svc.cluster</code>, <code>kubernetes.default.svc.cluster.local</code>)</p><p><code>kind</code>는 하나 이상의 <a href=https://godoc.org/k8s.io/api/certificates/v1beta1#KeyUsage>x509 키 사용</a> 종류를 가진다.</p><table><thead><tr><th>종류</th><th>키 사용</th></tr></thead><tbody><tr><td>server</td><td>digital signature, key encipherment, server auth</td></tr><tr><td>client</td><td>digital signature, key encipherment, client auth</td></tr></tbody></table><blockquote class="note callout"><div><strong>참고:</strong> 위에 나열된 호스트/SAN은 작업 중인 클러스터를 획득하는데 권장된다. 특정 설정이 필요한 경우, 모든 서버 인증서에 SAN을 추가할 수 있다.</div></blockquote><blockquote class="note callout"><div><strong>참고:</strong><p>kubeadm 사용자만 해당:</p><ul><li>개인 키 없이 클러스터 CA 인증서에 복사하는 시나리오는 kubeadm 문서에서 외부 CA라고 한다.</li><li>위 목록을 kubeadm이 생성한 PKI와 비교하는 경우, <code>kube-etcd</code>, <code>kube-etcd-peer</code> 와 <code>kube-etcd-healthcheck-client</code> 인증서는
외부 etcd 케이스에서는 생성하지 않는 것을 알고 있어야 한다.</li></ul></div></blockquote><h3 id=인증서-파일-경로>인증서 파일 경로</h3><p>인증서는 권고하는 파일 경로에 존재해야 한다(<a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>에서 사용되는 것처럼). 경로는 위치에 관계없이 주어진 파라미터를 사용하여 지정해야 한다.</p><table><thead><tr><th>기본 CN</th><th>권고되는 키 파일 경로</th><th>권고하는 인증서 파일 경로</th><th>명령어</th><th>키 파라미터</th><th>인증서 파라미터</th></tr></thead><tbody><tr><td>etcd-ca</td><td>etcd/ca.key</td><td>etcd/ca.crt</td><td>kube-apiserver</td><td></td><td>--etcd-cafile</td></tr><tr><td>kube-apiserver-etcd-client</td><td>apiserver-etcd-client.key</td><td>apiserver-etcd-client.crt</td><td>kube-apiserver</td><td>--etcd-keyfile</td><td>--etcd-certfile</td></tr><tr><td>kubernetes-ca</td><td>ca.key</td><td>ca.crt</td><td>kube-apiserver</td><td></td><td>--client-ca-file</td></tr><tr><td>kubernetes-ca</td><td>ca.key</td><td>ca.crt</td><td>kube-controller-manager</td><td>--cluster-signing-key-file</td><td>--client-ca-file, --root-ca-file, --cluster-signing-cert-file</td></tr><tr><td>kube-apiserver</td><td>apiserver.key</td><td>apiserver.crt</td><td>kube-apiserver</td><td>--tls-private-key-file</td><td>--tls-cert-file</td></tr><tr><td>kube-apiserver-kubelet-client</td><td>apiserver-kubelet-client.key</td><td>apiserver-kubelet-client.crt</td><td>kube-apiserver</td><td>--kubelet-client-key</td><td>--kubelet-client-certificate</td></tr><tr><td>front-proxy-ca</td><td>front-proxy-ca.key</td><td>front-proxy-ca.crt</td><td>kube-apiserver</td><td></td><td>--requestheader-client-ca-file</td></tr><tr><td>front-proxy-ca</td><td>front-proxy-ca.key</td><td>front-proxy-ca.crt</td><td>kube-controller-manager</td><td></td><td>--requestheader-client-ca-file</td></tr><tr><td>front-proxy-client</td><td>front-proxy-client.key</td><td>front-proxy-client.crt</td><td>kube-apiserver</td><td>--proxy-client-key-file</td><td>--proxy-client-cert-file</td></tr><tr><td>etcd-ca</td><td>etcd/ca.key</td><td>etcd/ca.crt</td><td>etcd</td><td></td><td>--trusted-ca-file, --peer-trusted-ca-file</td></tr><tr><td>kube-etcd</td><td>etcd/server.key</td><td>etcd/server.crt</td><td>etcd</td><td>--key-file</td><td>--cert-file</td></tr><tr><td>kube-etcd-peer</td><td>etcd/peer.key</td><td>etcd/peer.crt</td><td>etcd</td><td>--peer-key-file</td><td>--peer-cert-file</td></tr><tr><td>etcd-ca</td><td></td><td>etcd/ca.crt</td><td>etcdctl</td><td></td><td>--cacert</td></tr><tr><td>kube-etcd-healthcheck-client</td><td>etcd/healthcheck-client.key</td><td>etcd/healthcheck-client.crt</td><td>etcdctl</td><td>--key</td><td>--cert</td></tr></tbody></table><p>서비스 계정 키 쌍에도 동일한 고려 사항이 적용된다.</p><table><thead><tr><th>개인키 경로</th><th>공개 키 경로</th><th>명령어</th><th>파라미터</th></tr></thead><tbody><tr><td>sa.key</td><td></td><td>kube-controller-manager</td><td>--service-account-private-key-file</td></tr><tr><td></td><td>sa.pub</td><td>kube-apiserver</td><td>--service-account-key-file</td></tr></tbody></table><h2 id=각-사용자-계정을-위한-인증서-설정하기>각 사용자 계정을 위한 인증서 설정하기</h2><p>반드시 이런 관리자 계정과 서비스 계정을 설정해야 한다.</p><table><thead><tr><th>파일명</th><th>자격증명 이름</th><th>기본 CN</th><th>O (주체에서)</th></tr></thead><tbody><tr><td>admin.conf</td><td>default-admin</td><td>kubernetes-admin</td><td>system:masters</td></tr><tr><td>kubelet.conf</td><td>default-auth</td><td>system:node:<code>&lt;nodeName></code> (note를 보자)</td><td>system:nodes</td></tr><tr><td>controller-manager.conf</td><td>default-controller-manager</td><td>system:kube-controller-manager</td><td></td></tr><tr><td>scheduler.conf</td><td>default-scheduler</td><td>system:kube-scheduler</td><td></td></tr></tbody></table><blockquote class="note callout"><div><strong>참고:</strong> <code>kubelet.conf</code>을 위한 <code>&lt;nodeName></code>값은 API 서버에 등록된 것처럼 kubelet에 제공되는 노드 이름 값과 <strong>반드시</strong> 정확히 일치해야 한다. 더 자세한 내용은 <a href=/docs/reference/access-authn-authz/node/>노드 인증</a>을 살펴보자.</div></blockquote><ol><li><p>각 환경 설정에 대해 주어진 CN과 O를 이용하여 x509 인증서와 키쌍을 생성한다.</p></li><li><p>각 환경 설정에 대해 다음과 같이 <code>kubectl</code>를 실행한다.</p></li></ol><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>&lt;filename&gt; kubectl config set-cluster default-cluster --server<span style=color:#666>=</span>https://&lt;host ip&gt;:6443 --certificate-authority &lt;path-to-kubernetes-ca&gt; --embed-certs
<span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>&lt;filename&gt; kubectl config set-credentials &lt;credential-name&gt; --client-key &lt;path-to-key&gt;.pem --client-certificate &lt;path-to-cert&gt;.pem --embed-certs
<span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>&lt;filename&gt; kubectl config set-context default-system --cluster default-cluster --user &lt;credential-name&gt;
<span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>&lt;filename&gt; kubectl config use-context default-system
</code></pre></div><p>이 파일들은 다음과 같이 사용된다.</p><table><thead><tr><th>파일명</th><th>명령어</th><th>설명</th></tr></thead><tbody><tr><td>admin.conf</td><td>kubectl</td><td>클러스터 관리자를 설정한다.</td></tr><tr><td>kubelet.conf</td><td>kubelet</td><td>클러스터 각 노드를 위해 필요하다.</td></tr><tr><td>controller-manager.conf</td><td>kube-controller-manager</td><td>반드시 매니페스트를 <code>manifests/kube-controller-manager.yaml</code>에 추가해야 한다.</td></tr><tr><td>scheduler.conf</td><td>kube-scheduler</td><td>반드시 매니페스트를 <code>manifests/kube-scheduler.yaml</code>에 추가해야 한다.</td></tr></tbody></table></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/ko/docs/home/>홈</a>
<a class=text-white href=/ko/blog/>블로그</a>
<a class=text-white href=/ko/training/>교육</a>
<a class=text-white href=/ko/partners/>파트너</a>
<a class=text-white href=/ko/community/>커뮤니티</a>
<a class=text-white href=/ko/case-studies/>사례 연구</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/popper-1.14.3.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script><script src=/js/bootstrap-4.3.1.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script><script src=/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js integrity="sha256-QGFiUam25LaJ53ab4DQGYe+k1+u3P5V0BOlj4TW07VI=" crossorigin=anonymous></script></body></html>